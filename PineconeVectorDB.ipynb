{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo\n",
    "Create streamlit app\n",
    "Rag fusion \n",
    "Search other rag techniques that would make your output better \n",
    "How do you run all your code without creating a new index every time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import standard libraries\n",
    "import os\n",
    "from typing import List\n",
    "import json\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Langchain Lbraries\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_react_agent\n",
    "from langsmith import Client\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain. retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_core.messages.human import HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pinecone libraries\n",
    "import pinecone\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import utilis\n",
    "from airtable import AirTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import secret keys\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pine_cone_api = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup Langsmith for debugging\n",
    "from uuid import uuid4\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Tracing Walkthrough - {unique_id}\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__c4c7a9772ef046038636017b03b5f17b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Langsmith_client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompts.prompts_2024_03_26 as prompts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        To post data to the Airtable table.\n",
      "        Args:\n",
      "            data (dict): A dictionary with the format `{'column_name': data_to_post, ...}`.\n",
      "        \n",
      "        Keys for dictionary:\n",
      "              {\n",
      "                name_of_dev: \"\",\n",
      "                model_name: \"\",\n",
      "                human_prompt: \"\",\n",
      "                global_context: \"\",\n",
      "                context_entrichment_agent_system_prompt: \"\",\n",
      "                enriched_prompt_output: \"\",\n",
      "                rag_extractor_agent_system_prompt: \"\",\n",
      "                rag_optimized_queries_output: \"\",\n",
      "                total_chunks_retrieved: \"\",\n",
      "                chunk_size: \"\",\n",
      "                knowledge_base_docs_list: \"\",\n",
      "                evaluator_agent_system_prompt: \"\",\n",
      "                reranked_rag_queries_output: \"\",\n",
      "                answer_agent_system_prompt: \"\",\n",
      "                final_answer_to_user: \"\"\n",
      "              }\n",
      "        \n",
      "data posted to Airtable successfully.\n"
     ]
    }
   ],
   "source": [
    "airtable = AirTable()\n",
    "airtable.post_data_to_table(data={\"name_of_dev\": \"kuba\",\n",
    "                \"model_name\": \"\",\n",
    "                \"human_prompt\": \"\",\n",
    "                \"global_context\": \"\",\n",
    "                \"context_entrichment_agent_system_prompt\": \"\",\n",
    "                \"enriched_prompt_output\": \"\",\n",
    "                \"rag_extractor_agent_system_prompt\": \"\",\n",
    "                \"rag_optimized_queries_output\": \"\",\n",
    "                \"total_chunks_retrieved\": \"\",\n",
    "                \"chunk_size\": \"\",\n",
    "                \"knowledge_base_docs_list\": \"\",\n",
    "                \"evaluator_agent_system_prompt\": \"\",\n",
    "                \"reranked_rag_queries_output\": \"\",\n",
    "                \"answer_agent_system_prompt\": \"\",\n",
    "                \"final_answer_to_user\": \"\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiaze large language models\n",
    "llm  = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key, \n",
    "    model=\"gpt-4-turbo-preview\", \n",
    "    temperature= 0.4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import global context file \n",
    "with open(\"Fastrise_global_context.txt\", \"r\") as file:\n",
    "     global_context = file.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "COMPONENTS OF CONTEXT ENRICHMENT AGENT\n",
    "global_context document \n",
    "tool \n",
    "prompt template\n",
    "human input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Context_Enrichment_Agent(human_prompt: str):\n",
    "   \n",
    "    #import global context file \n",
    "    with open(\"Fastrise_global_context.txt\", \"r\") as file:\n",
    "     global_context = file.read()\n",
    "    \n",
    "    \n",
    "    @tool\n",
    "    def Enrichement_tool(human_prompt:str)-> str:\n",
    "        \"use this tool any time you get question about meetings, tasks, activities in a organization called Fastrise\"\n",
    "        global global_context\n",
    "        return global_context\n",
    "\n",
    "    tools = [Enrichement_tool]\n",
    "\n",
    "    #create context_enrichment prompt template\n",
    "    context_enrichment_template = prompts.context_enrichment_template\n",
    "    context_prompt = PromptTemplate.from_template(template=context_enrichment_template, MessagePlaceholder=[\"(agent_scratchpad)\"])\n",
    "    \n",
    "    #creating agent from the template\n",
    "    context_agent = create_react_agent(\n",
    "                            llm=llm, \n",
    "                           tools=tools, \n",
    "                           prompt=context_prompt)\n",
    "    \n",
    "   #invoke the agent\n",
    "    context_agent_executor = AgentExecutor(\n",
    "    agent=context_agent, \n",
    "    tools=tools, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True, \n",
    "    )\n",
    "    context_enriched_output = context_agent_executor.invoke({\"input\": human_prompt })\n",
    "    Enriched_prompt = context_enriched_output[\"output\"]\n",
    "    \n",
    "    return Enriched_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = \"Given a list of tasks to be completed knowledgenow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Given a list of tasks to be completed knowledgenow\n",
      "\n",
      "Thought: To enrich the user's prompt effectively, I need to understand the specific tasks mentioned, their relevance to Fasterise's organizational goals, and any underlying context that might influence their prioritization or execution. This requires integrating knowledge about Fasterise's strategic objectives, the teams involved, and any recent developments or challenges that could impact these tasks.\n",
      "\n",
      "Action: Enrichement_tool\n",
      "\n",
      "Action Input: Given a list of tasks to be completed knowledgenow\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m### Mission and Vision\n",
      "- *Mission and Vision*: Fasterise is centered around leveraging AI technology to amplify human potential, prioritizing ethical AI development that enriches human capabilities. The company envisions a future where AI solutions address societal needs and business challenges while augmenting the human potential and keeping it at the center of the system.\n",
      "### Team Structure and Roles\n",
      "- *Henry*: Brings AI and entrepreneurial insights, contributing significantly to the team's innovative capabilities in AI and LangChain.\n",
      "- *Zach*: Offers sales expertise and a keen sense for impactful business development, essential for guiding the company's market direction.\n",
      "- *Paige*: With a background in education and a focus on ethical AI, Paige drives the mission, marketing vision, and operational strategies of the company.\n",
      "- *Pawel*: Provides business analysis and client-facing skills, ensuring professional and confident representation of Fasterise's image.\n",
      "- *Bartek*: Leads in engineering with expertise in Prompt Engineering and AI Agents, and a focus on system design and test-driven development, enhancing the company's technical rigor.\n",
      "- *Alejo*: Plays a key role in Operations, Sales, and Development. In development, Alejo focuses on developer guidance through Scrums, making the vision of the company more tangible into projects with a particular emphasis on AI technologies like RAG, LLMs and Multi-Agent Systems.\n",
      "- *Hubi*: is diving into Python, LangChain and RAG. He has experience in front end development.\n",
      "- *Jorg*: Contributes to social media content and marketing campaigns, showcasing the company's solutions through various platforms.\n",
      "- *Kuba*: has played a key role in LangChain and RAG efforts, creating the first versions of the Pinecone Vector Database chat and the Personalized Outreach System.\n",
      "### Projects and Operations\n",
      "- *Completed Projects*: Highlight projects like the Ski Chalet Concierge, Scheduler Assistant, and Lead Qualifier, which exemplify Fasterise's commitment to enhancing operational efficiency and customer experience through AI.\n",
      "- *Current Projects*: Emphasize the development of innovative solutions like the Zoom Transcriber to Pinecone Integration, Knowledge Base Builder called KnowledgeNow, Personalized Outreach System, Administrative Automation Tools, and Real Estate-focused AI Solutions. These projects aim to integrate AI across various industries, improving efficiency and amplifying human capabilities.\n",
      "- *Future Direction*: Focus on continuous exploration of AI applications, with a commitment to adapting to technological advancements and exploring areas where AI can have a transformative societal impact, keeping empowerement and education at the forefront of the company's mission.\n",
      "### Company Culture and Values\n",
      "- *Profit-Sharing and Collaboration*: All team members are co-founders, with a profit-sharing structure and collective decision-making. The company culture promotes innovation, ethical business practices, and a shared vision for the impact of AI technology.\n",
      "- *Ethical and Human-Centered Approach*: A foundational commitment to developing AI solutions that align with ethical standards, enhance rather than replace human work, and focus on amplifying human capabilities.\n",
      "### Innovations and Products\n",
      "- *Technological Innovations*: AI-driven products, including AI solutions for real estate, personalized outreach, and KnowledgeNow. High technological sophistication and human-centered design of products like automated CRM and calendar systems, which facilitate better interactions with leads and clients.\n",
      "### Conclusion\n",
      "Fasterise stands out for its innovative approach to AI technology, with a strong emphasis on ethical development, collaborative innovation, and a culture of shared success. Through a diverse range of projects, the company showcases its capability to address complex challenges across various sectors, aiming for a significant societal impact and leading by example in the ethical use and development of AI.\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Given a list of tasks to be completed knowledgenow\n",
      "\n",
      "Thought: To enrich the user's prompt effectively, I have integrated comprehensive details about Fasterise's mission, team structure, ongoing projects, and company values. This enriched context will help in understanding the significance of the tasks within the broader organizational objectives and how they align with Fasterise's strategic goals and ethical AI development focus.\n",
      "\n",
      "Final Answer: In the context of Fasterise's mission to leverage AI technology to amplify human potential with a strong emphasis on ethical AI development, and considering the company's diverse team structure comprising individuals with expertise in AI, sales, ethical AI, business analysis, engineering, operations, and marketing, how can the tasks listed for the KnowledgeNow project be prioritized and executed effectively? This consideration should take into account the company's ongoing projects such as the Zoom Transcriber to Pinecone Integration, Knowledge Base Builder (KnowledgeNow), Personalized Outreach System, Administrative Automation Tools, and Real Estate-focused AI Solutions, aligning with the strategic goals of continuous AI application exploration, empowerment, education, and a transformative societal impact. Additionally, how can these tasks be aligned with Fasterise's culture of profit-sharing, collaboration, and its ethical, human-centered approach to AI development?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Enriched_prompt_output = Context_Enrichment_Agent(human_prompt=human_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In their meeting, Alejo and Bartek discussed strategic initiatives and projects at Fasterise, focusing on leveraging AI technology to amplify human potential and address societal needs. They covered the roles and contributions of team members, including their own in operations, sales, development, engineering, and prompt engineering with AI agents. They highlighted completed projects like the Ski Chalet Concierge, Scheduler Assistant, and Lead Qualifier, and current projects such as the Zoom Transcriber to Pinecone Integration and KnowledgeNow. The discussion also touched on the company's mission, vision, culture of innovation, profit-sharing, and the ethical, human-centered approach to AI development. This aligns with Fasterise's goals of ethical AI development, enhancing operational efficiency, and exploring AI's transformative societal impact.\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Enriched_prompt_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG EXTRACTOR AGENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rag_extractor_agent(Enriched_prompt_output:str) -> list:\n",
    "\n",
    "#Creating a class for my output parser\n",
    "    class sub_query(BaseModel):\n",
    "\n",
    "        sub_queries: list = Field(description=\"\"\"The sub queries extracted from the context_enriched_prompt\"\"\")\n",
    "\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=sub_query)\n",
    "\n",
    "\n",
    "#defining the Rag_extractor tool\n",
    "    @tool\n",
    "    def Rag_extractor(Enriched_prompt_output:str)-> str:\n",
    "        \"use this tool any time you need to access context-enriched prompt for creating the sub-queries\"\n",
    "        return Enriched_prompt_output\n",
    "\n",
    "    tools = [Rag_extractor]\n",
    "\n",
    "    #create rag_extractor prompt template\n",
    "    rag_extractor_template = prompts.rag_template\n",
    "    rag_extractor_prompt = PromptTemplate.from_template(template=rag_extractor_template, MessagePlaceholder=[\"(agent_scratchpad)\"])\n",
    "    #creating agent from the template\n",
    "    rag_extractor_agent = create_react_agent(llm=llm, \n",
    "                           tools=tools, \n",
    "                           prompt=rag_extractor_prompt)\n",
    "    #invoke the agent\n",
    "    rag_extractor_agent_executor = AgentExecutor(\n",
    "    agent=rag_extractor_agent, \n",
    "    tools=tools, \n",
    "    verbose=True, \n",
    "    handle_parsing_errors=True, \n",
    "    )\n",
    "    rag_optimized_queries_output = rag_extractor_agent_executor.invoke({\"input\":human_prompt,\n",
    "                       \"chat_history\": [], \n",
    "                       \"format_instructions\":parser.get_format_instructions() })\n",
    "    \n",
    "    rag_optimized_queries = rag_optimized_queries_output[\"output\"]\n",
    "\n",
    "    Rag_query= rag_optimized_queries\n",
    "\n",
    "\n",
    "    Rag_query_cleaned = Rag_query.replace('```json\\n', '').replace('\\n```', '')\n",
    "\n",
    "    # Convert the JSON string into a dictionary\n",
    "    Rag_query_dict = json.loads(Rag_query_cleaned)\n",
    "\n",
    "    # Extract the sub-queries\n",
    "    sub_queries = Rag_query_dict[\"sub_queries\"]\n",
    "\n",
    "    return sub_queries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"sub_queries\": [\n",
      "    \"List all current tasks assigned within the KnowledgeNow project\",\n",
      "    \"Identify the deadlines for each task in the KnowledgeNow project\",\n",
      "    \"Determine the current progress status of each KnowledgeNow task\",\n",
      "    \"Extract any recent updates or changes made to tasks in the KnowledgeNow project\",\n",
      "    \"Identify team members responsible for each task in the KnowledgeNow project\"\n",
      "  ]\n",
      "}\n",
      "```\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"sub_queries\": [\n",
      "    \"List all current tasks assigned within the KnowledgeNow project\",\n",
      "    \"Identify the deadlines for each task in the KnowledgeNow project\",\n",
      "    \"Determine the current progress status of each KnowledgeNow task\",\n",
      "    \"Extract any recent updates or changes made to tasks in the KnowledgeNow project\",\n",
      "    \"Identify team members responsible for each task in the KnowledgeNow project\"\n",
      "  ]\n",
      "}\n",
      "```\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mAction: Rag_extractor\n",
      "Thought: I now know the final answer\n",
      "Final Answer: ```json\n",
      "{\n",
      "  \"sub_queries\": [\n",
      "    \"List all current tasks assigned within the KnowledgeNow project\",\n",
      "    \"Identify the deadlines for each task in the KnowledgeNow project\",\n",
      "    \"Determine the current progress status of each KnowledgeNow task\",\n",
      "    \"Extract any recent updates or changes made to tasks in the KnowledgeNow project\",\n",
      "    \"Identify team members responsible for each task in the KnowledgeNow project\"\n",
      "  ]\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sub_queries = Rag_extractor_agent(Enriched_prompt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['List all current tasks assigned within the KnowledgeNow project', 'Identify the deadlines for each task in the KnowledgeNow project', 'Determine the current progress status of each KnowledgeNow task', 'Extract any recent updates or changes made to tasks in the KnowledgeNow project', 'Identify team members responsible for each task in the KnowledgeNow project']\n"
     ]
    }
   ],
   "source": [
    "sub_query_texts = [sub_query for sub_query in sub_queries]\n",
    "print(sub_query_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all current tasks assigned within the KnowledgeNow project\n",
      "Identify the deadlines for each task in the KnowledgeNow project\n",
      "Determine the current progress status of each KnowledgeNow task\n",
      "Extract any recent updates or changes made to tasks in the KnowledgeNow project\n"
     ]
    }
   ],
   "source": [
    "sub_query_1 = sub_query_texts[0]\n",
    "sub_query_2 = sub_query_texts[1]\n",
    "sub_query_3 = sub_query_texts[2]\n",
    "sub_query_4 = sub_query_texts[3]\n",
    "print(sub_query_1)\n",
    "print(sub_query_2)\n",
    "print(sub_query_3)\n",
    "print(sub_query_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading company docs\n",
    "loader = DirectoryLoader(\"data\",\n",
    "                    glob=\"**/*.txt\",\n",
    "                    loader_cls= TextLoader)\n",
    "text_documents = loader.load()\n",
    "\n",
    "len(text_documents)\n",
    "    \n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the chunk: 77\n"
     ]
    }
   ],
   "source": [
    "#split documents into chunks\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\")\n",
    "text_chunk = text_splitter.split_documents(text_documents)\n",
    "\n",
    "print(\"The length of the chunk:\", len(text_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the chunk: 367\n"
     ]
    }
   ],
   "source": [
    "#text_splitter = RecursiveCharacterTextSplitter(\n",
    "        #chunk_size= 400,\n",
    "        #chunk_overlap=0,\n",
    "        #length_function=len\n",
    "    #)\n",
    "#text_chunk = text_splitter.split_documents(text_documents)\n",
    "\n",
    "#print(\"The length of the chunk:\", len(text_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 : page_content=\"\\n01:09\\nAlejo\\nOkay. Hi, see you all again. 01:17\\nBartek\\nWaiting for us or it's only three of us here? Hi guys, I'm hearing you right now. I just had a dinner, so excuse me, eating. Aleo, I think you have something with your audio. I can't hear you. Aleo, you're not here. 02:49\\nAlejo\\nOkay, I guess no headphones it is. Hey you guys. 02:53\\nBartek\\nYeah, sounds good. 02:54\\nAlejo\\nCool. 02:55\\nBartek\\nHi again. 02:57\\nAlejo\\nHey, did you say something? Is there something you wanted to share? 03:05\\nBartek\\nI just wanted to share that I have great. Dinner or lunch?\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 1 : page_content=\"Lunch. I messed that up every time. Lunch. 03:13\\nKuba\\nHi guys. 03:15\\nAlejo\\nHey Kuba. 03:23\\nKuba\\nLet'S see how you doing, bro? 03:35\\nAlejo\\n1 second, you guys, thank you guys for sharing your update on Friday. It makes me very happy to see progress on what you get to work on or what you want to work on. I hear a lot of rag, I hear a lot of lang chain. As you said, kuwa, rag is the future. And it's been very exciting to talk to developers this last week. A variety of experiences and expertise and they all say the same thing. It's like Rag is where it's at. Rag is the future, Rag is what I want to learn. So we're taking that strong indication and running with it. We're building knowledge now. Okay, first of all, before we step into that, because start rattling on, wanted to share an update. I'm working on the real estate automations. 04:57\\nAlejo\\nI'm working on the free side on the two free real estate automations. When those are ready, I'll share the demo. In the next few days. They'll be ready. In the next few days. I'll share the demo. We can make sure we get some testing in together and I will make sure that each of us can follow the exact same process for when we actually have the paid clients that will come through referrals that we can emulate this system for their side. For some of those that might include importing contacts to the follow up boss CRM and just setting them up from scratch. For some of them that might be like, hey, I would like these automations and each of us needs to already know the API and how does the CRM actually look and feel? 06:09\\nAlejo\\nSo I kind of tried to do that last week, but I realized I don't understand it well enough to guide others. So I took a step back. It's like, let me work on these automations, finish them, let me fall into the pits of working with any new API and make sure that I set up you guys for success once the money actually comes in. So that's the update on that. On real estate automations, client is still very excited. We got introduced to two people that she's working with, the manual follow up boss guy that's kind of importing her contacts manually and her social media person. And we're going to be able to find ways to help in both of those areas. 07:09\\nAlejo\\nWe got some questions around profit sharing and we will make sure that we have a genexac to clarify, to share, to have questions, and to make sure that everything is clear. It's very important to us, to all of us, to each of us, that we know what's going to happen with the money once the money hits the account. Right. So we'll make sure that everybody has clarity on that and that everybody agrees. Yes, this is fair. Okay, so that's on the real estate side and that's the short term. Yeah, barta, go ahead. 07:58\\nBartek\\nBecause we are kind of starting to work this week, probably internally on some content automation. So I think we can actually work simultaneously on the automation for the real estate. We have this idea to make notion integrated with relevance AI. Like make some agents, and for example you have idea for your content, you write it in the notion, you have this kanban in notion. And then for example, you have this raw idea and then some ideas you want to put to AI to draft. And then that will trigger the relevance AI agent, for example, first kind of EDH version of it. And then basically it would draft a post or whatever and then send it back to notion. So that's where I'm thinking, and we're probably going to start working on it this week if there is a time, if the winds are correct. 09:04\\nAlejo\\nYeah, cool, that's good to know. 09:11\\nBartek\\nAnd I also have updates now from the call just a second ago. 09:17\\nAlejo\\nGo in a circle and do updates. 09:18\\nBartek\\nSo go crazy. Yeah, so I was talking to this guy from the prompt hub, and we can have collaboration there, like constant collaboration or whatever. I was talking to him on this kind of note, but the thing that really clicked after this call, because I was showing him PFA and the output was kind of short. I mean the use case was for a recipe and for a cuisine, sending and generating receipts. So I see that the details couldn't be there more. But I got thinking like PFA sometimes does that PFA sometimes give a short prompt and you need to regenerate. And I was thinking like, we need the swarm, we fucking need the swarm. It's not a product until we have the swarm. This is just a proof of content. And if user have to know that the prompt. 10:10\\nBartek\\nI know from my eyes that the prompt is not good, but users want. So we need to have this. The thing that I'm doing manually, like regenerating, like looking the prompt is not good. Or regenerating, or saying, like, use more markdown or make this prompt more detailed. We need a feedback loop for that in the PFS form, like some agents doing basically what I'm doing now. So the prompt is too short, the prompt lacks markdown, lack structure. We should really go there. 10:42\\nAlejo\\nOkay, perfect. 10:42\\nBartek\\nAnd I'm thinking about maybe we could repurpose some of our agent systems. Like, I'm not sure how we can. Maybe we can use the outage system a little bit to change it in a way that we could have those. Or maybe it's better to make it from scratch. I'm still not sure, but we kind of have this structure already where we have those agents talking to each other. I mean, they are not really talking. That are in a chain, right? Yeah, it's kind of chain of action rather than conversation. I think we need to step into the conversation part where we have some kind of hierarchies. Like this is agent one that making the context enrichment. And then there is another one, let's say in a simplest form, generating. And then we would have some agents that above them and check their work. 11:44\\nBartek\\nAnd they need to talk, basically, yeah. I think we need to make it from scratch. 11:50\\nAlejo\\nOkay.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 2 : page_content=\"Make what from scratch? 11:55\\nBartek\\nThe communication PFA is warm, like the lang chain framework for PFA, basically. 12:02\\nAlejo\\nOkay. 12:03\\nBartek\\nMaybe we can step into some kind of crew AI thing. It's popping recently. Crew AI on my. 12:11\\nAlejo\\nSo let's. Let's get there. I want to make sure that Kuba and Hubi are with us on this dive into the possibilities I'm following. So let's get to the point where everybody's on the same page and we can actually make some decisions because there's a lot of things that we don't need to do from scratch.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 3 : page_content=\"Right. There's a lot of research on communication frameworks that we can probably just grab from an open source and then just tune for the use case of prompt regeneration of PFA. So that's what we will step into.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 4 : page_content=\"Since we're there. 13:05\\nBartek\\nLet's just go there, Kuba, we'll get. 13:07\\nAlejo\\nAround to personalized our system, and I'll give you an update on that. I would like to ask you, Kuba, were you able to start with this rack system from the single document transcript? 13:24\\nKuba\\nYeah, I created it with pine cone. I tested pine cone and abute system. One with pine cone and one with. 13:41\\nAlejo\\nPine cone and the other one with. 13:48\\nKuba\\nOpen source vector database. 13:50\\nAlejo\\nOkay. 13:51\\nKuba\\nYeah, I'm just testing, like cosine similarities between the vectors. 14:01\\nAlejo\\nI'm just testing, yeah. 14:07\\nKuba\\nUpdates the two system. I will show you demo like that. 14:13\\nBartek\\nCool. 14:14\\nAlejo\\nYeah, you have it now. You said you have it now. 14:17\\nKuba\\nYeah, I do. 14:19\\nAlejo\\nAwesome. Let's do it. Let me allow sharing. It's great.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 5 : page_content=\"Yeah. 14:27\\nBartek\\nAlso, on the note of databases, I wanted to ask if, yeah, go ahead. In the meantime, I wanted to ask if we have capabilities on the AWS in our developer team or generally, because there is those two things. Like there is the vector databases and the new stuff, and there is the old stuff, the relational databases, non relational databases. And actually right now we are facing the problem, the challenge, more of them, the problem. Let's see. Challenges, not problems. So we're facing challenge to actually offering the chatbot that will kind of pick four different data inputs into a chatbot interface so the client can basically talk with it. Yeah, I refer to that Us client. And we're thinking if there should be one database out of those four, so we're going to have some data migration and stuff. 15:36\\nBartek\\nSo I'm just thinking if there may be somebody who already been doing some of those stuff. I saw Kuba actually posting something on the discord about AWS, so maybe I can ask you if you've been doing some stuff with. 15:50\\nKuba\\nYeah, yeah. During the weekend, I played around using streamlit. I created a little QC generator. So I created the front end with extremely, and I hosted it on AWS server. So it was like playing around it. 16:09\\nBartek\\nHave you been doing some with daca migration? 16:12\\nKuba\\nNo, not yet. 16:15\\nBartek\\nAll right, so maybe we connect later after this call and maybe talk about this more, or are you aware of somebody else having AWS experience? 16:25\\nAlejo\\nYes, because at another company\\xa0we worked with AWS. So I have experience with AWS storage. I have experience with limited experience with AWS systems, but they don't feel strange to know. I will ask around. And you're essentially looking for a systems engineer, like somebody that could do potentially a migration. 16:55\\nBartek\\nYeah. 16:56\\nAlejo\\nOkay, I'll ask around. Knowledge. Now remind me to ask for a systems engineer. Already getting used to it. 17:09\\nBartek\\nBasically we need to do like centralized database for the chatbot interface. Like initial. 17:15\\nAlejo\\nOkay, cool. 17:16\\nBartek\\nThat's probably going to be migration of. 17:17\\nAlejo\\nThe data migration into a data migration Aws into a central database. Okay, let's pause on that and we can talk more about it later. Kuba, the stage is all yours. Yeah. 17:36\\nKuba\\nSo this is like the chart now. So first of all I put in my pocket, let me just keep this. So yeah, remember I told you earlier I'm not going to use Google Collab I have because number one, it's crashing my system for now because I'm testing, I found a way to build visual code. So this is like the other one I'm building like debugging. 18:09\\nAlejo\\nColab is great. Colab is fantastic. Prototyping on Colab is a great idea. As we look at versioning and actually making it more usable, that's when we'll transition out. Colab works great for now, but thank you for clarifying. 18:30\\nKuba\\nLet me remove, so let me walk you through the code. First of all I imported the meetings transcript using planchain. So this is like the transcript. So I splitted it into chunks. So this is a chunk of it. 19:02\\nAlejo\\nWow. What are those? 19:06\\nKuba\\nJust the chunk of the data. So this is the total length after the trunk of the data. So I embedded it using open AI embedding. 19:17\\nAlejo\\nCool. 19:18\\nKuba\\nSo I imported into the panic on vector database. So this is the name of the index here.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 6 : page_content=\"So I just queried it. This is just a normal query like to just get the similarity search. So you just return the most very bad document. So this is it here. When I ask what type of agents can we create? So this is like the documents. So in this document I can indicate how many I want it, but I just listen to just. So now I want to pass the document into an LLM. Once you get the document you can answer my query better knowing the context. So I asked the question again, what type of agents can we create? It seems like the conversation is discussing creating agent for real estate or mortgage learning purposes. 20:18\\nKuba\\nThis is not clear specifically what type of agents they are referring to, but it can potentially be an automated agent. Sorry, an automated agent or a human agent. It is also mentioned that they are trying to reduce the amount of agents. Keep the process simple and programmatic. So this is just like for querying it continuously, like putting it in a. 20:46\\nAlejo\\nLoop at the very bottom. What's that output? 20:53\\nKuba\\nYeah, it's just like keeping it in a loop that I can keep on asking. Like chatting with it conversational. 21:07\\nAlejo\\nYes, but what is that result from? The meeting was about implementing automation services. 21:17\\nKuba\\nOkay, this is like from another question I asked actually. Okay, I'm going to show you. Let me run. 21:25\\nAlejo\\nSo you have great start, man. This is a great start. That's the one thing that's really annoying about Colab that you have to import upload the documents every single time. 21:54\\nKuba\\nYeah. 21:59\\nBartek\\nGuys, I thinking for the first version, for the MVP or proof of concept, I think we should list the most required functionalities we need. So I'm thinking definitely who is saying the stuff like participants. 22:18\\nAlejo\\nWe're doing that with fireflies. So we are going to have that.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 7 : page_content=\"Yeah. And if we can do it through zoom cloud, then it'll be even easier. So hold that thought and we will get to that point.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 8 : page_content=\"We'll talk about that too. 22:48\\nBartek\\nAnd one thing on the processing side, I'm thinking maybe we should use, I mean, it looks quite good over here, but the beginning of the transcript, weird. 23:00\\nAlejo\\nWords. 23:04\\nBartek\\nWe should have. Maybe. 23:09\\nKuba\\nThere are a lot of weird words in the document. 23:13\\nBartek\\nYeah, I'm thinking maybe we should have agent that corrects the words like extract the meaning. 23:25\\nAlejo\\nSo that is already built. I can show you. I want to go from big picture to small picture. And we can talk about the components and the subcomponents. And fixing the transcript is one of those subcomponents. All right, call out.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 9 : page_content=\"Cool. Let's see what it comes up with. I wonder how stochastic it is. Yeah, that's unfortunate.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 10 : page_content=\"What if you try it again? 24:04\\nBartek\\nWhat if you instead of agents say product? Because I think this was about the real estate how to say listing description generator. 24:19\\nAlejo\\nRight? 24:19\\nBartek\\nI saw it in the transcript. It was actually me talking about the first project of celebrities. So I think it's more of a product. Oh yeah. 24:37\\nAlejo\\nGo. There we go. 24:40\\nBartek\\nYou see, you need a prompt engineer. 24:44\\nAlejo\\nThat's where that comes in. 24:45\\nBartek\\nThe prompt registration. 24:51\\nAlejo\\nShould we. Wow, this is just. 24:59\\nKuba\\nLike imputing, like incrementing continuously. 25:05\\nAlejo\\nOkay, got you. Let's try. This call was about knowledge. Now could you ask what is the product called, how is it used about. 25:44\\nBartek\\nExtract and either eight project documentation. 25:49\\nKuba\\nExtract. Sorry, I didn't get that. 25:54\\nAlejo\\nExtract and ideate product documentation. 26:00\\nBartek\\nProject. 26:14\\nAlejo\\nI wonder how well it does with typos. Summary.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 11 : page_content=\"So this is just extracting and interpreting the chunks from. 26:28\\nKuba\\nThe vector store and the vector database. 26:31\\nAlejo\\nYeah. 26:34\\nKuba\\nWhat I need now is like using a prompt to guide its output. Instead I was just like typing just requesting. 26:51\\nBartek\\nWhen need sort of extractor agent, like extract first and then ask later for something. In this situation we'll have two agents. One is extracting the information required, or even better, we start from what's required for the documentation for this project, from this little extraction, and then another extraction agent knows basically more where we're going with it. So say extracting. Then the documentation agent tries to make the documentation but lacks context. So it goes back to the first agent, to the extractor, and give me more context on this and this. And then it's kind of a feedback loop in here. 27:35\\nAlejo\\nOkay. Yeah, totally.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 12 : page_content=\"So we're noticing a few things. We're noticing the quality of the extracted documents from pine cone varies in quality, which is normal. It's only one transcript and the transcript is not even clean, so that's normal. Number two, we're noticing that the output of the queries is limited to only the context that it is given from the low quality extraction of the chunks. So it doesn't have much to work with. What if the next step was giving it more context and using that context to actually create a proper answer? Yes. And then number three or number four is the prompt regeneration so that the query being asked can be regenerated, say, by PFA, based on the context of essentially who's asking. In this case, let's just say it's the normal quote unquote faster ICE is asking. So just answer, faster ICE. 28:58\\nAlejo\\nWho is faster ICE. Here's who faster ICE is. And we just feed the knowledge base of faster ICE. So there are some components there. Thank you, Kuba. This is a great start, man.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 13 : page_content=\"This is wonderful. I wanted to be able to visualize these components, so let's pause so we can keep going forward. So we talked about a lot of things last meeting, it was brainstorming session, and we're taking all these ideas and all these use cases and we're running with it. So let's make it a little more visual. Number one, the thing that we know for sure, which is at the end of a. Sorry, I'm trying to remove the captions. They're in the way. Okay, well, it is what it is. At the end of. 30:11\\nBartek\\nThe end of. 30:12\\nAlejo\\nThe day, what we need is answer. Sounds obvious, but how do we get.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 14 : page_content=\"So let's see. 30:30\\nBartek\\nI think we definitely need to let PFA into the wild. I'm actually tired of the GPT version now today. It's really.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 15 : page_content=\"I agree. Making me angry about this. 30:45\\nAlejo\\nGood, get angry. Create new from that anger. 30:50\\nBartek\\nLet's make it into the wild. Yeah, I'm thinking it will best if, for example, in this collab we would have PFA as a hint text. Can you imagine writing prompt and in real time it gets like autocompletion hint text kind of thing. How do we do that?\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 16 : page_content=\"31:14\\nAlejo\\nI like that. Okay, that's a whole different component. Let's figure out where that fits, because that probably fits here somewhere. 31:24\\nBartek\\nYeah, knowledge. 31:25\\nAlejo\\nNow let's start from the end of it, which is the answer. And I want to dig into this a little bit because, Bartek, you and I connected earlier today and we threw out some great brainstorming. I want to make sure that everybody's with us because we said some really interesting things that we could do with knowledge. Now we talked about a little more space. We talked about a bot that measures messages. You with your to dos say the call ends. We're in a dev meeting. At the end of this dev meeting, the objective for each of us is to have clarity on which of these tasks of this whole system that we're going to look at. We are tackling, it's a subcomponent of a component and we're going to make sure that we are each set up for success. 32:31\\nAlejo\\nWhat that looks like with knowledgenow in the future, with knowledgenow, is that right after the meeting we can get a list of to do's. It's like, hey, this is what you're working on and these are the subtasks that you have to.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 17 : page_content=\"Oh, right, okay. Yeah, thank you, Hubi. We'll get you the recording and we'll make sure that you have a clear task to work on. So at the end of the meeting, Hubi that now has to leave will get a list of tasks that he has to get done and maybe he's not super clear on what those tasks really mean. So you can message the bot to catch up on the meeting, get clarity on the meeting. That's kind of one use case in itself. So number one, great. Another use case is at a deaf meeting. We have a new project. 33:34\\nAlejo\\nWe're talking about knowledge. Now we figure out the objectives of knowledge. Now we figure out the use case, right? So let's say it's this first use case. We figure out the success criteria, that it actually messages each person after the meeting. That it's clear on the tasks, that the tasks are actually what we talked about, that they're assigned to the right person. So we set up the success criteria and we figure out the step by step. This whole thing that we're doing now is going to be that step by step. So all that knowledge exists in the meeting. After the meeting, there's already a prototype being built. So that might look like a documentation writer. A documentation writer. It might look like a project manager, multi agent, anybody. It might look like actual programmers. 34:39\\nBartek\\nLet's make digital twins. Of all the dev team partners of. 34:45\\nAlejo\\nAll the dev team. Hey, I am good at this, but I want to learn rag. 34:52\\nKuba\\nGreat. 34:52\\nAlejo\\nNow you have a Bartech digital partner that is an expert at Rag and can help you build those projects while guiding you through it. Because code, in the very near future we won't even need to write. But systems design is something that we need to keep honing in on Cuba. The fact with a personalized outreach system, the fact that were able to throw you a picture of the system that we wanted, and you were able to write the code to put each agent and how it would work together, what tools each agent would need. That is freaking awesome, man.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 18 : page_content=\"I believe that in the future. 35:41\\nKuba\\nThat'S. 35:42\\nAlejo\\nGoing to be a minor value added, which is huge value today, that the great value is going to be able to be in coming up with the system in the first place. So say we have a call and we come up with this system, and by the end of the meeting, there's already a prototype being built, there's already documentation written. The steps, the project manager figure out the steps because of the objective and the success criteria that we set up and the programmers are already working on it. Kuba, you wanted to add something? 36:25\\nKuba\\nNo, what I'm thinking is we can actually build all this. All I was watching videos on cool AI, and it's very cool. It can enable us to do this. That was saying like the documentation writer, the projects manager, the programmer, then we have like a supervisor for all of them. Supervisor is the one that will be assigning the rules when a query comes in. So the supervisor understands that. Okay, this message belongs to the documentation writer. Okay, let's say agent. Then this rule belongs to the project manager. Agent. It's just like routing h query to the right. 37:19\\nAlejo\\nSomething like perfect. Okay.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 19 : page_content=\"Yes. And that exactly fits in with what Bartek was mentioning of. Hey, we need somebody to kind of moderate and manage the conversation. Could you text what that service thing that you were looking at is called? 37:43\\nKuba\\nThe service Aws. Is that what I mean? 37:50\\nAlejo\\nI'm not familiar. Could you write it? You were watching something that does this? Did I capture that? 37:59\\nKuba\\nYeah, yeah, I was watching like a video. That's what I was saying.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 20 : page_content=\"Like a video on YouTube. You know this guy Matthew Berman now? 38:08\\nAlejo\\nNo. 38:12\\nKuba\\nHe'S like an AI influencer. He did a video about it, about the framework. 38:20\\nAlejo\\nOkay, cool. Could you post it in the chat and we'll definitely take a look? Yeah, thank you, man.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 21 : page_content=\"Great. And having other frameworks that we can get inspired by is a great idea. It's not a great idea. It's necessary to figure out what others have worked on and how we can make it better for ourselves. Another one that we threw out there is a scrum master assistant, which you can kind of call a project manager. It's a type of project management, but earlier, and we mentioned it last week, at the beginning of faster eyes, we had this sort of scrum format, and then it was really hard to keep up with because there were a lot of people and there were very few people. It was mostly like Henry and I and most dev calls. So this kind of fell off. 39:18\\nAlejo\\nBut if we can have this, and I wonder if this scrum master assistant mixes in with messaging you with your to Dos, you can ask the scrum master assistant for clarity on what your tasks are and the programmers on how to, and creating a draft for that task that then you can go and make better. So this all comes together really beautifully to work together as different components, different use cases working in harmony.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 22 : page_content=\"So we're coming up with these use cases. Okay, what are the steps to get there? We know a few things. We know that before the answer happens, we need a good evaluation of the answer. How close is this to a full, accurate, relevant answer? Is this an agent? Is this a second moderator that can then kick it back to supervisor? 40:36\\nAlejo\\nWe'll figure out how these components play together, but we definitely need an evaluation before we ever send any answer out. We're also talking about a supervisor agent. We can call it whatever we want. I'm going to put supervisor, moderator. Who is this supervisor moderating. What is that conversation that is being moderated and what information gets. We know the output, right? It's an evaluation. And the final answer, what is the input? Well, we have the knowledge base, and this knowledge base has information about all these things. We have real time Zoom call transcripts, close to real time. Every other transcript we have about who we are and what we do, knowing skills of each person and what each person wants to specialize in, like rag and knowledge of the project, et cetera. There's a bunch of things, clients, industry. 41:43\\nBartek\\nFocus. 41:46\\nAlejo\\nThat'S part of the input. We also have the initial prompt.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 23 : page_content=\"Okay. And now that we know the prompt leads to the knowledge base in what exact capacity? When is the repropting? Let's figure that out together.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 24 : page_content='So. 42:11\\nBartek\\nI think the PFA swarm framework is pretty reusable in here. We can have the input like you write a prompt, you make a type or whatever.' metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 25 : page_content=\"Later. We have like a context enrichment. So basically, just like PFA enhances your input, this can also enrich your input, and then it's kind of trying to get maybe using the fasterized knowledge base. Like, okay, see we are in fasterized right now. This guy asking me for this and this. Now I enrich this to be more relevant to pastorize the query itself. 42:57\\nAlejo\\nYes, exactly. 43:01\\nBartek\\nAnd then next thing we have is innovative angles. We not use that in here.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 26 : page_content=\"Next thing I need to come back to the diagram. I already don't have it on my whiteboard. So first time I'm going to look at the actual photos of the whiteboard. So let's get back there. 43:24\\nAlejo\\nWe are putting the output to be kind of enriched prompt. So I wonder if there's a knowledge base and then a base kind of system prompt about sort of very brief, like a paragraph about fasterize. Right. Because how do we make sure that if the prompt doesn't mention anything about AI, fasterize any projects, anything. This also has the context of what faster is. What is the global context? Maybe there's some component here of global context. 44:12\\nBartek\\nI think we need to have two separate knowledge base calls, let's say. So you would have first, before the transcript knowledge base comes in, need to be the fasterized knowledge base. And actually the knowledge base from transcript will be after enrichment. 44:34\\nAlejo\\nI think that's exactly what I was thinking. Okay.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 27 : page_content=\"I love how this is coming together. So we go from prompt to global context knowledge base. 44:49\\nBartek\\nActually, enrichment. Enrichment first, before you get to the global context, you need to fix the typos and enrich the input. 44:58\\nAlejo\\nOkay, got you. I wonder if it's because you're already. 45:02\\nBartek\\nQuerying the global context with this prompt that comes. 45:07\\nAlejo\\nYeah. So. So we put vanilla PFA to fix the prompt without other context. Maybe like slight context in its system. Prompt, vanilla PFA. The whole point is enrich fix. 45:28\\nBartek\\nActually the enrichment agent could be having the faster. 45:33\\nAlejo\\nRight. 45:33\\nBartek\\nKnowledge base in the enrichment agent knowledge. 45:41\\nAlejo\\nOkay, question. When we're talking this component from the initial prompt, are we already talking multi agent? 45:51\\nBartek\\nI guess. 45:53\\nAlejo\\nOkay, we'll put a maybe in there. Maybe already multi agent wondering if we need to do the heavy lifting without even putting the global context in already. But that's minor. 46:11\\nBartek\\nActually, it's even better when we have multi agent system from the start. And then this enrichment is an agent. An agent can have its own knowledge base and that could be the global context because actually I doubt thing now the enrichment without the context I don't think will be good enrichment. So the enrichment agent already needs to know the pasteurized thing. 46:32\\nAlejo\\nWell, I mean, your fagpt without any context is pretty freaking good. Like excellent.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 28 : page_content=\"Yeah. 46:41\\nBartek\\nBut if it knows where we're going and from where we're coming from, actually the fasterized knowledge base. Okay.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 29 : page_content=\"I think it will enrich even better. 46:51\\nAlejo\\nOkay, so then would this step be redundant because we're going from prompt to add global context into PFA? It's not a rhetorical question. 47:08\\nBartek\\nI think the global context has to. 47:10\\nAlejo\\nBe. 47:13\\nBartek\\nIn the context of context enrichment. The context enrichment agent has to have the context to enrich from. It's kind of like meta enrichment. 47:26\\nAlejo\\nYeah, no, I'm with you. I'm with you on that one. Okay, so the PFA specifically, we're talking about the context enrichment agent with general knowledge of general context. General context. So that's my question here. And then we throw that into the global context knowledge base. 47:52\\nBartek\\nNo, actually this global context gets merged into the first step as a knowledge base. So we don't have a separate call later in the air. We don't calling the knowledge base by itself. We're calling it through the context management agent. 48:13\\nAlejo\\nOkay, something like this then. 48:18\\nBartek\\nYeah, I guess we can have it like that. 48:24\\nAlejo\\nAnd this is a draft. It has lots of room for improvement.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 30 : page_content=\"But yeah, this makes sense. There's a simple not well written prompt. We have global context and PFA. The heavy lifting in this case is done by the context and reinstrument agent with the general context fixes and enriches the prompt. Maybe it's already multi agent, maybe it's one.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 31 : page_content=\"Good. Well, it's PFA, so yes, multi agent. Great.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 32 : page_content=\"Wonderful. 48:57\\nBartek\\nNext step will be extractor agent. 49:03\\nAlejo\\nIs that within this component? Because this component. 49:07\\nBartek\\nNo, it's next step. 49:09\\nAlejo\\nOkay. 49:17\\nBartek\\nActually I'm looking at the diagram for the PFA swarm, but we're going to. 49:21\\nAlejo\\nHave diagram next time. 49:27\\nBartek\\nYeah, I don't know if you will be able to see that. 49:34\\nAlejo\\nCool. I love learning. 49:38\\nBartek\\nI don't know if you can read that. 49:40\\nAlejo\\nI cannot. It's the context. 49:44\\nBartek\\nAnd then maybe I'll just share with. 49:46\\nAlejo\\nThe image later if we can get something kind of in the figma board. Maybe just throwing the word. 49:56\\nBartek\\nMaybe I will draw this again because this is kind of mess in here. I had it on my whiteboard for a few days and I was just adding stuff on top. So I will redraw this from scratch. 50:10\\nAlejo\\nAwesome. Yeah. Even just getting like a general idea of what the swarm is going to be like. Because we know what PFA is and we know what swarms are. 50:20\\nBartek\\nRight. 50:21\\nAlejo\\nWe get the general idea. Okay. So there is now an enriched prompt that comes from the initial prompt and the global context PFA creates that enriched prompt. What happens next? You mentioned a extractor agent. 50:42\\nBartek\\nAn extractor agent has the transcript as a knowledge base. 50:48\\nAlejo\\nHas transcript. So it has the full knowledge base. 50:54\\nBartek\\nYeah. 50:55\\nAlejo\\nOkay. 50:57\\nBartek\\nSo we kind of shift the usual way of calling the knowledge base. We have like every agent has the knowledge base, right? I mean, maybe not every, but these two agents have a knowledge base and he would be extracting from his knowledge through the prompt that we enriched before. 51:19\\nAlejo\\nSo this prompt gets passed as a rag query into the knowledge base. Is that what you're saying? 51:28\\nBartek\\nIt's passed to the extractor agent. Then extractor agent gets to the rival. 51:40\\nAlejo\\nOkay, I think I'm following now. So the extractor agent will intake the enriched prompt and make it a query adapted for rag. Optimized for rag. Yeah. Okay, cool. So the output of this is query optimized for rag, which as we know is not actually. 52:11\\nBartek\\nWait, we have that already. This is the output of the first agent. Well, the query optimized, I think that's. 52:22\\nAlejo\\nKind of a question because this prompt is going to be like, tell me about the real estate project. Then we add the global context into that. And then this enriched prompt, this outfocus, just on the output would have, tell me about the real estate project. This is kind of like what I'm interested about it. Be very explicit about the step by step, be clear about what the client wants. Takataka.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 33 : page_content=\"Takataka. So the enriched prompt based on that global context, based on the initial prompt and the PFA extractor agent may or may not have to do multiple calls to get. 53:30\\nBartek\\nThat's where we're going. 53:32\\nAlejo\\nMultiple queries to the knowledge base in order to actually extract all the components that the enriched prompt is talking about. 53:41\\nBartek\\nSo we're kind of going like, Gemini produces three outputs and lets you choose. 53:47\\nAlejo\\nYeah. 53:52\\nBartek\\nNext we have agent that chooses the best version of the output of those queries. 54:01\\nAlejo\\nSo then with all that. So the PFA extractor agent is going to come up with multiple queries. Multiple queries optimized for rag. We call the knowledge base with each of those queries and the output of that. Man, this is fun. 54:33\\nBartek\\nIt goes to the supervisor now. And then we have a feedback loop. 54:37\\nAlejo\\nYou mentioned something different, which was, we need an evaluation of all that data, all the answers of the queries. And I just want to make sure that we're on the same page, that the supervisor will lead the free for all conversation where now agents are just talking with each other and the supervisor decides what is relevant for it. Yeah.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 34 : page_content=\"Okay, cool. 55:02\\nBartek\\nAll right. So now it's evaluator. 55:04\\nAlejo\\nSo it's the evaluator agent which will evaluate the quality, relevance, et cetera, of all the outputs of each kind of sub query to the vector database. And the output is going to be output.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 35 : page_content=\"Let's keep it simple for now.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 36 : page_content=\"These are the most relevant. 55:52\\nBartek\\nCan also add a scoring in there, like from one to ten. 55:56\\nAlejo\\nYes, score one to ten and we can start with top three. So let's say that ten chunks are extracted for each query out of the vector database and we do top five out of those. Top ten. Based on what? Well, the input is going to be. Input is going to be the. 56:29\\nBartek\\nEnriched prompt. 56:31\\nAlejo\\nYeah. The global context. It's going to be all the queries each query. Let's call it sub query or rag query. Yeah, let's do that. Rag query. Each rag query and the global context. Maybe there's some other stuff in there, but that's good for now. 56:58\\nBartek\\nI'm thinking if we should add transcript in this one or there should be like separate agent that is focusing on rereading the transcript to kind of check the evaluator or if the evaluator should also do that. But I think that will be too much job for evaluator. We also pass the transcript. We need to think about the context window here. 57:22\\nAlejo\\nYeah, that's where it starts getting interesting and let's experiment. That's where I say, let's see how many tokens we can spend. And then when we get the best output, we can, we reduce, we simplify. Yeah. So, yes, to all your ideas, let's have a kind of, I'm not going to get too meta, but kind of an evaluator to the evaluator. So let's let the supervisor in now to say what is needed from here. 58:04\\nBartek\\nMaybe we can also add like transcript. I'm thinking like kind of code review to the evaluator, but it's a transcript review. So transcript review agent. 58:22\\nAlejo\\nSo this is kind of a tester. 58:26\\nBartek\\nYeah, it brings back the whole transcript and slashes that with the evaluator output. 58:36\\nAlejo\\nYeah. 58:37\\nBartek\\nAnd kind of make a semantic check on the evaluator. 58:46\\nAlejo\\nKind of semantic quality check on the evaluator. Cool. So as we are testing the system, this will definitely be necessary because what if the evaluator is the one that's wrong? 59:01\\nBartek\\nRight? 59:02\\nAlejo\\nWhat if the evaluator is the one that. So part of the input that this transcript reviewer is going to need is kind of its own examples. Here's the whole transcript, here's the query, here are the relevant chunks and we can kind of give its own few shot prompting. I'm not going to call it knowledge base right now because we have way too many knowledge bases to keep track. 59:35\\nBartek\\nOf, but few shot prompt. Yeah, but that's good. I mean like every agent should have a knowledge base and every knowledge base should be different. 59:43\\nAlejo\\nYes, I agree with you. Let's keep Fusot prompt for now and. 59:49\\nBartek\\nWe can go from there. 59:50\\nAlejo\\nFusion prompt of query plus transcript plus relevant chunks plus score from one to ten. So tester of QA agent transcript. There you go, QA agent, which we'll do like a check on the evaluator agent. Okay, I'm going to pause now because I want to be considerate to all the other human being in this conversation because I feel like we're robots right now. Kuba, what clarity, what questions. Maybe everything's clear, but I know sometimes. 01:01:04\\nKuba\\nI go often, to be honest, I enjoyed the conversation. I like the way you guys think. This is like a new picture to the entire system. So I understand. I just need to go over the stigma body again to understand it. 01:01:24\\nAlejo\\nWell, cool.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 37 : page_content=\"Awesome. Well, if you have any questions, there's the chat, whatever comes to mind, ideas, feel free to pitch in. Okay. 01:01:39\\nBartek\\nRefinement loops, definitely in the evaluator to. 01:01:43\\nAlejo\\nThe extractor, my mind. So before you go into that, Kuba, you asked me the other day, what's the thought process for these icebreakers for the personalized outreach system? And I mentioned this reinforcement learning with human feedback, or at least trying to emulate that self refinement getting better over time. And this very much we want to go in that direction with this. So that's where the QA agents might come in too, right? How do we make sure that this system gets refined over time, that it doesn't hit a ceiling. 01:02:27\\nBartek\\nOr at least. 01:02:28\\nAlejo\\nDelay the ceiling as long as possible? So you're talking self refinement, which sounds like a branch from the QA agent, may or may not. 01:02:45\\nBartek\\nThe evaluator agent, an evaluator agent into the extractor agent. And also I'm thinking like this is refinement on the process one time. But I'm thinking we could also have agents that if the refinement happens, so the initial output was somewhat wrong because maybe not always could be wrong, maybe sometimes it will just go fine. 01:03:09\\nAlejo\\nRight? 01:03:09\\nBartek\\nAnd the evaluator has nothing to say. QA agent has nothing to say. But if they have something to say, we should save that and have agent that keeps track of the refinements that happened and use that as later maybe knowledge base. Oh fuck yeah, dude, let's go. 01:03:29\\nAlejo\\nOkay, that sounds like we're wondering like hey, where does the supervisor get into the conversation you just mentioned? Sometimes there might be like space for the self refinement agent, for the Q agent, and we might need to go back or reroute the conversation. So now we know a point where we want a supervisor to say hey, who's next? And it will have obviously knowledge of each agent, what they do, maybe a summary of their system QA. 01:04:11\\nBartek\\nThe QA agent needs to also report the supervisor agent like the evaluator agent do. And then supervisor makes the refinement loop. 01:04:23\\nAlejo\\nAnd now the supervisor. And now we start routing. Okay, we run out of figma board. We have the evaluator agent, then the QA agent. 01:04:46\\nBartek\\nSo we can go either to the evaluation or to the extraction from supervisor. 01:04:52\\nAlejo\\nNow. So we have PFA extractor which creates multiple queries optimized for rag. Then we have the knowledge which goes to parts of extraction from the knowledge base. We have the evaluation of that answer. What are the most relevant chunks then QA agent. We haven't defined yet what we do with these chunks. Trying to answer the prompt, right? So if we don't forget about what the user is asking, we're trying to answer the prompt. We now have the most relevant chunks to answer the prompt. At least we think we do. We pass it through the QA agent and we confirm yes, we have the most relevant chunks. Are we ready to answer the query? No.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 38 : page_content=\"What is missing? 01:05:57\\nBartek\\nSo we need like aggregator agent that, wait, aggregator agent or something else. We just need to now get these things that come out of the evaluator or QA agent. 01:06:17\\nAlejo\\nAnd have a path. 01:06:18\\nBartek\\nDownwards I guess to the, something should happen before the answer is now. And now we have evaluator that has scored the outputs and now those best scored we need like a merger agent. 01:06:36\\nAlejo\\nI think that will take the go ahead. 01:06:40\\nBartek\\nThe merger agent could take the best scoring from the evaluator, best scoring answers and then analyze them. Let's say there is the best chunk, but in the second best and the third best chunk there is also some stuff that is not in the first chunk. You get me? So the manager agent take the best pieces out of the say three most scored chunks and takes the best pieces into the answer. 01:07:18\\nAlejo\\nYes. So take the best chunks from evaluator agent and create a full answer for each rag query, basically submerging the best. 01:07:28\\nBartek\\nPieces now merging the best pieces. It's good now. No, it was good. You just add it at the, yeah, you take the best chunks and then for each rack query you merge the best pieces from those chunks. 01:07:48\\nAlejo\\nBest pieces from each chunk. We will work on the wording later because we are following.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 39 : page_content='Okay. The merger agent takes the best chunks from the evaluator agent and creates a full answer for each rag query by merging the best pieces from each chunk. Okay. And merge the best pieces from each chunk to create a full answer for each rack query. Yes.' metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 40 : page_content=\"Awesome. We're going to put the self refinement agent somewhere around here and we're going to start creating the routing function, essentially, which is most likely literally a function call with the input being which agent is next, if that makes sense. Kind of like the tool is function calling for routing to most relevant next agent. To continue the conversation.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 41 : page_content=\"Okay. 01:09:16\\nBartek\\nI think that the supervisor is actually making those loops back to where it was the mistake, but the self refinement agent, it's more of like, I would say it's like a self refinement bookkeeper. So the one that keeps track of the refinements that happened and puts them in a knowledge base so we can have, this is where the self learning happens. Self learning knowledge base is happening right here. 01:09:48\\nAlejo\\nOkay. So a supervisor could fulfill that role, technically could fulfill that role because he is keeping track of everything. He is tasked with being like the bright mind that can put all the pieces together and know who to call and kind of know what's missing. At the same time, the supervisor only knows what it knows. It's not necessarily there to judge what it was given. It's tasked with, take what it's given and run with it. It's like what's next, not what could have been better. So the supervisor says, hey, maybe there was room for improvement here. That's when the self refinement agent might create a kind of full evaluation of everything up till now and kind of find the blind spots which agent it was where the process went astray went wrong. 01:11:15\\nBartek\\nYeah. Now this agent will have a kind of bookkeeper agent that's kind of working after the self refinement happens, it gets noted to the bookkeeper agent, which then keeps track of all the refinements that happen. 01:11:32\\nAlejo\\nSo then we would function more than another agent. It's like it could call the function of bookkeeping. 01:11:42\\nBartek\\nOh, yeah. If refinement happens, then call the function to save the refinement process that happened. 01:11:50\\nAlejo\\nIf refinement happens, keep a log of full combo into what was wrong, evaluation of what was wrong, into improvements suggested, and at the very least, for now, let's not let the conversation just loop back. Let's just keep a log and that's going to be great. Training data to know what might need refinement as opposed to creating a crazy loop of agents that might end up no one knowing where to go next or like a feedback loop of bad data. So bookkeeping function, great. 01:12:53\\nBartek\\nI think that supervisor role is to know what to do next from there. 01:12:59\\nAlejo\\nActually, yeah, that's the function routing to most relevant next agent. Yeah, you mean from the self refinement agent? 01:13:09\\nBartek\\nYeah. So the self refinement make decision what to refine and then supervisor makes a loop to that agent that needs to be refined. Okay. 01:13:21\\nAlejo\\nThrough all this we have to figure out, you talked about low hanging fruits, we have to figure out what's like. 01:13:27\\nBartek\\nPriority because that's the big picture now. 01:13:32\\nAlejo\\nAnd this is great, you guys, this is truly going to be the future. Okay, so we know, let's assume that no refinement is needed. What we do know that we need is now a merger agent to take the best chunks from evaluator and merge the best species from each chunk to create a full answer for each rag query. Now that we have a full answer for those sub queries, we need to actually answer the prompt answer formatting agent. Okay, this is where if you talk. 01:14:23\\nBartek\\nIn one prompt, this is the output format. 01:14:27\\nAlejo\\nYes. 01:14:28\\nBartek\\nAnd then from the merge chunks from the merger agent, it will have a structured output. 01:14:39\\nAlejo\\nI see your mic going on Kuba, if you want to jump in, feel free. Okay, so we have answer formatting agent, but we're running out of figma space. Again, this is great. Okay, so what happens before the final evaluation of the answer? Well, there's answer formatting agent and in between evaluating the answer and deciding how the answer is going to be formatted, there's answer agent. So somebody that actually creates the final answer. 01:15:32\\nBartek\\nI found blind spot in all of this because the final answer is bot messages you with to do we need a knowledge base with the competency metrics or something like that? Like at least information about who is in the team. 01:15:49\\nAlejo\\nAt very least that's part of it. Knowing skills of each person and what they want to specialize in matrix. Good catch, man. 01:16:01\\nBartek\\nBut yeah, I think that it should be at the end rather than in here. 01:16:07\\nAlejo\\nSo for each different use case, this is something great, this is a great point you're bringing in. It's like, hey, what's the actual use case? But this is not the answer agent. This is the formatting agent. What's the actual use case. What other info might be needed? But then is this, what other info might be needed? The answer formatting or the supervisor. 01:16:49\\nBartek\\nOr sort of like team manager agent that we are getting the answer, but now we need to actually choose who going to do what from this answer we got. 01:17:06\\nAlejo\\nOkay. So we could subdivide this supervisor into other sub agents, like an HR agent. 01:17:15\\nBartek\\nOr team lead agent. 01:17:20\\nAlejo\\nYeah. It would feel slightly redundant to this supervisor because they can have that ability. Yeah. 01:17:32\\nBartek\\nI'm just thinking if it wouldn't be too much for one agent, but let's talk MVP and maybe it will work. 01:17:38\\nAlejo\\nOkay. Yeah, it's 02:20 a.m. For me already. But we're in a roll. We're in a roll. And then decide which agent comes next. Right off the bat is keeping track of the conversation, identify what info might be needed and then decide which agent comes next. Doesn't feel like too much.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 42 : page_content=\"There's going to be other things that we add on top. 01:18:08\\nBartek\\nAlso assign team members. 01:18:10\\nAlejo\\nAssign team members. So what's the actual use case?\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 43 : page_content='For example, E. G, for the to do task use case, we would need to check relevant skills. Assign team members. We would need to.' metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 44 : page_content=\"What else? 01:18:43\\nBartek\\nDecompose tasks. 01:18:46\\nAlejo\\nDecompose tasks? Yes, decompose projects into components. Into tasks. 01:19:02\\nBartek\\nAssign deadlines. 01:19:05\\nAlejo\\nAssign deadlines. Which ideally we're saying out loud during the call. 01:19:16\\nBartek\\nIt'S like deadline for the whole project. Right. We talk on the call, but there is another deadline for the tasks and for the components, right? 01:19:27\\nAlejo\\nYes. We then have to figure out over time how much autonomy do we want to give it, even if the output is perfect, the nuances of humans and hey, I'm actually quite swamped this week and I'm only now learning rag. So how big of a deadline, how long of a deadline or how big of a task can I really take on? Let's keep that human for now. And the scrum assistant can help with the evaluation, sort of the analysis, evaluation of all of that. 01:20:18\\nBartek\\nYeah. We could also have at some point availability checker, something like that. So checks tasks already assigned to the person. 01:20:33\\nAlejo\\nYeah. So like, checks tasks already assigned. So we need project manager management tool to keep track of this, which is likely going to be notion. So we're actually already migrating a lot of stuff to notion and we can then automate the project manager within notion. Check tasks already assigned, deliverables missed and delivered, missed. And it can help sort of adapt like, oh, well, maybe this person is overloaded right now and kind of like checks capacity and then assigns. 01:21:29\\nBartek\\nThis is already fault three we're talking. But that could also be like contribution calculator or whatever. 01:21:41\\nAlejo\\nYeah, contribution calculator. And I actually found a great template to do that. It's an airtable template where you can create a project and then keep progress logging. Yes, absolutely. And maybe even that can be filled automatically during the call live. That'd be cool. Kind of like project automated auto project logging, progress logging. 01:22:32\\nBartek\\nOkay, and after that we have like a UI thing going on. After the answer we are stepping out of this agent. Now we have UI, so either yes or no. For V one, for example, you get the to do list from this and then you have option to say like. 01:22:52\\nAlejo\\nYes or no, yes or no, like. 01:22:57\\nBartek\\nIf you take the task or you don't take the task because you get assigned to something. AI already checked. You can do this, but now it's human decision if you want to do see? 01:23:09\\nAlejo\\nI see, yep. 01:23:17\\nBartek\\nNow we're getting to the human, to. 01:23:19\\nAlejo\\nThe UI confirm task. 01:23:23\\nBartek\\nI think that should be like separate card because we are stepping out of this is not AI anymore. We are going to the UI, to the human. So that should be like another card. 01:23:37\\nAlejo\\nI think so. These are use cases. Each of these subcomponents may or may not contain AI. I want to just make sure that we're not now dividing the use cases into what we'll need, just so we can refer back to these and look at the whole use case as a whole. It's going to be very important to be very clear and almost like simplify use cases so we know what the success criteria is of each use case. Yes. Now knowledgenow completes this to do task successfully and we don't have such large variations of branches of the use case itself. So I'm putting here confirm task assignment. We'll figure out how that works and where that fits in. 01:24:37\\nBartek\\nRight. So. 01:24:42\\nAlejo\\nLet'S look at it backwards so we get the final answer. Hey, these are your to dos based on the project, based on the deliveries that you have, the capacity that you have. This is what has been assigned to you. Do you accept these? Which ones do you accept or do you want to review this? Yes, I accept. Contribution calculator comes later. You can message bot to catch up on meetings and get clarity on assignments. Which was the first low hanging fruit that we identified even as a subcomponent of this. We asked about this, right? What are the low hanging fruits? 01:25:33\\nBartek\\nOkay, I think what we should do now because we have this high level thing and now we should maybe go backwards like you say, and mark the things that are required for the minimal version. 01:25:45\\nAlejo\\nYeah. 01:25:48\\nBartek\\nLet's have this green sticker. Where is things required? 01:25:54\\nAlejo\\nOkay, cool. So we know that the actual output is required and we'll just tag like MVP. That's a little too small. MVP. Bam. Evaluation. We're going to be doing manual evaluation. 01:26:17\\nBartek\\nYeah, I think all evaluations can go to the V two. 01:26:21\\nAlejo\\nYeah.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 45 : page_content=\"Answer. Obviously we need answer. It feels like depending on the use case. Well, we're going to start with one use case. So the format is already going to be set. Maybe we don't need an agent to come up with a format to give summaries of meetings that is already set. Then we have merger agent. 01:26:50\\nBartek\\nWe are doing agent comes from evaluation. 01:26:54\\nAlejo\\nSo no supervisor, I think supervisor. Yeah. We ended up not having any branches. This is all sequential. The only branch is the self refinement agents, which is probably not the MVP. 01:27:19\\nBartek\\nSo. 01:27:23\\nAlejo\\nI'm sure that a free for all conversation is going to be important, especially for coding tasks. So does this task require multiple agents having an open conversation. 01:27:48\\nBartek\\nFor example. But we are talking like a board of the company. Like this is the board. And then later, if we have some tasks like coding and stuff, we would have another kind of system or swarm. That is the worker agents. Yeah, I don't think the programmers are in this diagram. This should be like another diagram of the worker agents because this is high level. Like a board. Like a seaboard. This thing we just built is like a seaboard. 01:28:22\\nAlejo\\nSo kind of like, well, I'm just leaving at programming team. So programmer, tester, whatever, which for coding tasks we would need to route to here. You've definitely been watching the has framework. When you throw out the word. This is the board. The supreme oversight board. Yeah, no, it's a great concept. It's a very well developed concept. So yes, supervisor, moderator board. So these in itself could be a multi agent system because alignment, again, is probably the hardest problem in all of AI. So is this really a single agent question for not the MVP? Okay, we have the evaluator agent, which grabs the relevant chunks for each query. So we need an agent to grab those relevant chunks to grab chunks, period. So that's the extractor. 01:29:33\\nAlejo\\nSo we need an extractor which will break down a prompt into break down prompt into multiple queries optimized for rag. I think we have something in our hands with you guys.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 46 : page_content=\"And then, well, the knowledge base will need it, which is not trivial. And then finally we need context enrichment. So we need global context and this is human input. 01:30:15\\nKuba\\nGuys, I have to bounce. 01:30:17\\nAlejo\\nOkay, we're pretty much done, so thank you for sticking through it. Kuba, great to have you here. 01:30:28\\nKuba\\nThe prompt engineering resources that I told you about. 01:30:33\\nAlejo\\nYes, thank you for reminding me. Bartek. Kuba asked about some prompt engineering resources to sort of keep learning, keep getting better. I think it'll be good for all of us to sharpen our prompt engineering skills. Would you share some intermediate into advanced resources with Kuba? 01:31:00\\nBartek\\nI already shared at some point the documentations. 01:31:04\\nAlejo\\nDocumentation. Right, right. 01:31:06\\nBartek\\nAnd the OpenAI guide. That's the thing for me.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 47 : page_content=\"This is very beginner stuff. So if you talk intermediate, I would recommend reading markdown syntax and getting familiar with all the markdown things can. All the things markdown can do. Because that's actually how before going to latent space, because I'm referring to how I upgraded PFA because field version of PFA is already the documentation level stuff. But then the next version, like the PFA overseer was about, I was reading the markdown syntax and I was thinking, okay, I have this markdown syntax. I know Markdown is using the prompts. How do I use all those things markdown have? Because Markdown have quite a lot of things you can do with Markdown. So getting familiar with Markdown, I would recommend. Definitely.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 48 : page_content=\"And then later I would recommend for more advanced stuff. 01:32:02\\nBartek\\nGetting familiar with the latent space activation. 01:32:05\\nAlejo\\nOkay, cool. Like sparse representation and all that stuff. 01:32:14\\nBartek\\nYeah. Also there is actually the latent space activation function written by David Shapiro, so that you can also find it on his GitHub. Also on my GitHub, you can find it's still not finished, but I've been doing a Vicky for PFA. And in this Vicky, I have a little bit like two kind of little articles about latent space activation from my point of view and from point of view on property engineering. So how to use latent space in writing? Persona for the AI for the sale. You make an agent and you want a Persona, and you want this Persona to be with the latent space activation included. So you can read about this at my GitHub. 01:33:02\\nAlejo\\nOkay, I will share the latent space activation video with. 01:33:12\\nBartek\\nShapiro. Okay, cool. 01:33:14\\nAlejo\\nSo, Kuba, I'm sending you two resources to start, and let's evaluate from there, if you need, where you feel like you want to go from there, if more into the very specific and advanced Personas, et cetera. 01:33:33\\nKuba\\nAll right, thank you, guys. Thank you, Batik. 01:33:37\\nAlejo\\nYeah, I'll see you soon, and we'll talk about the personalized outreach system. I went in a bit of a rabbit hole of evaluating which LLM is best at refactoring a whole big project into a proper repo that we can actually maintain. So all these different files and all that stuff.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 49 : page_content=\"But I will add that to you by tomorrow. 01:34:05\\nKuba\\nAll right, no problem going with your stuff. 01:34:08\\nAlejo\\nI'll send you some more documents and we can with a bigger knowledge base. 01:34:13\\nKuba\\nAll right, guys. 01:34:15\\nBartek\\nGood job, brother. Yeah. 01:34:21\\nAlejo\\nPrompt engineer. 01:34:22\\nBartek\\nAll right, so we've got like 1234 agents for the MVP. 01:34:34\\nAlejo\\nWe have to figure out the use case. There's the answer. Agent one, evaluator, extractor four. 01:34:46\\nBartek\\nAll right, but the problem is that the first agent is a swarm itself. 01:34:54\\nAlejo\\nSure.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 50 : page_content=\"It need not be. Remember, you have built an amazing product just by itself, and we're going to make it even better.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 51 : page_content=\"Dude. 01:35:11\\nBartek\\nI'm striving to make it like, don't make a mistake, because now, because of the randomness, you cannot control in the GPT because you cannot even set the temperature. I'm not even talking about the other parameters, but you cannot even set the temperature. So that's why it's so random. And that's why sometimes the prompt is just like one line. I hate it.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 52 : page_content=\"01:35:35\\nAlejo\\nSo this is what I'm going to need from you. I need you to pat yourself on the back for creating an amazing product that we are going to put in a whole different category of amazing once it's multiagent. And right now, we really need to focus on creating the bigger product because again, that's one amazing, but just one component of the whole system. And I am absolutely sure that through these testings, through these. Hey, now create, break down this enriched prompt into multiple queries optimized for rag. You're going to find new things to make better, not from this 8000 character prompt, but how to actually make it into these multiple agents. And then we'll step into that. 01:36:38\\nAlejo\\nSo let's give it a little bit more freedom by taking it out of the chat OpenAI context window and limitations and putting it into a new environment where it can be a little more free and we'll see what it does. 01:36:59\\nBartek\\nYeah, actually, I already drafted the prompts for, like, context agent. There is like, wait, there's context agent. There is the PM agent. Like a Pmidation agent. 01:37:13\\nAlejo\\nI'm going to write this down. 01:37:14\\nBartek\\nThis is the context. 01:37:15\\nAlejo\\nContext agent. 01:37:18\\nBartek\\nThen there is the pmidiation agent. Iteration, iteration, like ideation. 01:37:28\\nAlejo\\nAnd then there is ideation agent. 01:37:31\\nBartek\\nYeah. And this ideation agent is like technic choice, fusion structure and latent space activation. 01:37:42\\nAlejo\\nFusion, latent space and what else? 01:37:46\\nBartek\\nTechnic choice. Like a prompt. Technic choice. 01:37:51\\nAlejo\\nOh yeah. Fuck yeah.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 53 : page_content=\"I love that. So it'll know if it'll go like tree of thoughts or chain of reasoning. That's cool, man. 01:38:01\\nBartek\\nThat's such a good idea. 01:38:03\\nAlejo\\nI love that. I've had that in my brain for so long. I love that. Okay, awesome. 01:38:11\\nBartek\\nAnd it's been on my whiteboard for quite a long time. 01:38:15\\nAlejo\\nThat's cool. 01:38:17\\nBartek\\nAnd then later is the generation agent. 01:38:20\\nAlejo\\nThe what? Generation. 01:38:22\\nBartek\\nGeneration agent. The actual generation of the prompt. 01:38:25\\nAlejo\\nOkay. 01:38:26\\nBartek\\nAnd that's where I'm at currently. But the ideation PM agent is still work in progress. So I finished the context and I finished the generation because that was basically had before. I just had to take that out to the one, to the separate prompt. So that's why in my vs code is the current state of the PFA swarm. Later on there will be obviously after generation there is evaluation and there the iterator. 01:38:55\\nAlejo\\nOkay. And what we need to do progress. And what we need to do is knowledge. Now wait, Tor, remember this, we are checking which agents we've yet to build. And these are going to be the tests of this whole system. 01:39:16\\nBartek\\nRight. 01:39:16\\nAlejo\\nSo we're calling knowledge now. I love this.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 54 : page_content=\"Okay. Evaluator agent. 01:39:23\\nBartek\\nYes. And then iterator agent. 01:39:25\\nAlejo\\nIterator agent. 01:39:28\\nBartek\\nThen I have still cloudy talk. 01:39:33\\nAlejo\\nExtractor agent, or we've yet to build. We need to break down a prompt into multiple queries optimized for rag. 01:39:41\\nBartek\\nYeah. So that's also to do. 01:39:44\\nAlejo\\nOkay. 01:39:45\\nBartek\\nExtractorate, because that's not part of the PFA swarm itself, it's just part of the knowledge. 01:39:50\\nAlejo\\nRight, right, exactly. Okay. 01:39:57\\nBartek\\nAnd then also I got an idea. This is like a very raw idea. Like after the iterator, if you can see that after the iterator, there is prompt levels. Upgrade, swarm. I'm thinking like upgrading of the prompt will be another swarm upgrade. I still don't have that laid out completely because for V One there will be the iterator agent doing the upgrades. But what I'm thinking later, after iterator make a fish upgrade, we can have levels of upgrades like level one, upgrade Markdown, level two, upgrade complexity. Level three, upgrade latent space activation. 01:40:44\\nAlejo\\nSo that is what I would love us to have as a testing framework of the PFA system. Like talking about that. We can integrate here, of course, but as a whole different system, these multi agents. And have the testers be kind of like what you showed in promptful, but on steroids, of course, evaluation and leveling up. So is that what we're doing for MVP? 01:41:23\\nBartek\\nNo, that's for like, that's poultry or something. 01:41:26\\nAlejo\\nOkay, so I'm then going to put this in green and it's MVP. Yeah.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 55 : page_content=\"Okay. 01:41:37\\nBartek\\nAnd then we will have like a testing upgrades form for later testing. 01:41:46\\nAlejo\\nUpgradeswarm. And that's going to be V two.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 56 : page_content='Okay. No, the other way around. V two is going to be testing an upgrade swarm with levels E. G. One, markdown two. What would level two be? 01:42:15\\nBartek\\nComplexity or like details. 01:42:18\\nAlejo\\nDetails. Three, accurate context capture. Okay.' metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 57 : page_content=\"Anyway. Oh yeah. Actually run on the environment. Actually run the code and we'll figure this one out later. This is not V one, the programming team. 01:42:49\\nBartek\\nSo. 01:42:52\\nAlejo\\nInput we have. So what do we need to do? We need to do the for agents. This is what we need to do. And then for other stuff we need global context. We need knowledge base. 01:43:20\\nBartek\\nNo, I got to beard back 1 minute. 01:43:23\\nAlejo\\nYeah, we need answer agent. And I'm glad we budgeted $800 for fast rice. This is going to get fun. Make a message bot to catch up on meetings, declaring assignments. It discord.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 58 : page_content='Discord. Right.' metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 59 : page_content=\"Amak. 01:44:48\\nBartek\\nLet'S sum up what prompts we need for those agents. So prepare those prompts for the MVP of the knowledge now. 01:45:07\\nAlejo\\nOne sec. And then answer agent. And then for other stuff is the global context, the actual knowledge base which I'm working on. And then the discord bot web. Love it.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 60 : page_content=\"This is looking so nice. Prompts. 01:45:43\\nBartek\\nWe have four agents. The context enrichment is like 90 or 80% done because I had it done for PFA. So I would just tweak it a little bit for the knowledge now. So it's enriching in the transcript case rather than prompting case. 01:46:03\\nAlejo\\nYeah. 01:46:05\\nBartek\\nLater we have the query agent, direct query agent. 01:46:18\\nAlejo\\nWhich is the rag extractor. 01:46:22\\nBartek\\nYeah. 01:46:25\\nAlejo\\nAha. 01:46:30\\nBartek\\nThen we have evaluation in V one. 01:46:36\\nAlejo\\nThe evaluator agent that will actually. So the rag query extractor agent. The rag query agent will create the queries from the prompt. And then the evaluator agent will say, these are the best chunks from that. Extract from that cosine, similar. 01:47:02\\nBartek\\nBut the iterator agent is for. 01:47:06\\nAlejo\\nOh, you mentioned for V one that would be V two. Yeah. 01:47:12\\nBartek\\nBut now I'm talking about the knowledge now. So yeah, for the PFA there is an iteration agent. 01:47:19\\nAlejo\\nRight. 01:47:19\\nBartek\\nBut I'm talking about knowledge now because I'm thinking about the prompts needed for the knowledgenow system. 01:47:25\\nAlejo\\nI'm talking about knowledge now too. But you had mentioned an iterator. 01:47:30\\nBartek\\nOh, it's for. 01:47:36\\nAlejo\\nPFA swarm. So that would be an iterator. 01:47:44\\nBartek\\nJust I thought like, both of these green cards are for the PFA swarm, right? 01:47:51\\nAlejo\\nWell, technically, yes, they are, but this is also for knowledge now. So I'm going to put different colors and we're going to call this V two for V two. This is what we're focusing on now. And the other stuff we're focusing on after we have the MVP, not that we can't keep thinking about it, but in terms of output. 01:48:26\\nBartek\\nRight. So the progress part is actually for the PFS world. 01:48:32\\nAlejo\\nGotcha. Gotcha.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 61 : page_content='Great. So progress, bam, we put here. Great.' metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 62 : page_content='Thank you for clarifying. And are any of these agents relevant to our MVP, which would be the context agent. Context enrichment agent, which is at 80%.' metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 63 : page_content=\"Yeah. 01:49:07\\nBartek\\nBecause for the PFA swarm, it's finished. It's just that I will have to make a little different vanishing for the knowledge now. So be more relevant to. 01:49:24\\nAlejo\\nEvaluator, iterator agent was the other one. That was not that. Then evaluator agent, rag extractor agent, query builder agent, and then we have the answer agent. And then for other stuff that we need to have build is the global context, which is sort of a short system, prompt kind of style knowledge base. All of our transcripts.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 64 : page_content=\"All of our transcripts or detailed summaries of our transcripts. It would probably be the full transcripts. 01:50:09\\nBartek\\nOr the cleaned transcript. Clean from those weird words. 01:50:13\\nAlejo\\nYes, cleaned transcript. And I think we are going, I have that code. 01:50:24\\nBartek\\nI think we should be going like one transcript per one use of the knowledge now. Because if you throw all of the transcript in the one knowledge base, I'm not sure how that's going to go. I mean, you want to extract from one meeting, right? You don't want to extract from every meeting at once. 01:50:43\\nAlejo\\nThe whole point is that there is continuity from meeting to meeting. 01:50:50\\nBartek\\nYeah, but at one, say, run of the knowledge, now you're extracting from one particular meeting. 01:50:57\\nAlejo\\nRight. 01:50:58\\nBartek\\nThe all meetings is like a global context, like infrastructure, knowledge base, something like that. In my variant there is the run. It's on a one transcript, and then we have output of that and that should be saved into the all transcript knowledge base. Not the transcript itself, but the result of the knowledge. Now doing the work, analyzing transcript, and then have like summary or something like that. 01:51:41\\nAlejo\\nOkay. I'm not 100% sure.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 65 : page_content=\"What is the difference. We'll be testing this most likely with a few transcripts and see what it pulls. Because there is relevant information for the same question in different days, different meetings. Right. System or knowledge. Now we will limit it because it's a good point that you're bringing like are you really going to put like 100 hours of context of transcript just to grab from a knowledge base? That would be pretty messy and confusing for the rag.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 66 : page_content=\"01:52:34\\nBartek\\nSo. 01:52:38\\nAlejo\\nBut that is part of why we have the evaluator agent, because it's like, hey, based on the enriched prompt, the rag queries, this chunk that you withdrew, we're talking about AI agents. We're not talking about real estate agents.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 67 : page_content=\"So this is irrelevant or the other way around. We're talking about a real estate solution. So AI agents doesn't make sense. So the evaluator would figure that out. Good question. Let's test it. Let's get the MVP. Let's test it. We'll figure out what we change and also obviously how we manage our knowledge base, which is going to be garbage in, garbage out. The quality of the data, the underlying data has to be high and we'll do our best to have a solid data quality standard for our MVP and we'll make it better over time. 01:53:34\\nBartek\\nAnd you see that we are making, let's see, the call ends. The transcripts get rendered automatically or you have to do that yourself. 01:53:47\\nAlejo\\nWe will be able to render them. 01:53:51\\nBartek\\nAutomatically and then also we should automatically have them cleaned. 01:53:56\\nAlejo\\nYes, correct. 01:53:57\\nBartek\\nAnd the question is now if we also want them automatically to be pushed into the knowledge now. 01:54:07\\nAlejo\\nThat is definitely a pending question because what? Oh, that's what the global context is. Oh my God. Global context is. This is what the dev team does, has worked on, is working on. This is the marketing team. This is who composes the marketing team. The upcoming strategy does say videos published, et cetera, et cetera. And that's the global context that, based on what the original query and the enriched query is, will have certain relevance. So we can create what makes sense to me as a gated access of information to guide. I don't know if that's what you meant by global or global meaning every single component, every single transcript is there. But we'll figure that out at the start. 01:55:30\\nAlejo\\nIf we want to enrich a prompt, let's give it some context and then we can dig into all the details and the transcripts and all that stuff. 01:55:40\\nBartek\\nYeah, I think it also depends on the use case. I feel like some use cases could be done automatically. Like we automatically render the transcript, automatically clean the transcript and let's say for the to do we also automatically run it through the knowledge now. But I guess some use cases will be like run manually and some use cases will be run automatically. 01:56:01\\nAlejo\\nYeah. So I'm going to write dockup considerations, auto run or human check or fully manual, e. G. Modifying the dev team global context document. Because when a new project comes in and we have a new project we're working on a new project, the dev team global context document needs to be updated, but we want to do a human check. 01:56:52\\nBartek\\nThat's like. 01:56:53\\nAlejo\\nYes, that's how you should update it. Dev team deserves human check. Okay, cool.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 68 : page_content=\"Okay. You threw out other considerations there. What was it. 01:57:15\\nBartek\\nI was just saying before about the automation of rendering and cleaning? So I guess that happens automatically all the time. And then we only have differentiation for. 01:57:28\\nAlejo\\nThe use case rendering and cleaning. Yeah, auto cleaning, but auto rendering. 01:57:41\\nBartek\\nAnd also we can have, how to say, categorizing the transcript into like dev call or marketing call. 01:57:52\\nAlejo\\nWe're lucky because Zoom already does that for us. This right now that we're on is a dev meeting. And if you look at the chat. 01:58:01\\nBartek\\nOh yeah, I forget the name of. 01:58:03\\nAlejo\\nThe meeting, and you scroll up, all of our chats of every dev meeting are there, including the summaries. So it's pretty cool.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 69 : page_content=\"01:58:13\\nBartek\\nAll right. 01:58:17\\nAlejo\\nAnd just to be funny, I'm going to ask the AI companion. Catch me? 01:58:32\\nBartek\\nYes, I think that's the end of my idea for today. 01:58:37\\nAlejo\\nWell, that was 2 hours of idea. So I'm asking the zoom AI companion to give me an in depth explanation of knowledge now. I'm sorry, but the meeting transcript does not provide enough information to give an in depth explanation of knowledge now. So the rag sucks. 01:59:00\\nBartek\\nBut this is like the zoom out of the box transcript analysis, right? 01:59:06\\nAlejo\\nYes. Okay, I'm going to walk through this real quick and we can close it. So I input a prompt, there's global context about who fasterize is, who the teams are, and who each person is. That context allows the PFA context enrichment agent to fix and enrich the prompt with the context and outputs an enriched prompt. A lot of the word enrich in there. We'll fix that. We'll ask PFA to fix that. That follows into a PFA rag extractor agent which has access, full access to the knowledge base. The output of, wait, that goes after. The output of this extractor agent is to break down a prompt into multiple queries optimized for rag. Those queries going to the knowledge base which will be living in pine cone. And that knowledge base has the most recent Zoom call transcript, plus every other transcript we have. 02:00:27\\nAlejo\\nIt knows skills of each person and what they want to specialize in through the competency matrix and it has knowledge of projects, clients, industry, focus, et cetera. Then comes the evaluator agent because we extracted for each query several relevant based on semantic similarity, based on cosine similarity, several chunks of information. We now need to evaluate which chunks are relevant because if we're talking about real estate agents, AI agents shouldn't be part of the answer that we're integrating, or maybe yes, depending on the automations that we're building for them. So we have an evaluator agent to say, hey, these are the most relevant chunks for each query. This is the score from one to ten for each chunk, and here are the top five chunks. From there we will have a QA agent that will do a full transcript review. 02:01:28\\nAlejo\\nSo what chunks were retrieved and then do an evaluation of how well did the evaluator agent do its job. We will integrate an oversight board agent that will be able to route to the most relevant next agents to continue the conversation. So we'll keep track of the conversation. Identify does this task require multiple agents to have an open conversation? What other information might be needed? And it will decide which agent comes next, which might be a self refinement agent to log potential refinements to the system. It might be the programming team or most commonly it will be the merger agent which will take the best chunks from the evaluator agent and merge the best pieces from each chunk to create a full answer for each rag query. 02:02:23\\nAlejo\\nEach individual rag query and the final steps are we have answer formatting agent prompt format no wait, that goes to the beginning. We will have answer formatting agent for hey, what's the actual use case and how we make sure we are effective at answering. And there's a big one here who is asking how can we give them a relevant answer that they care about? The CEO doesn't care about the same thing as the engineering manager. So we'll give the output format to the answer agent. It'll grab all of the relevant information and create a final output. Finally, we will have an evaluation answer evaluation agent which will help us keep track of the accuracy of our system. How close is this to a full accurate relevant system? 02:03:36\\nAlejo\\nThe first use case is going to be the first MVP use case is going to be you can message the bot to catch up on meetings and get clarity on assignments, which is going to be one component of our V one use case which is the bot messages you with your to Dos after the meeting checks the tasks that you already have assigned your deliverables checks the capacity and then assigns the tasks. It will confirm with you which tasks you actually want and can take on. It will actually help calculate your contributions and you can have a conversation with the bot to get clarity on those assignments and do your best work. That's knowledge now.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 70 : page_content=\"02:04:24\\nBartek\\nYeah. And also it will attack everybody to make a post on social media. 02:04:31\\nAlejo\\nIt will what? 02:04:33\\nBartek\\nIt will attack everybody with a message to write something for the social media. Seriously, I need like, attacker to attack me every day. 02:04:46\\nAlejo\\nI don't know that attack is the right word. It, but yes, we need, it's more. 02:04:53\\nBartek\\nOf a peeing, but I don't know. I want this AI to be aggressively making me write a post because otherwise I won't. 02:05:02\\nAlejo\\nDude, this is going to be a huge part of the knowledge base of knowledge. Now don't use the words aggressive and attack. That's funny. We'll cut that out. We'll cut that knowledge now. Cut that last part out. But I'm with you.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 71 : page_content=\"I'm with you. Let's have something that we're proud to show PFA. You should be proud to show it. The real estate automations, as simple as they will be. We're proud to show it. It's our first client and we're actually delivering something great for them. So let's get on that social media game and let's grind these projects out for now. This is what this project and fastrase needs from you. Bartek working on the agents. Let's get some drafts for these three agents. 02:05:58\\nBartek\\nCan you send it to me in a chat in a private message? 02:06:03\\nAlejo\\nThat's exactly what I was about to do. Awesome. So we need draft prompts. 02:06:15\\nBartek\\nFor. 02:06:19\\nAlejo\\nGreat. 02:06:22\\nBartek\\nAnd also context agent, right? 02:06:27\\nAlejo\\nOh, did I not put that in there? Oh, yeah, you said the context agent was 90%, but yeah, I'll add that in there. It was in a different section. 02:06:37\\nBartek\\nYeah, because it's finished for the PFA swarm, but for the transcript, it has to be a little tweaked, I think, because it's kind of a little different. Context enrichment in case of transcript analysis and in case of prompt engineering, it's a different thing. 02:06:53\\nAlejo\\nYeah, makes sense. 02:06:54\\nBartek\\nOkay, cool. And do you need any help with the real estate agent projects? Maybe Hubert can help you with that. 02:07:05\\nAlejo\\nThank you. Not for now, because it would be more lift, it would be more time spent kind of guiding someone through all of the components of number one, the CRM, number two, the API, and then most importantly, what the client wants and how they want it. So I am going to show, not tell. I'm going to first work on these two free automations that we're making for them. And then I'm going to show hooby, for example, and walk him through the final build the output, and then go backwards from there. And we can all work on those. They'll be relatively simple and we all want to make money. So I want to integrate everybody into at least one part of those real estate automations. 02:08:02\\nBartek\\nYes, awesome. 02:08:06\\nAlejo\\nKnowledge. Now draft 1 March twelveth 2024. Let that date be remembered. 02:08:19\\nBartek\\nYeah. And check out the messages I sent you before this call. I found some transcript. 02:08:26\\nAlejo\\nOh yes. 02:08:26\\nBartek\\nAnd also those videos. We can use them also for this. 02:08:31\\nAlejo\\nCool, cool. Lovely. I'll check them out in between tomorrow. I'll check them out tomorrow. I'll find some bartech, thank you for your. This is, this has been very fun. I'm honored. 02:08:46\\nBartek\\nYeah, sure, man. Yeah.\" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 72 : page_content=\"Happy to work on this one. Seems that it's going to be revolutionizing. 02:08:56\\nAlejo\\nYeah, absolutely. We can help a lot of people make better lifestyles, better work, better everything. 02:09:04\\nBartek\\nYeah. 02:09:04\\nAlejo\\nTake care, brother. I'll see you tomorrow. 02:09:07\\nBartek\\nYeah, bye. \" metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\n",
      "chunk 73 : page_content=\"AI meeting summary:\\n     **Kuba** showcases integrating Pine Cone Vector Database and OpenAI embeddings to generate responses from meeting transcriptions. The team discusses agents essential to their system, including context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. Automated tasks like cleaning and rendering transcripts are considered for system input. Use cases like messaging bots providing assignment updates post-meetings are highlighted.  Future iterations aim at self-refinement agents to enhance AI performance over time. **Kuba** introduces data integration methods, emphasizing the importance of maintaining high-quality underlying data for accurate outcomes. The team prioritizes achieving Minimum Viable Product (MVP) status before delving into complexities like contribution calculators or project log automation. Tasks are assigned among team members to progress product development focusing on different 'agents' within their pipeline. Action items:\\n     **Bartek**\\n     Share intermediate and advanced prompt engineering resources with Kuba (1:27:21)\\n     Draft prompts for context enrichment agent, RAG extractor agent, evaluator agent and answer formatting agent in relation to Knowledge Now MVP (2:06:19)\\n     **Kuba**\\n     Review Bartek's shared prompt engineering resources (1:28:33)\\n     Work on draft prompts provided by Bartek for Knowledge Now MVP once received (2:07)\\nNotes:\\n     ? **Developing Automation Services**\\n     The team is working on implementing automation services to streamline the project management process.\" metadata={'source': 'data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt'}\n",
      "chunk 74 : page_content=\" A focus is placed on enhancing content creation and idea generation.  **Hubi** is tasked with specific duties that need clarity.  ? **Using 'Knowledgenow' for Task Management**\\n     'Knowledgenow' is being used to generate a list of tasks for team members after each meeting.  It is aimed to provide clarity on the tasks assigned to each individual.  **Hubi** is given examples of how the system functions.  ? **Success Criteria and Project Management**\\n     The team discussed the success criteria for the project, emphasizing clear task distribution and responsibility assignment.  The introduction of a scrum master assistant was mentioned as a way to further improve task clarity.  ? **Supervisor and Moderator Roles**\\n     The supervisor will guide the conversation, deciding what information is relevant.  The moderator is responsible for overseeing the conversation and ensuring it stays on topic.  ? **Focus on Markdown and Documentation**\\n     The team is advised to familiarize themselves with markdown syntax for better documentation.  **Kuba** is given resources to get started on this.\" metadata={'source': 'data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt'}\n",
      "chunk 75 : page_content=' ? **Answer Formatting and Evaluation**\\n     An answer formatting agent is proposed to help evaluate and format the responses.  The team also discussed the need for a separate agent to handle answer generation.  ? **Assigning Team Members and Deadlines**\\n     The team members are assigned specific tasks and deadlines.  A tool like Airtable is suggested as a potential way to track project progress.  ? **Meeting Summaries and Global Context**\\n     The team discussed the importance of meeting summaries and the need for a global context in project management.  The idea of categorizing transcripts based on the nature of the meeting (dev call, marketing call) was proposed.' metadata={'source': 'data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt'}\n",
      "chunk 76 : page_content=' ? **MVP Use Case**\\n     The first MVP use case is decided to be a bot that sends you to-dos after meetings and allows you to clarify assignments.  It checks assigned deliverables and tasks, as well as the capacity of each team member. Outline:\\n     Chapter 1: Introduction to the Proposed System (10:21 - 13:12)\\n     10:21: Discussion begins on the issues of short, non-detailed prompts and the possibility of using markdown for more structure.  13:12: **Kuba** is asked about his experience with starting the rack system from a single document transcript.  Chapter 2: Processing and Transcript Considerations (18:43 - 28:00)\\n     18:43: **Kuba** shares his process of importing the meeting transcript using planchain.  22:48: The team discusses potential improvements in the processing side, particularly the initial parts of the transcript.  27:53: The team acknowledges that the transcript quality and the limitations of context extraction are affecting query outputs.  Chapter 3: Task Clarification and Success Criteria (32:10 - 34:22)\\n     32:10: The objective of the meeting is clarified as understanding individual tasks within the system project.  33:44: The team identifies success criteria as the ability to message each person clarifications after the meeting.  Chapter 4: Knowledge Extraction and Enrichment (43:24 - 54:48)\\n     43:24: The team discusses enriching the extracted information to create an improved prompt.  50:42: An extractor agent is introduced, which uses the transcript as a knowledge base.  53:06: Importance of being explicit and clear in step-by-step extraction and understanding client requirements is emphasized.  54:48: The idea of having a supervisor to lead free conversations among agents is proposed.  Chapter 5: Evaluation and Formatting of Answers (1:07:02 - 1:18:55)\\n     1:07:02: A system is proposed where a manager agent selects the best parts from high-scored chunks to form an answer.  1:13:59: The team agrees on the need for an answer formatting agent to provide a structured output.  1:17:52: The role of a supervisor in tracking the conversation and identifying necessary information is highlighted.  Chapter 6: Transcript Analysis and Knowledge Extraction (1:49:55 - 2:01:40)\\n     1:49:55: The team discusses the potential of using all available transcripts or detailed summaries as resources.  1:51:18: The idea of saving the output from the analysis of a single transcript into a knowledge base is proposed.  1:56:32: The team talks about modifying the dev team global context document and categorizing transcripts.  2:01:15: A QA agent is proposed to review the full transcript and evaluate how well the evaluator agent did its job.  Chapter 7: Final Steps and Use Cases (2:03:06 - 2:06:37)\\n     2:03:06: The team discusses the final steps, such as giving the output format to the answer agent to create a final output.  2:03:36: The first use case is introduced as a bot that provides meeting summaries and clarifies assignments.  2:06:37: The team acknowledges the need to tweak the system for transcript analysis compared to prompt engineering. ' metadata={'source': 'data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt'}\n"
     ]
    }
   ],
   "source": [
    "for i, _ in enumerate(text_chunk):\n",
    "    print(f\"chunk {i} : {text_chunk[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating embeddings\n",
    "\n",
    "model_name = \"text-embedding-3-small\"\n",
    "def data_embedding():\n",
    "    embeddings = OpenAIEmbeddings(model=model_name)\n",
    "    return embeddings\n",
    "\n",
    "embeddings = data_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing Vectorstore\n",
    "Pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "Your_env = \"gcp-starter\"\n",
    "index_name = \"knowledgenow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding embeddings into the vectorstore\n",
    "vectorstore = PineconeVectorStore.from_documents(text_chunk, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vectorstore.as_retriever(search_kwargs={'k':25})\n",
    "\n",
    "multi_llm = ChatOpenAI(temperature= 0.5)\n",
    "\n",
    "#Adding mutli query retriver\n",
    "retriever = MultiQueryRetriever.from_llm( retriever=retriver, llm=multi_llm\n",
    "                )\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
    "\n",
    "#retrieval chain\n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "llm=multi_llm, \n",
    "chain_type=\"stuff\", \n",
    "retriever=retriever)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNOWLEDGEBASE QUERY AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_query = sub_query_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def knowledgebase(retrived_doc:str)-> str:\n",
    "    \"\"\"Use this tool when you want extract information from the Knowledgenow database\"\"\"\n",
    "    result_str = qa.invoke(sub_query)\n",
    "    return result_str\n",
    "\n",
    "tools = [knowledgebase]\n",
    "\n",
    " #create rag_extractor prompt template\n",
    "knowledgebase_query_template = prompts.Knowledgebase_template\n",
    "knowledgebase_query_prompt = PromptTemplate.from_template(template=knowledgebase_query_template, MessagePlaceholder=[\"(agent_scratchpad)\"])\n",
    "knowledgebase_query_agent = create_react_agent(llm=llm, \n",
    "                           tools=tools, \n",
    "                           prompt=knowledgebase_query_prompt)\n",
    "knowledgebase_query_agent_executor = AgentExecutor(agent=knowledgebase_query_agent, tools=tools, verbose=True, handle_parsing_errors=True, max_iterations=8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to query the KnowledgeNow database to find all the current tasks assigned within the KnowledgeNow project. This will require extracting specific information about tasks, including their descriptions, assignees, and deadlines if available.\n",
      "\n",
      "Action: knowledgebase\n",
      "Action Input: List all current tasks assigned within the KnowledgeNow project\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What are the current tasks being worked on in the KnowledgeNow project?', '2. Can you provide a list of tasks currently assigned in the KnowledgeNow project?', '3. What tasks are currently underway in the KnowledgeNow project?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m{'question': 'List all current tasks assigned within the KnowledgeNow project', 'answer': \"Tasks assigned within the KnowledgeNow project are:\\n1. Share intermediate and advanced prompt engineering resources with Kuba\\n2. Draft prompts for context enrichment agent, RAG extractor agent, evaluator agent, and answer formatting agent in relation to Knowledge Now MVP\\n3. Review Bartek's shared prompt engineering resources\\n4. Work on draft prompts provided by Bartek for Knowledge Now MVP once received\\n5. Showcase integrating Pine Cone Vector Database and OpenAI embeddings to generate responses from meeting transcriptions\\n6. Develop automation services to streamline the project management process\\n7. Familiarize with markdown syntax for better documentation\\n\\n\", 'sources': 'data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt, data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "\n",
      "Final Answer: The current tasks assigned within the KnowledgeNow project are:\n",
      "1. Share intermediate and advanced prompt engineering resources with Kuba.\n",
      "2. Draft prompts for context enrichment agent, RAG extractor agent, evaluator agent, and answer formatting agent in relation to Knowledge Now MVP.\n",
      "3. Review Bartek's shared prompt engineering resources.\n",
      "4. Work on draft prompts provided by Bartek for Knowledge Now MVP once received.\n",
      "5. Showcase integrating Pine Cone Vector Database and OpenAI embeddings to generate responses from meeting transcriptions.\n",
      "6. Develop automation services to streamline the project management process.\n",
      "7. Familiarize with markdown syntax for better documentation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Knowledgebase_agent_output= knowledgebase_query_agent_executor.invoke({\"sub_query\": sub_query})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_query = sub_query_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to query the KnowledgeNow database to find specific deadlines for each task within the KnowledgeNow project. This will involve extracting dates and associated tasks from the project documentation stored within the database.\n",
      "\n",
      "Action: knowledgebase\n",
      "Action Input: Identify the deadlines for each task in the KnowledgeNow project\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What are the specific deadlines associated with each task within the KnowledgeNow project?', '2. Can you provide a breakdown of the task deadlines within the KnowledgeNow project?', '3. How are the deadlines distributed across the various tasks in the KnowledgeNow project?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m{'question': 'Identify the deadlines for each task in the KnowledgeNow project', 'answer': 'The deadlines for each task in the KnowledgeNow project were not explicitly mentioned in the provided content.\\n', 'sources': ''}\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "\n",
      "Final Answer: The deadlines for each task in the KnowledgeNow project were not explicitly mentioned in the provided content.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Knowledgebase_agent_output_2= knowledgebase_query_agent_executor.invoke({\"sub_query\": sub_query_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_query = sub_query_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to query the KnowledgeNow database to find the current progress status of each task within the KnowledgeNow system. This involves extracting specific details regarding the status of tasks, such as whether they are in progress, completed, or pending, and any relevant metrics or updates that indicate their current state.\n",
      "\n",
      "Action: knowledgebase\n",
      "Action Input: What is the current progress status of each KnowledgeNow task?\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What is the current status update for all tasks in KnowledgeNow?', '2. Can you provide an update on the progress of each task within KnowledgeNow?', '3. How can I check the current progress status of individual tasks in KnowledgeNow?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m{'question': 'Determine the current progress status of each KnowledgeNow task', 'answer': 'The progress status of each KnowledgeNow task is not explicitly mentioned in the provided content.\\n', 'sources': ''}\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "\n",
      "Final Answer: The current progress status of each KnowledgeNow task is not explicitly mentioned in the provided content.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Knowledgebase_agent_output_3 = knowledgebase_query_agent_executor.invoke({\"sub_query\": sub_query_3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_query = sub_query_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to query the KnowledgeNow database to find the most recent updates or changes made to tasks within the KnowledgeNow project. This will involve searching for documents or entries that detail task modifications, updates, or any form of change log related to the project tasks.\n",
      "\n",
      "Action: knowledgebase\n",
      "Action Input: Recent updates or changes made to tasks in the KnowledgeNow project\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What are the most recent modifications or updates to tasks within the KnowledgeNow project?', '2. Can you provide me with the latest changes or updates made to tasks in the KnowledgeNow project?', '3. Have there been any recent updates or revisions to tasks in the KnowledgeNow project that I should be aware of?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m{'question': 'Extract any recent updates or changes made to tasks in the KnowledgeNow project', 'answer': \"Recent updates in the KnowledgeNow project include the implementation of automation services to streamline project management processes and the use of 'Knowledgenow' for task management, generating a list of tasks for team members after each meeting. There is also a focus on enhancing content creation and idea generation within the project. Additionally, there are ongoing discussions about integrating various AI agents to improve system performance and efficiency.\\n\", 'sources': 'data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt, data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "\n",
      "Final Answer: Recent updates in the KnowledgeNow project include the implementation of automation services to streamline project management processes and the use of 'Knowledgenow' for task management, generating a list of tasks for team members after each meeting. There is also a focus on enhancing content creation and idea generation within the project. Additionally, there are ongoing discussions about integrating various AI agents to improve system performance and efficiency.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "knowledgebase_agent_output_4 = knowledgebase_query_agent_executor.invoke({\"sub_query\": sub_query_4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['During the meeting, Alejo and Bartek were involved in discussing key topics such as the development of a multi-agent system for the Knowledge Now project. This included focusing on agents like context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. They also emphasized the importance of feedback loops for prompt generation and the need for a swarm system to improve prompt quality. However, the provided information does not explicitly mention specific action items assigned to Alejo and Bartek.', 'The key topics discussed by Alejo and Bartek in the meeting include the development of agents for the Knowledge Now system, such as context enrichment, query agent, evaluation agent, and generation agent. They also discussed the need for a feedback loop for prompt generation and the importance of simplicity and programmatic processes. Additionally, they touched on integrating Notion with Relevance AI for content automation and the importance of real estate automations. The conversation also highlighted the potential for aggressive AI prompts for social media posts.', 'Alejo and Bartek discussed several key topics in their meeting, including knowledge components, context enrichment, prompt engineering resources, agent functionalities, and real estate automations.', 'The concerns or issues raised by Alejo and Bartek in the meeting were not directly mentioned in the provided observation. The observation instead detailed the key topics discussed, including the integration of Pine Cone Vector Database and OpenAI embeddings, essential agents for their system, automated tasks, messaging bots for updates, future iterations for self-refinement agents, data integration methods, achieving MVP status, and task assignments among team members for product development.', \"Key topics discussed by Alejo and Bartek in the meeting include:\\n1. Integration of Pine Cone Vector Database and OpenAI embeddings for generating responses from meeting transcriptions.\\n2. Discussion on essential agents for the system, such as context enrichment, RAG extractor, evaluator, QA, supervisor, merger, and answer formatting agents.\\n3. Consideration of automated tasks like cleaning and rendering transcripts for system input.\\n4. Use cases like messaging bots providing assignment updates post-meetings.\\n5. Future iterations focusing on self-refinement agents to enhance AI performance over time.\\n6. Prioritization of achieving Minimum Viable Product (MVP) status before delving into complexities like contribution calculators or project log automation.\\n7. Assigning tasks among team members to progress product development focusing on different 'agents' within their pipeline.\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Knowledgebase_answer_1 = Knowledgebase_agent_output[\"output\"]\n",
    "Knowledgebase_answer_2 = Knowledgebase_agent_output_2[\"output\"]\n",
    "Knowledgebase_answer_3= Knowledgebase_agent_output_3[\"output\"]\n",
    "Knowledgebase_answer_4= knowledgebase_agent_output_4[\"output\"]\n",
    "Knowledgebase_answer_5= knowledgebase_agent_output_5[\"output\"]\n",
    "\n",
    "combined_output_list = [Knowledgebase_answer_1, Knowledgebase_answer_2, Knowledgebase_answer_3, Knowledgebase_answer_4, Knowledgebase_answer_5]\n",
    "print(combined_output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a custom tool\n",
    "@tool\n",
    "def Vectormatches(query:str)-> str:\n",
    "    \"\"\"\n",
    "    Use this tool when you want to return vector match results for the vectordatabase\"\"\"\n",
    "    global combined_output_list\n",
    "    return combined_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [Vectormatches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_template = prompts.evaluator_template\n",
    "\n",
    "evaluator_prompt = PromptTemplate.from_template(template=evaluator_template, MessagePlaceholder=[\"(agent_scratchpad)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluator_agent = create_react_agent(llm=llm, tools=tools, prompt=evaluator_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_agent_executor = AgentExecutor(agent=evaluator_agent, tools=tools, verbose=True,handle_parsing_errors=True, max_iterations=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mGiven the enriched prompt and the vector matches, it's clear that Alejo and Bartek's discussion focused heavily on the technical development and strategic planning of AI technologies within the KnowledgeNow project and potentially other projects at Fasterise. Their conversation spanned a range of topics crucial for the integration and enhancement of AI capabilities, emphasizing the development of a multi-agent system, the importance of feedback loops for prompt generation, and the integration of advanced technologies like the Pine Cone Vector Database and OpenAI embeddings.\n",
      "\n",
      "The discussion points indicate a deep dive into the operational and technical specifics necessary for advancing Fasterise's mission of leveraging AI to amplify human potential. The emphasis on multi-agent systems, including specific roles like context enrichment, RAG extractor, evaluator, and answer formatting agents, aligns with Fasterise's focus on creating sophisticated, ethical AI solutions. The mention of feedback loops and swarm systems for improving prompt quality further reflects a commitment to continuous improvement and innovation.\n",
      "\n",
      "Moreover, the integration of Notion with Relevance AI for content automation and the focus on real estate automations suggest a strategic approach to applying AI technologies across various operational areas. The potential for aggressive AI prompts for social media posts indicates an understanding of the broader applications of AI in marketing and communication strategies.\n",
      "\n",
      "Given this analysis, the most relevant vector matches seem to be those that detail the development of the multi-agent system for KnowledgeNow, the integration of advanced AI technologies, and the strategic focus on continuous improvement and broad application of AI solutions. These discussions are not only technically significant but also strategically aligned with Fasterise's mission and vision, indicating a comprehensive approach to leveraging AI for amplifying human capabilities across industries.\n",
      "\n",
      "Final Answer: Alejo and Bartek discussed several key topics in their meeting, focusing on the development and strategic planning of AI technologies within the KnowledgeNow project and potentially other initiatives at Fasterise. Their conversation covered the technical development of a multi-agent system, including specific agent roles like context enrichment and RAG extractor, and the strategic application of AI across various operational areas, such as content automation and real estate. The emphasis on feedback loops, the integration of advanced technologies like the Pine Cone Vector Database and OpenAI embeddings, and the potential for AI-driven social media strategies reflect a deep commitment to leveraging AI to amplify human potential, aligning with Fasterise's mission and vision.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Evalutor_output=evaluator_agent_executor.invoke({\n",
    "        \"input\":input, \n",
    "        \"global_context\": global_context, \n",
    "        \"enriched_prompt\": Enriched_prompt_output,\n",
    "        \"Vector_matches\": combined_output_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alejo and Bartek discussed several key topics in their meeting, focusing on the development and strategic planning of AI technologies within the KnowledgeNow project and potentially other initiatives at Fasterise. Their conversation covered the technical development of a multi-agent system, including specific agent roles like context enrichment and RAG extractor, and the strategic application of AI across various operational areas, such as content automation and real estate. The emphasis on feedback loops, the integration of advanced technologies like the Pine Cone Vector Database and OpenAI embeddings, and the potential for AI-driven social media strategies reflect a deep commitment to leveraging AI to amplify human potential, aligning with Fasterise's mission and vision.\n"
     ]
    }
   ],
   "source": [
    "Evaluator_agent_output=Evalutor_output[\"output\"]\n",
    "print(Evaluator_agent_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a custom tool\n",
    "@tool\n",
    "def Evaluator_result(query:str)-> str:\n",
    "    \"\"\"\n",
    "    Use this tool anytime you need to return  Re-ranked and evaluated data results from the Evaluator assistant \"\"\"\n",
    "    global Evaluator_agent_output\n",
    "    return Evaluator_agent_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer_template = prompts.Answer_template\n",
    "\n",
    "Answer_prompt = PromptTemplate.from_template(template=Answer_template, MessagePlaceholder=[\"(agent_scratchpad)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer_agent = create_react_agent(llm=llm, tools=tools, prompt=Answer_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer_agent_executor = AgentExecutor(agent=Answer_agent, tools=tools, verbose=True,handle_parsing_errors=True, max_iterations=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo address this query, we need to delve into the specifics of what Alejo and Bartek, key figures at Fasterise, might have discussed in their meeting, focusing on their roles and the company's strategic direction. Alejo, deeply involved in Operations, Sales, and Development with an emphasis on AI technologies including RAG, LLMs, and Multi-Agent Systems, and Bartek, leading engineering with a specialization in Prompt Engineering and AI Agents, are pivotal in steering Fasterise's innovative projects.\n",
      "\n",
      "Given their expertise and the context of Fasterise's mission, it's plausible that their discussion revolved around several critical areas:\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**: They likely explored how to further incorporate AI technologies like RAG and LLMs into ongoing projects such as the Zoom Transcriber to Pinecone Integration and KnowledgeNow. This could involve technical discussions on optimizing these technologies for better performance and efficiency, ensuring these projects align with Fasterise's vision of amplifying human capabilities through AI.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**: Alejo and Bartek probably strategized on future initiatives, considering the company's mission to leverage AI for societal and business challenges. They might have identified potential industries or sectors where Fasterise's AI solutions could be impactful, discussing how to adapt and evolve their technology stack to meet these new challenges.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**: With Alejo's role touching on Operations and Development and Bartek's expertise in engineering, they likely deliberated on improving internal processes. This could include adopting new methodologies in development, enhancing collaboration between teams, or streamlining operations to support the company's rapid growth and innovation pace.\n",
      "\n",
      "4. **Ethical AI Development**: Aligning with Fasterise's commitment to ethical AI, their discussion might have touched on ensuring that current and future projects uphold these standards. This includes evaluating AI technologies and their applications to prevent biases, ensure transparency, and enhance user trust.\n",
      "\n",
      "5. **Amplifying Human Capabilities**: Central to Fasterise's mission, they likely focused on how their projects, especially KnowledgeNow and the Zoom Transcriber to Pinecone Integration, can further augment human potential. This could involve discussions on user experience, accessibility, and how these technologies can empower users in their daily tasks and decision-making processes.\n",
      "\n",
      "In conclusion, Alejo and Bartek's meeting likely covered a broad spectrum of topics, all aimed at advancing Fasterise's mission through the strategic integration of AI technologies, operational excellence, and a steadfast commitment to ethical AI development. Their discussions are crucial in shaping the company's direction, ensuring that Fasterise remains at the forefront of AI innovation while amplifying human capabilities across various industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the intricate details surrounding Fasterise's mission, the roles of Alejo and Bartek, and the strategic direction of their projects, it's clear that their meeting likely covered several pivotal topics. These discussions are instrumental in propelling Fasterise towards its goal of leveraging AI to amplify human potential while adhering to ethical AI development principles. Here's a comprehensive breakdown of what Alejo and Bartek might have discussed, based on their roles and the company's ongoing projects:\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**: \n",
      "   - They likely explored enhancing ongoing projects like the Zoom Transcriber to Pinecone Integration and KnowledgeNow with AI technologies such as RAG, LLMs, and Multi-Agent Systems. This would involve technical strategies for optimizing these technologies to improve performance and efficiency, ensuring alignment with Fasterise's vision.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**: \n",
      "   - The discussion probably included strategic planning for future initiatives that align with Fasterise's mission to address societal and business challenges through AI. Identifying potential sectors for impact and adapting the technology stack to meet these challenges would be key topics.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**: \n",
      "   - Given Alejo's involvement in Operations and Development and Bartek's engineering leadership, improving internal processes for better efficiency and innovation pace likely featured in their conversation. This could encompass adopting new development methodologies and enhancing team collaboration.\n",
      "\n",
      "4. **Ethical AI Development**: \n",
      "   - Aligning with the company's ethical AI commitment, ensuring that projects uphold these standards would be crucial. Discussions might have focused on evaluating AI technologies and applications to avoid biases, ensure transparency, and build user trust.\n",
      "\n",
      "5. **Amplifying Human Capabilities**: \n",
      "   - Central to Fasterise's mission, how projects like KnowledgeNow and the Zoom Transcriber to Pinecone Integration can further augment human potential was likely a significant focus. Enhancing user experience, accessibility, and empowering users in their daily tasks and decisions would be key discussion points.\n",
      "\n",
      "In essence, Alejo and Bartek's meeting would have spanned a broad spectrum of topics, all aimed at furthering Fasterise's mission. Through strategic AI technology integration, operational excellence, and a commitment to ethical AI development, their discussions are vital in steering the company towards remaining a leader in AI innovation, with a focus on amplifying human capabilities across industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the detailed insights into the roles of Alejo and Bartek at Fasterise, along with the company's mission and ongoing projects, it's plausible to conclude that their meeting focused on several strategic and operational topics crucial for advancing the company's objectives. Heres a synthesized overview of the potential discussion points, structured around Fasterise's core mission of leveraging AI to amplify human potential while adhering to ethical AI development principles:\n",
      "\n",
      "### Key Discussion Points Between Alejo and Bartek\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**\n",
      "   - **Objective**: Enhance projects like the Zoom Transcriber to Pinecone Integration and KnowledgeNow with advanced AI technologies such as RAG, LLMs, and Multi-Agent Systems.\n",
      "   - **Strategy**: Discuss technical optimizations for these technologies to boost performance and efficiency, ensuring they align with Fasterise's vision of amplifying human capabilities through AI.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**\n",
      "   - **Objective**: Identify and strategize on future initiatives that leverage AI to address both societal and business challenges.\n",
      "   - **Focus Areas**: Pinpoint potential sectors where Fasterise's AI solutions could have a significant impact and discuss adapting the technology stack to meet new challenges.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**\n",
      "   - **Objective**: Improve internal processes to support Fasterise's rapid growth and innovation pace.\n",
      "   - **Strategies**: Consider adopting new development methodologies, enhancing team collaboration, and streamlining operations, with Alejo's insights on Operations and Development and Bartek's expertise in engineering guiding the way.\n",
      "\n",
      "4. **Ethical AI Development**\n",
      "   - **Objective**: Ensure that Fasterise's projects uphold the company's commitment to ethical AI standards.\n",
      "   - **Discussion Points**: Evaluate AI technologies and their applications to prevent biases, ensure transparency, and enhance user trust, aligning with Fasterise's ethical AI development principles.\n",
      "\n",
      "5. **Amplifying Human Capabilities**\n",
      "   - **Objective**: Focus on how projects like KnowledgeNow and the Zoom Transcriber to Pinecone Integration can further augment human potential.\n",
      "   - **Key Considerations**: Enhance user experience, improve accessibility, and empower users in their daily tasks and decision-making processes.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Alejo and Bartek's discussions are integral to steering Fasterise towards its goal of amplifying human potential through ethical AI development. By focusing on strategic AI technology integration, operational excellence, and a steadfast commitment to ethical principles, their collaborative efforts are crucial in ensuring that Fasterise remains at the forefront of AI innovation, with a clear focus on enhancing human capabilities across various industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the intricate details surrounding Fasterise's mission, the roles of Alejo and Bartek, and the strategic direction of their projects, it's clear that their meeting likely covered several pivotal topics. These discussions are instrumental in propelling Fasterise towards its goal of leveraging AI to amplify human potential while adhering to ethical AI development principles. Heres a comprehensive breakdown of what Alejo and Bartek might have discussed, based on their roles and the company's ongoing projects:\n",
      "\n",
      "### Key Discussion Points Between Alejo and Bartek\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**\n",
      "   - **Objective**: Enhance projects like the Zoom Transcriber to Pinecone Integration and KnowledgeNow with advanced AI technologies such as RAG, LLMs, and Multi-Agent Systems.\n",
      "   - **Strategy**: Discuss technical optimizations for these technologies to boost performance and efficiency, ensuring they align with Fasterise's vision of amplifying human capabilities through AI.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**\n",
      "   - **Objective**: Identify and strategize on future initiatives that leverage AI to address both societal and business challenges.\n",
      "   - **Focus Areas**: Pinpoint potential sectors where Fasterise's AI solutions could have a significant impact and discuss adapting the technology stack to meet new challenges.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**\n",
      "   - **Objective**: Improve internal processes to support Fasterise's rapid growth and innovation pace.\n",
      "   - **Strategies**: Consider adopting new development methodologies, enhancing team collaboration, and streamlining operations, with Alejo's insights on Operations and Development and Bartek's expertise in engineering guiding the way.\n",
      "\n",
      "4. **Ethical AI Development**\n",
      "   - **Objective**: Ensure that Fasterise's projects uphold the company's commitment to ethical AI standards.\n",
      "   - **Discussion Points**: Evaluate AI technologies and their applications to prevent biases, ensure transparency, and enhance user trust, aligning with Fasterise's ethical AI development principles.\n",
      "\n",
      "5. **Amplifying Human Capabilities**\n",
      "   - **Objective**: Focus on how projects like KnowledgeNow and the Zoom Transcriber to Pinecone Integration can further augment human potential.\n",
      "   - **Key Considerations**: Enhance user experience, improve accessibility, and empower users in their daily tasks and decision-making processes.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Alejo and Bartek's discussions are integral to steering Fasterise towards its goal of amplifying human potential through ethical AI development. By focusing on strategic AI technology integration, operational excellence, and a steadfast commitment to ethical principles, their collaborative efforts are crucial in ensuring that Fasterise remains at the forefront of AI innovation, with a clear focus on enhancing human capabilities across various industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the intricate details surrounding Fasterise's mission, the roles of Alejo and Bartek, and the strategic direction of their projects, it's clear that their meeting likely covered several pivotal topics. These discussions are instrumental in propelling Fasterise towards its goal of leveraging AI to amplify human potential while adhering to ethical AI development principles. Heres a comprehensive breakdown of what Alejo and Bartek might have discussed, based on their roles and the company's ongoing projects:\n",
      "\n",
      "### Key Discussion Points Between Alejo and Bartek\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**\n",
      "   - **Objective**: Enhance projects like the Zoom Transcriber to Pinecone Integration and KnowledgeNow with advanced AI technologies such as RAG, LLMs, and Multi-Agent Systems.\n",
      "   - **Strategy**: Discuss technical optimizations for these technologies to boost performance and efficiency, ensuring they align with Fasterise's vision of amplifying human capabilities through AI.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**\n",
      "   - **Objective**: Identify and strategize on future initiatives that leverage AI to address both societal and business challenges.\n",
      "   - **Focus Areas**: Pinpoint potential sectors where Fasterise's AI solutions could have a significant impact and discuss adapting the technology stack to meet new challenges.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**\n",
      "   - **Objective**: Improve internal processes to support Fasterise's rapid growth and innovation pace.\n",
      "   - **Strategies**: Consider adopting new development methodologies, enhancing team collaboration, and streamlining operations, with Alejo's insights on Operations and Development and Bartek's expertise in engineering guiding the way.\n",
      "\n",
      "4. **Ethical AI Development**\n",
      "   - **Objective**: Ensure that Fasterise's projects uphold the company's commitment to ethical AI standards.\n",
      "   - **Discussion Points**: Evaluate AI technologies and their applications to prevent biases, ensure transparency, and enhance user trust, aligning with Fasterise's ethical AI development principles.\n",
      "\n",
      "5. **Amplifying Human Capabilities**\n",
      "   - **Objective**: Focus on how projects like KnowledgeNow and the Zoom Transcriber to Pinecone Integration can further augment human potential.\n",
      "   - **Key Considerations**: Enhance user experience, improve accessibility, and empower users in their daily tasks and decision-making processes.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Alejo and Bartek's discussions are integral to steering Fasterise towards its goal of amplifying human potential through ethical AI development. By focusing on strategic AI technology integration, operational excellence, and a steadfast commitment to ethical principles, their collaborative efforts are crucial in ensuring that Fasterise remains at the forefront of AI innovation, with a clear focus on enhancing human capabilities across various industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the detailed context surrounding Fasterise's mission and the specific roles of Alejo and Bartek, it is evident that their meeting would have focused on several critical areas that align with the company's strategic direction and core objectives. Here's a synthesized overview of the potential discussion points, structured around Fasterise's mission of leveraging AI to amplify human potential while adhering to ethical AI development principles:\n",
      "\n",
      "### Key Discussion Points Between Alejo and Bartek\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**\n",
      "   - **Objective**: Enhance projects like the Zoom Transcriber to Pinecone Integration and KnowledgeNow with advanced AI technologies such as RAG, LLMs, and Multi-Agent Systems.\n",
      "   - **Strategy**: Technical optimizations for these technologies to boost performance and efficiency, ensuring alignment with Fasterise's vision.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**\n",
      "   - **Objective**: Strategize on future initiatives that leverage AI to address societal and business challenges.\n",
      "   - **Focus Areas**: Identify potential sectors for impact and discuss adapting the technology stack to meet these challenges.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**\n",
      "   - **Objective**: Improve internal processes to support Fasterise's innovation pace and growth.\n",
      "   - **Strategies**: Adopt new development methodologies, enhance team collaboration, and streamline operations.\n",
      "\n",
      "4. **Ethical AI Development**\n",
      "   - **Objective**: Uphold Fasterise's commitment to ethical AI standards in all projects.\n",
      "   - **Discussion Points**: Evaluate AI technologies and applications to prevent biases, ensure transparency, and build user trust.\n",
      "\n",
      "5. **Amplifying Human Capabilities**\n",
      "   - **Objective**: Discuss how projects can further augment human potential, focusing on user experience, accessibility, and empowerment in daily tasks and decision-making.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Alejo and Bartek's discussions are pivotal in driving Fasterise towards its goal of amplifying human potential through ethical AI development. By focusing on strategic AI technology integration, operational excellence, and ethical principles, their efforts are key to ensuring that Fasterise remains a leader in AI innovation, enhancing human capabilities across various industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the detailed context surrounding Fasterise's mission and the specific roles of Alejo and Bartek, it is evident that their meeting would have focused on several critical areas that align with the company's strategic direction and core objectives. Here's a synthesized overview of the potential discussion points, structured around Fasterise's mission of leveraging AI to amplify human potential while adhering to ethical AI development principles:\n",
      "\n",
      "### Key Discussion Points Between Alejo and Bartek\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**\n",
      "   - **Objective**: Enhance projects like the Zoom Transcriber to Pinecone Integration and KnowledgeNow with advanced AI technologies such as RAG, LLMs, and Multi-Agent Systems.\n",
      "   - **Strategy**: Technical optimizations for these technologies to boost performance and efficiency, ensuring alignment with Fasterise's vision.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**\n",
      "   - **Objective**: Strategize on future initiatives that leverage AI to address societal and business challenges.\n",
      "   - **Focus Areas**: Identify potential sectors for impact and discuss adapting the technology stack to meet these challenges.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**\n",
      "   - **Objective**: Improve internal processes to support Fasterise's innovation pace and growth.\n",
      "   - **Strategies**: Adopt new development methodologies, enhance team collaboration, and streamline operations.\n",
      "\n",
      "4. **Ethical AI Development**\n",
      "   - **Objective**: Uphold Fasterise's commitment to ethical AI standards in all projects.\n",
      "   - **Discussion Points**: Evaluate AI technologies and applications to prevent biases, ensure transparency, and build user trust.\n",
      "\n",
      "5. **Amplifying Human Capabilities**\n",
      "   - **Objective**: Discuss how projects can further augment human potential, focusing on user experience, accessibility, and empowerment in daily tasks and decision-making.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Alejo and Bartek's discussions are pivotal in driving Fasterise towards its goal of amplifying human potential through ethical AI development. By focusing on strategic AI technology integration, operational excellence, and ethical principles, their efforts are key to ensuring that Fasterise remains a leader in AI innovation, enhancing human capabilities across various industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the detailed context surrounding Fasterise's mission and the specific roles of Alejo and Bartek, it is evident that their meeting would have focused on several critical areas that align with the company's strategic direction and core objectives. Here's a synthesized overview of the potential discussion points, structured around Fasterise's mission of leveraging AI to amplify human potential while adhering to ethical AI development principles:\n",
      "\n",
      "### Key Discussion Points Between Alejo and Bartek\n",
      "\n",
      "1. **Integration of AI Technologies in Current Projects**\n",
      "   - **Objective**: Enhance projects like the Zoom Transcriber to Pinecone Integration and KnowledgeNow with advanced AI technologies such as RAG, LLMs, and Multi-Agent Systems.\n",
      "   - **Strategy**: Technical optimizations for these technologies to boost performance and efficiency, ensuring alignment with Fasterise's vision.\n",
      "\n",
      "2. **Strategic Planning for Future Projects**\n",
      "   - **Objective**: Strategize on future initiatives that leverage AI to address societal and business challenges.\n",
      "   - **Focus Areas**: Identify potential sectors for impact and discuss adapting the technology stack to meet these challenges.\n",
      "\n",
      "3. **Operational Efficiency and Development Processes**\n",
      "   - **Objective**: Improve internal processes to support Fasterise's innovation pace and growth.\n",
      "   - **Strategies**: Adopt new development methodologies, enhance team collaboration, and streamline operations.\n",
      "\n",
      "4. **Ethical AI Development**\n",
      "   - **Objective**: Uphold Fasterise's commitment to ethical AI standards in all projects.\n",
      "   - **Discussion Points**: Evaluate AI technologies and applications to prevent biases, ensure transparency, and build user trust.\n",
      "\n",
      "5. **Amplifying Human Capabilities**\n",
      "   - **Objective**: Discuss how projects can further augment human potential, focusing on user experience, accessibility, and empowerment in daily tasks and decision-making.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Alejo and Bartek's discussions are pivotal in driving Fasterise towards its goal of amplifying human potential through ethical AI development. By focusing on strategic AI technology integration, operational excellence, and ethical principles, their efforts are key to ensuring that Fasterise remains a leader in AI innovation, enhancing human capabilities across various industries.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "Answer_output=Answer_agent_executor.invoke({\n",
    "        \"input\":input, \n",
    "        \"global_context\": global_context, \n",
    "        \"enriched_prompt\": Enriched_prompt_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent stopped due to iteration limit or time limit.\n"
     ]
    }
   ],
   "source": [
    "Answer_agent_output = Answer_output[\"output\"]\n",
    "print(Answer_agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#conversational memory \n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    k=5,\n",
    "    return_messages=True\n",
    "\n",
    ")\n",
    "conversational_memory.chat_memory.messages\n",
    "conversational_memory.chat_memory.add_user_message(input)\n",
    "conversational_memory.chat_memory.add_ai_message(Answer_agent_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def memory2str(memory:ConversationBufferWindowMemory):\n",
    "    messages = memory.chat_memory.messages\n",
    "    memory_list = [\n",
    "        f\"Human: {mem.content}\" for mem in messages \n",
    "    ]\n",
    "    memory_str = \"/n\".join(memory_list)\n",
    "    return memory_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(text:str):\n",
    "    Answer_agent_executor.invoke({\n",
    "        \"input\":input, \n",
    "        \"global_context\": global_context, \n",
    "        \"enriched_prompt\": Enriched_prompt_output})\n",
    "    conversational_memory.chat_memory.add_user_message(text)\n",
    "    conversational_memory.chat_memory.add_ai_message(Answer_agent_output)\n",
    "    return Answer_agent_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mGiven the enriched context and the focus areas of Alejo and Bartek at Fasterise, it's reasonable to infer that their meeting discussion revolved around the strategic integration of AI technologies within Fasterise's current and upcoming projects. Specifically, they likely deliberated on how to effectively apply RAG, LLMs, and Multi-Agent Systems to enhance the KnowledgeNow and Personalized Outreach System projects. This aligns with Fasterise's overarching mission of leveraging AI to amplify human potential while adhering to ethical AI development principles. Their conversation would have been a blend of technical planning, operational strategy, and possibly, the exploration of new AI applications that could further Fasterise's goals of operational efficiency, improved customer experience, and societal impact through AI innovation.\n",
      "\n",
      "### Key Discussion Points:\n",
      "- **Integration of AI Technologies**: Alejo and Bartek likely discussed the technical aspects of incorporating RAG, LLMs, and Multi-Agent Systems into Fasterise's projects, focusing on overcoming challenges and maximizing the potential of these technologies.\n",
      "- **Operational Efficiency and Customer Experience**: They probably explored strategies to enhance operational processes and customer interactions through AI, particularly within the KnowledgeNow and Personalized Outreach System projects.\n",
      "- **Ethical AI Development**: Given Fasterise's commitment to ethical AI, their conversation would have included considerations on how to ensure these technologies are developed and implemented in a way that aligns with ethical standards and amplifies human capabilities without replacing human work.\n",
      "- **Future AI Applications**: They might have also discussed potential new areas where AI can be applied to drive societal impact, in line with Fasterise's vision of exploring transformative AI applications across various industries.\n",
      "\n",
      "### Conclusion:\n",
      "Alejo and Bartek's meeting was a strategic convergence of their expertise in operations, sales, development, and engineering, aimed at advancing Fasterise's mission through the thoughtful integration of AI technologies. Their discussion underscores the company's commitment to innovation, ethical AI development, and the pursuit of projects that not only enhance operational efficiency and customer experience but also contribute to societal betterment through AI.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the enriched context and the strategic roles of Alejo and Bartek at Fasterise, it's clear that their meeting was a significant discussion on the integration and application of AI technologies within the company's projects. Drawing from the global context of Fasterise's mission and the specific areas of expertise of Alejo and Bartek, we can deduce that their conversation was both technical and strategic, focusing on how to leverage AI to amplify human potential while adhering to ethical AI development principles.\n",
      "\n",
      "### Meeting Discussion Overview\n",
      "\n",
      "- **Integration of AI Technologies**: Alejo and Bartek likely delved into the technical specifics of incorporating RAG, LLMs, and Multi-Agent Systems into Fasterise's projects. Their discussion would have covered the challenges and opportunities of these technologies, aiming to maximize their potential to enhance the company's offerings.\n",
      "  \n",
      "- **Operational Efficiency and Customer Experience**: A significant part of their conversation probably revolved around using AI to improve operational processes and customer interactions. Given the ongoing projects like KnowledgeNow and the Personalized Outreach System, they would have explored strategies to make these systems more efficient and user-friendly.\n",
      "  \n",
      "- **Ethical AI Development**: Consistent with Fasterise's commitment, Alejo and Bartek's discussion would have included considerations on developing and implementing AI technologies ethically. This involves ensuring that these technologies augment rather than replace human capabilities and adhere to ethical standards.\n",
      "  \n",
      "- **Future AI Applications**: They might have also discussed exploring new areas for AI application that align with Fasterise's vision of societal impact. This includes identifying opportunities where AI can address complex challenges across various sectors, furthering the company's mission of leveraging AI for societal betterment.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The meeting between Alejo and Bartek was a strategic alignment of their expertise, focusing on advancing Fasterise's mission through the thoughtful integration of AI technologies. Their discussion highlights the company's dedication to innovation, ethical AI development, and the pursuit of projects that enhance operational efficiency, improve customer experience, and contribute to societal betterment through AI.\n",
      "\n",
      "This synthesis of their meeting underscores the collaborative spirit at Fasterise, where team members bring together their diverse skills and perspectives to drive the company forward in its mission to amplify human potential with AI.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the enriched context and the strategic roles of Alejo and Bartek at Fasterise, it's clear that their meeting was a significant discussion on the integration and application of AI technologies within the company's projects. Drawing from the global context of Fasterise's mission and the specific areas of expertise of Alejo and Bartek, we can deduce that their conversation was both technical and strategic, focusing on how to leverage AI to amplify human potential while adhering to ethical AI development principles.\n",
      "\n",
      "### Meeting Discussion Overview\n",
      "\n",
      "- **Integration of AI Technologies**: Alejo and Bartek likely delved into the technical specifics of incorporating RAG, LLMs, and Multi-Agent Systems into Fasterise's projects. Their discussion would have covered the challenges and opportunities of these technologies, aiming to maximize their potential to enhance the company's offerings.\n",
      "  \n",
      "- **Operational Efficiency and Customer Experience**: A significant part of their conversation probably revolved around using AI to improve operational processes and customer interactions. Given the ongoing projects like KnowledgeNow and the Personalized Outreach System, they would have explored strategies to make these systems more efficient and user-friendly.\n",
      "  \n",
      "- **Ethical AI Development**: Consistent with Fasterise's commitment, Alejo and Bartek's discussion would have included considerations on developing and implementing AI technologies ethically. This involves ensuring that these technologies augment rather than replace human capabilities and adhere to ethical standards.\n",
      "  \n",
      "- **Future AI Applications**: They might have also discussed exploring new areas for AI application that align with Fasterise's vision of societal impact. This includes identifying opportunities where AI can address complex challenges across various sectors, furthering the company's mission of leveraging AI for societal betterment.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The meeting between Alejo and Bartek was a strategic alignment of their expertise, focusing on advancing Fasterise's mission through the thoughtful integration of AI technologies. Their discussion highlights the company's dedication to innovation, ethical AI development, and the pursuit of projects that enhance operational efficiency, improve customer experience, and contribute to societal betterment through AI.\n",
      "\n",
      "This synthesis of their meeting underscores the collaborative spirit at Fasterise, where team members bring together their diverse skills and perspectives to drive the company forward in its mission to amplify human potential with AI.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the comprehensive insights derived from the enriched context and strategic roles of Alejo and Bartek at Fasterise, it's evident that their meeting was a pivotal discussion focused on the integration and application of AI technologies within the company's projects. Drawing from the global context of Fasterise's mission and the specific areas of expertise of Alejo and Bartek, we can conclude that their conversation was both technical and strategic, emphasizing how to leverage AI to amplify human potential while adhering to ethical AI development principles.\n",
      "\n",
      "### Meeting Discussion Overview\n",
      "\n",
      "- **Integration of AI Technologies**: Alejo and Bartek engaged in a detailed exploration of incorporating RAG, LLMs, and Multi-Agent Systems into Fasterise's projects. Their dialogue likely spanned the challenges and opportunities presented by these technologies, with a goal to maximize their potential in enhancing the company's offerings.\n",
      "\n",
      "- **Operational Efficiency and Customer Experience**: A significant portion of their conversation was probably dedicated to leveraging AI to streamline operational processes and enrich customer interactions. With ongoing projects like KnowledgeNow and the Personalized Outreach System in mind, strategies to augment these systems for greater efficiency and user engagement were likely discussed.\n",
      "\n",
      "- **Ethical AI Development**: Aligning with Fasterise's core values, the discussion between Alejo and Bartek would have encompassed the ethical development and implementation of AI technologies. This includes a focus on augmenting rather than replacing human capabilities and adhering to ethical standards in AI development.\n",
      "\n",
      "- **Future AI Applications**: The conversation also ventured into potential new domains for AI application that resonate with Fasterise's vision for societal impact. Identifying opportunities where AI can tackle complex challenges across various sectors was likely a topic, furthering the company's mission of leveraging AI for societal betterment.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The meeting between Alejo and Bartek represented a strategic convergence of their expertise, aimed at propelling Fasterise's mission forward through the thoughtful integration of AI technologies. Their discussion is a testament to the company's commitment to innovation, ethical AI development, and the pursuit of projects that not only enhance operational efficiency and customer experience but also contribute to societal advancement through AI.\n",
      "\n",
      "This synthesis of their meeting highlights the collaborative ethos at Fasterise, where team members unite their diverse skills and perspectives to advance the company's mission of amplifying human potential with AI.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the comprehensive insights derived from the enriched context and strategic roles of Alejo and Bartek at Fasterise, it's evident that their meeting was a pivotal discussion focused on the integration and application of AI technologies within the company's projects. Drawing from the global context of Fasterise's mission and the specific areas of expertise of Alejo and Bartek, we can conclude that their conversation was both technical and strategic, emphasizing how to leverage AI to amplify human potential while adhering to ethical AI development principles.\n",
      "\n",
      "### Meeting Discussion Overview\n",
      "\n",
      "- **Integration of AI Technologies**: Alejo and Bartek engaged in a detailed exploration of incorporating RAG, LLMs, and Multi-Agent Systems into Fasterise's projects. Their dialogue likely spanned the challenges and opportunities presented by these technologies, with a goal to maximize their potential in enhancing the company's offerings.\n",
      "\n",
      "- **Operational Efficiency and Customer Experience**: A significant portion of their conversation was probably dedicated to leveraging AI to streamline operational processes and enrich customer interactions. With ongoing projects like KnowledgeNow and the Personalized Outreach System in mind, strategies to augment these systems for greater efficiency and user engagement were likely discussed.\n",
      "\n",
      "- **Ethical AI Development**: Aligning with Fasterise's core values, the discussion between Alejo and Bartek would have encompassed the ethical development and implementation of AI technologies. This includes a focus on augmenting rather than replacing human capabilities and adhering to ethical standards in AI development.\n",
      "\n",
      "- **Future AI Applications**: The conversation also ventured into potential new domains for AI application that resonate with Fasterise's vision for societal impact. Identifying opportunities where AI can tackle complex challenges across various sectors was likely a topic, furthering the company's mission of leveraging AI for societal betterment.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The meeting between Alejo and Bartek represented a strategic convergence of their expertise, aimed at propelling Fasterise's mission forward through the thoughtful integration of AI technologies. Their discussion is a testament to the company's commitment to innovation, ethical AI development, and the pursuit of projects that not only enhance operational efficiency and customer experience but also contribute to societal advancement through AI.\n",
      "\n",
      "This synthesis of their meeting highlights the collaborative ethos at Fasterise, where team members unite their diverse skills and perspectives to advance the company's mission of amplifying human potential with AI.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:\u001b[32;1m\u001b[1;3mGiven the comprehensive insights derived from the enriched context and strategic roles of Alejo and Bartek at Fasterise, it's evident that their meeting was a pivotal discussion focused on the integration and application of AI technologies within the company's projects. Drawing from the global context of Fasterise's mission and the specific areas of expertise of Alejo and Bartek, we can conclude that their conversation was both technical and strategic, emphasizing how to leverage AI to amplify human potential while adhering to ethical AI development principles.\n",
      "\n",
      "### Meeting Discussion Overview\n",
      "\n",
      "- **Integration of AI Technologies**: Alejo and Bartek engaged in a detailed exploration of incorporating RAG, LLMs, and Multi-Agent Systems into Fasterise's projects. Their dialogue likely spanned the challenges and opportunities presented by these technologies, with a goal to maximize their potential in enhancing the company's offerings.\n",
      "\n",
      "- **Operational Efficiency and Customer Experience**: A significant portion of their conversation was probably dedicated to leveraging AI to streamline operational processes and enrich customer interactions. With ongoing projects like KnowledgeNow and the Personalized Outreach System in mind, strategies to augment these systems for greater efficiency and user engagement were likely discussed.\n",
      "\n",
      "- **Ethical AI Development**: Aligning with Fasterise's core values, the discussion between Alejo and Bartek would have encompassed the ethical development and implementation of AI technologies. This includes a focus on augmenting rather than replacing human capabilities and adhering to ethical standards in AI development.\n",
      "\n",
      "- **Future AI Applications**: The conversation also ventured into potential new domains for AI application that resonate with Fasterise's vision for societal impact. Identifying opportunities where AI can tackle complex challenges across various sectors was likely a topic, furthering the company's mission of leveraging AI for societal betterment.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The meeting between Alejo and Bartek represented a strategic convergence of their expertise, aimed at propelling Fasterise's mission forward through the thoughtful integration of AI technologies. Their discussion is a testament to the company's commitment to innovation, ethical AI development, and the pursuit of projects that not only enhance operational efficiency and customer experience but also contribute to societal advancement through AI.\n",
      "\n",
      "This synthesis of their meeting highlights the collaborative ethos at Fasterise, where team members unite their diverse skills and perspectives to advance the company's mission of amplifying human potential with AI.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "chat({\"input\":\"what are the things they said about the project knowledgenow\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
