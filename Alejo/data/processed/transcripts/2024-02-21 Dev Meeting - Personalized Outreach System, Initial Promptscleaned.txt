Speaker 3
Yeah, that'd be interesting. He was on the board of Pepsi and Burger King and the CEO of Holbus and transformed them. He's done a lot, which is crazy.

Speaker 1
What an opportunity. I totally picture you, like, asking a lot of questions over, like, two days, and then at the end being like, okay, so here's the deal. This is what we built for you guys.

Speaker 3
Yeah, definitely. It'll be interesting, though. Part of me was expecting him to be like, sorry, we're really busy at the moment, because, as I said, they're laying off so many people. So it will be really interesting to see what the dynamic is like at the top when they're making decisions like that.

Speaker 3
I think I'll just brainstorm loads of ideas and what I saw on the news. Like, I did some research on the company, and one of the articles I read was one of the bosses saying, AI won't take over jobs. But I think they mean in terms of customer experience. I don't think there's anyone at the company looking, doing AI stuff.

Speaker 1
Oh, that's interesting. What an opportunity, man. Let me know when that is, and we'll prep you with a demo.

Speaker 1
So, for right now, we have been diving into two projects. The massive outreach and the knowledge base builder.

Speaker 3
Yeah, I was just doing some of that now. I'm interested in what you're trying to figure out in the knowledge base builder and the problems you're facing there.

Speaker 1
There's two dimensions to that. Number one is figuring out Nan's code. And then number two, making it work, because it's not just reading the code, it's making the whole thing work.

Speaker 1
To answer your question, Henry, part of what we're trying to figure out in a conceptual way is how do these two play together? How does the context and the company story play with what happens at each meeting? So, what does that look like in practice? Is the context part of a master system prompt, or is that just part of the retrieval augmented generation? That's part of what we need to figure out.

Speaker 3
With the context, when do we need context? If it's, for example, having the context as a tool to use is something, is the way I see it, and being able to know when it wants to use that tool. If I said, how has alejo changed over or grown over a certain amount, maybe then the context is useful. I think the context should be a tool, just like sense.

Speaker 1
Contextual executive summaries will be created based on the company context. We're placing the concept that more context is going to allow these active information sources to become more specific. It builds on the story, and that there's coherence because the core story, the core context is always given when created these documents. We need to figure out if it's just a portion of the vector database or if it's part of the initial prompt.

Speaker 2
I make the prompt creation matrix complete. It was for PFA initially, but then I thought merging that into the PFA prompt is going to take me a week or so. Why not do it as a separate GPT and call it dimensions? And basically, that's what I did.

Speaker 2
I've been working with PFA on the agentic outreach system prompts. For the knowledge base builder, I also got a dope prompt and I wanted to test it together. I wanted to focus on the agentic outreach system because I think it's more interesting at this moment. So let's get this outreach system rolling.Speaker 1
About what you want to do. Nice. Okay. 

Speaker 2
And also I notice in the actual call up, I don't want to switch to that now because it's just waste time. But you guys probably remember that in the output, for example, the question was missed. It was giving you thought and action in the output of the reasoning of the agent. So I was thinking maybe the chain of thought is not working correctly. But even though we get the URL, so task is achieved. 

Speaker 1
Okay. 

Speaker 2
It's just me being perfect. It's just me being perfectionist. Yeah. So always it's good to emphasize on the importance of the bolt and stuff. I don't know if you guys want to test it because we got this thing working. So maybe I just go to the next one. 

Speaker 1
Yeah, do test it. Yeah. 

Speaker 2
This is get URL. This is the person profile. 

Speaker 1
How do you verify that this is the right person, that this person, if two people share the same name, that you're picking the right one. 

Speaker 2
Oh, it's actually PFA thought about it. I didn't know if we want to use that, but PFA thought of something like this. This is something that wasn't in the prompt before. 

Speaker 1
Yeah. Okay. Let's figure it out. 

Speaker 2
So if we would have the criteria, because I was thinking for what if we just give the name? So how does it actually verify the name? Let's say there is two persons with the same name on LinkedIn. Let's say. And then which person we want to have, right? 

Speaker 1
Yeah, go ahead. 

Speaker 2
I'm thinking if we want to have this verification, we would need to have some set of criteria how we want for example, we want people from that industry or whatever, or specific role or industry actually can be whatever, but just have some criteria. 

Speaker 1
Yeah, sometimes we'll know the person's company, sometimes we won't. What we always have is our story, the company story, the context, and maybe, hey, between the three of these LinkedIns, which one is the most relevant prospect to us? Fasterize and it has the context of the company story. So that was one way that I was thinking that could be achieved. Regardless, even if we don't have the company name or the email, most times we actually will. Most times we will have the company name or the email of the person. And that's how we could verify in LinkedIn. So I wouldn't stress about this step too much. It's awesome that we have this backup to do, but when I make the relevance action work on its own. Sorry. Not as an action, but as a function call on an assistant API. 

Speaker 1
I don't think we'll need any of this. But it's really cool that we have a backup. So we can actually use this as a backup or even as the main one if we find it's that effective. So this looks great. Let's try it. Let's see. Let me send you a name and we can test it. 

Speaker 2
I wouldn't test it. Maybe now, because you are getting URL versus getting URL, we get the same result. We would need a test case where we actually have some person that have LinkedIn clone, let's call it. So we need a different test case than we have now. I'm assuming the person we have now, as the input, doesn't have another person who has LinkedIn with the same name. 

Speaker 1
That's what I'm trying to find right now. A name that is popular. 

Speaker 2
Yeah, we can do it like this. But I'm thinking also from the way of prioritizing the time, I don't know how much time you guys have. So I still got three more prompts to go over and also something about the knowledge base. Okay, transcript Sandy, you can just leave it as a task for later. I will share these prompts and maybe you can test them later, I think. 

Speaker 1
Okay, yes. Let me just send you what I found and you can test it later. The name is Bill Miller and there are multiple ones, and one of them is the owner of a vacation rental. So you can check it out there. 

Speaker 2
All right. We share those things on Discord. Or we have some space for this, like a project space or something. 

Speaker 1
Let's see. Yes, there is. Okay, there I tagged you cool. So next one. 

Speaker 2
Right? Next one we got as I create the personal profile. So on the left is the version as is. On the right is the new version. It's mostly just specifying more like it's giving your task to extract instead of extracting information. So it's a little more guiding to the AI and also the markdown. The most interesting thing is actually in the next prompt because I took this to the separate prompt, separate agent and show in a second. I'm just thinking if there is something interesting in here because I just make it like 30 minutes ago. So really go deep into what's in this prompt because I go straight to icebreaker prompt. 

Speaker 1
Yeah. 

Speaker 2
It seems to be just because in here we have just markdown and little upgrades, but in here we have something more. So we have the ensuring of the final output is single JSon without any nodes. So it's just like strongifying. I don't know if there's a word like that, but I used to think like it's making stronger the instructions. 

Speaker 1
Strengthening, yeah. 

Speaker 2
Excuse me for my English sometimes. 

Speaker 1
Oh, you're fine. We're learning together. 

Speaker 2
And then it's giving another. Your task is crucial for personalizing outreach efforts. So it's giving like overarching goal. It should be also probably headerized like this overarching goal or something like that. Whatever. Overarching next is icebreaker here. We don't have comparison because it wasn't in the as is. So yeah, actually the most exciting thing is how I make it. I will show you in a second. Let's go over the prompt here because this was using this new matrix. 

Speaker 1
Okay. 

Speaker 2
Although it doesn't have much of because it was inspired by PFA brainstorming. Like, one prompt was PFA. Let's brainstorm what will be the outcomes of the icebreaker agents scenario. So this is basically the benefits. This prompt still needs a bit of work because this is basically the benefits from the brainstorming. And then put into a prompt and put into a structure. But generally I think it will work great. Just need some little more work to make the more detailed Persona. But in general, I was thinking if should make some communication style frameworks, methods and stuff, cultural, contextual considerations. Also the relevance, the interest based. This is, I think, like types of the icebreakers. So interest based. This is about the communication. Again, there is some examples of some industry trends and stuff. As I'm reading this, it still needs more work. 

Speaker 2
It was just looking good as the first glance, but it still needs more work. And I really like this .7. Suggestive collaboration. It was based on the idea of PFA. First was to make it like a predictive collaboration, something I really like that finds potential areas for future collaboration or mutual interest, laying the groundwork for professional relationship. So something like expertise aligning with the current project. So, yeah, I think it still might need more deep dive digging. And I will just maybe. Okay, this is also the prompt for the transcript. There is something. I don't know if you want to go over this now. Maybe we'll go over it later as I will dive deeper into the. 

Speaker 1
That was for what. 

Speaker 2
This one? This is for displaying. It's for the transcript. 

Speaker 1
Oh, cool. Okay. Did you use the original prompt and put PFA on it, or did you just go from scratch? 

Speaker 2
It's PFA. I'll just maybe share the browser again. Okay, this is the browser. About the agentic system. Yeah, so just to clarify the previous thought, this was the brainstorming. So after it make upgrade like the usual upgrade without telling what to do, just upgrade. So adding markdown and clarity, more emphasis and stuff. I ask it to brainstorm the possible outcomes of icebreaker generation, being separate agent with more detailed prom laser, focusing on communication and icebreaker relevant stuff. I sometimes do like this if I don't want to really think about the specificity of what I want to do, just say something like, give me relevant stuff to something like this. And then it just goes with ideas. And then this is basically those outcomes that got later incorporated into the prompt. So I maybe mispronounced it here a little. 

Speaker 2
I should maybe specify more that this should be just inspiration and not exactly transferred to the prompt, but I was just making it in kind of rush. So yeah, I will just need to do some of it in the evening. And here I call the prompt creation matrix separate GPT to get that all together and actually is the last message so we can give feedback. I meant for you to inspire from the outcomes after. Also proceed with detail, as in, oh, I forgot pin here. 

Speaker 1
I'm glad you stepped into multiple agents. Now. I think that it's the way to go. 

Speaker 2
Yeah, definitely. The prompt maximum length was very constraining to me, actually. Most of work was about not giving new ideas to the PFA, but making the prompt optimized so it fit in the 8000 character window. 

Speaker 1
Yeah. 

Speaker 2
So I often just brainstorm ideas, put some things in the prompt, and the prompt was instead of 8000, it was 18,000 characters. And then I had to trim it down again to the 8000. Characters while trying at least to keep most of the functionalities. 

Speaker 1
I would very much encourage you to start breaking up into multiple agents because you have some very clear separate steps. Very clear separate steps. 

Speaker 2
Yeah, I actually have it on my whiteboard. So this is like a middle of the process we see right now. 

Speaker 1
Cool. 

Speaker 2
Because I plan to make TDD fears, then context enrichment, something like scope, maybe, of the prompt that will give a very detailed process for the developers. But I don't think everyone would like to use it. So I assume everyone would start somewhere in the middle where we have the PFA latent space. So I think it's like an orchestrator, of course, situation after the initial context, where the context enrichment is now in the PFA latent space. But I want to take this function out to another GPT and then the base model kinda will function better because we'll have less clutter of the information because now it has so many functions, so many different things it can do and it's sometimes messing up. 

Speaker 1
Yeah. 

Speaker 2
In here. I didn't specify to make it in the code box and I'm thinking if actually it's looking good, but not exactly as I wanted. The Persona should be personification offer expert. 

Speaker 1
Okay, I have to go. I'm actually going to an AI talk that pages aren't invited us to. And there is a risk that the person that is invited to talk might not really know what the fuck they're talking about. And they're going to be teaching, which makes me very nervous. But we're going to go learn and actually talk with people face to face, which, as I found, is the best way of selling. I'll keep you guys updated on that. Meaning that the outreach meeting for later today, we will postpone tomorrow because we have actual in person outreach to do. So we will prioritize that. 

Speaker 3
That's really interesting company. 

Speaker 2
Did you guys see this? What happened here? 

Speaker 1
It's a real estate group. 

Speaker 2
Okay. 

Speaker 1
And I'm excited to tell you guys more about that. What happened there? Yeah. Was it just referring to the previous coded road? That right. 

Speaker 2
Where I give the prompt, I give it the whole cell from the Google collab, so it has a little context on the inputs and outputs. For example, it got some upper. I don't know if we have time for that. You need to go. So I'll just quickly paste it. Paste it in here so we can see it in a full glory. I never seen a prompt like this. This is something new. 

Speaker 1
Your chat. 

Speaker 2
All right. 

Speaker 1
If you do shift, click when you're sharing screen. You can do multiple. 

Speaker 2
You see the Vs code now? 

Speaker 1
Yeah, so we totally got it. 

Speaker 2
This is like kind of programmatic prompt. I like to use variables in the prompt. 

Speaker 1
That's great. 

Speaker 2
This is like a next level. 

Speaker 1
Well, that's exactly what we want. As long as we find the icebreakers that make sense, that are natural, that are human. We could have a bit of that small, superficially programmatic. But I'm curious to let it run. I'm curious to let it fly and see what cool shit it comes up with as opposed to limiting icebreakers to a certain format. But it is interesting that you're bringing it up the format. 

Speaker 2
Yeah, definitely needs some thought. And I will just merge it with the previous one and see what I come up with merging the best parts of both and we'll see how that's going to work. 

Speaker 1
Cool. Bartek, I have a question. I'm trying to sort of essentially copilot the repo for the audio to transcription to knowledge base project. What tools do you guys use for an AI to look at your whole project and be able to answer questions? Because I get a strong feeling that replit, for example, will only look at the document that you're working on and it only grabs that context. So I'm not sure if I have five files. How do I make it so the AI will answer questions in reference to all five files? 

Speaker 2
You're referring to having a code assistant in the repository. 

Speaker 1
It could be that. I just need to figure out how to troubleshoot what is not currently working. 

Speaker 2
All right, so you want to put the repository for the AI analysis or something like that? 

Speaker 1
Yes. 

Speaker 2
So I think we should try some of the codes assistant because I think the latest version, as I'm aware it was somewhere late last year. The code whisperer or something. The Microsoft one? Definitely. It was the Microsoft one. I don't remember the name. It could be the code whisperer and it has the ability to get the whole repo and kind of read it and understand. I'm not sure if this is correctly exactly this one, but some of them definitely can get your whole repo and just go over it. And for being like, honestly, this repository isn't that big. I think we can just also copy all the code into some. I don't know if it should better. Yeah, first it should better to try the code assistance, and then second, if that doesn't help, we can try to make either. 

Speaker 2
Just try talking with PFA, for example, and giving just by hand all the files and have it make sense of it. Or we can try to use rag for that. I'm not sure how better rag would be like vector database. How better that would be for getting the whole context because of the similarity. Do I just evoke the similarity parts to the query and then don't give the full picture? That's what I'm imagining, but maybe I'm wrong. Maybe it could work, but I would keep it as a tiered option. So first let's go with the AI assistant that can read the whole repo, hopefully. And then other is just so much a GPT or PFA and just giving the files. Yeah. And then third part would be rack for me. 

Speaker 1
Okay, awesome. Thank you. 

Speaker 2
One last thing I want to show you is the prompt for comic, the knowledge base prompt. So it's actually your prompt from where you are testing the PFA overseer. So I just got that from that link I got to the conversation and I actually use it for testing at some point of latent space. When it was first version of latent space created, I actually used that for testing. This is actually with the creation matrix. So that's why it's so long, because this is the first output of the PFA. And then I ask the prompt creation matrix to deepen this prompt using matrix. And then it goes to make it like twice longer. Okay. Wow. And it's where more details. There is not only mission, but as I told you, there's deeper matrix. 

Speaker 2
So in the matrix is mission and it contains purpose, scope, expected outcomes, relevant, sectional, BT. Actually there is more. There's like around six for every header and it's choosing most relevant. And then in here is the relevant part of the prompt. Yeah, we'll have to test that. But also I think there was some magic in the PFA overseer because there was this thing that we are so excited about for the content that you got excited that you could invoice that. Do you remember actually what that was? It was some contextual understanding. Yeah, something like that. 

Speaker 1
What are you referring to. 

Speaker 2
When you are first testing the PFA with this idea? Maybe I'll just dig it up again from our conversation. 

Speaker 1
What I remember is that zoom thing where it got the audio, the idea for finding important parts of the conversation by the tone of the voice in the audio file. 

Speaker 2
Oh yeah, that one. 

Speaker 1
That's the one that blew my mind. And that was like the first time I used it. 

Speaker 2
Yeah. I'm curious if it also came up with this. 

Speaker 1
Okay, I got to go. Tomorrow, let's definitely continue working. Today we have a lot of stuff to do. Thank you for these prompts. These are great. They're going to be super useful tomorrow. I'm going to be working on this company story thing. So we'll get together, Henry and Paige, and we can sort of bang out a conversation in which we just get the story down. It's like, hey, here's the context of who we are. Products we've done so far, products we want to do, period. 

Speaker 3
All right, cool. 

Speaker 1
Sounds good. 

Speaker 2
I got one question, because I want to deep dive into the agentic outreach system on the call up, and I've seen there is the API key in there, so I assume I can use it, right? I can just run it how much I want and just test. 

Speaker 1
Yep, yep, you're good. 

Speaker 2
All right. 

Speaker 1
Thank you for asking. 

Speaker 2
All right, so I think I'm just good to go. I copied the call up to my account so I can. Don't mess up the main part. 

Speaker 1
That's a great idea. 

Speaker 2
And I will just try to use those prompts in there and let you know tomorrow how it works. 

Speaker 1
Okay. 

Speaker 2
All right. 

Speaker 3
Thank you, guys. 

Speaker 2
Yeah, thank you, Sia. 

Speaker 1
See you, guys. Bye. 