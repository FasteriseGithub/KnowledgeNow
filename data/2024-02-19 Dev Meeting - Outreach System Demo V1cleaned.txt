Speaker 3
We never really talked after I took the full time position. Much doing company I was working for before needs some help, and so looks like I'm going to be pretty involved. 

Speaker 1
In that for a while. Cool. That's awesome. To the same capacity as to. As of right now or more than full time? 

Speaker 3
The contract is full time, but spending way more time. 

Speaker 2
Not much. Apart from this week's been slow. I had to put my dog down, so that wasn't actually that great.

Speaker 2
And then I've just been reading, learning, working, I guess. 

Speaker 1
Cool. What you been reading about? 

Speaker 2
Mindset by dweck. So growth and fixed mindset. 

Speaker 1
That's awesome. Yeah, Paige and I did a lot of mindset work, certainly. Well, this camp, we had two trainers who are just top of the line facilitation coaches. And it was transformational for sure. The camp itself was for teenagers in Bermuda, and it's around personal development and social and emotional development. And a lot of these kids come from very rough backgrounds. So it was very interesting from creating a rapport with people in very different backgrounds that any of us grew up in to helping them sort of find the key points or key experiences in their lives that have made them who they are. And at 1314, what to do from that point on as they start developing self awareness. 

Speaker 1
And they start getting into more risky situations in difficult backgrounds and kind of this empowerment to look at the choice in front of you and make the, let's say, more useful choice for your. It was. It's a fascinating thing that pages organization works in. So honored to have been there and getting like one one coaching with these amazing trainers. 

Speaker 4
I have my V one ready of the agents. So that's what I've been doing online chain. 

Speaker 1
Cool. Are you able to show us right now? 

Speaker 4
Okay, can you see my. 

Speaker 1
So did you mention you're ready to show us the demo you have so far? 

Speaker 4
Yeah. 

Speaker 4
So. So this is my library. I'm using Google collab because I'll load the libraries in slow form. I'm just losing libraries. Just give me a minute. So I'm going to import all the libraries, the Google sub for creating it. 

Speaker 4
The OpenAI chat module, the agent executor, the prompt templates, and also import all of that. Taking a while because my network is slow. 

Speaker 1
Yeah, no worries. Take your time. You can start walking us through the code while everything installs. 

Speaker 4
All right, so these are my API keys to check the log of my agents and to check token usage. So my API keys. So like a class I created for extracting the top three searches from Google self API. So what actually does. Okay, this is my tool I created for agents. Let me go to my prompt so you can actually understand. Okay, so this is the prompt template I created. So I'm telling the that I want you to get the URL link to the person's LinkedIn profile page. The answer should only contain a unique profile. So this I created is what contains the search result from my Google set API. Do you understand? 

Speaker 1
Yes. Following. 

Speaker 4
So this is just like chain of thoughts. This is the import and this is the agent scratch bob. So I created like a prompt template here. I created my tools, I chose my llm, I created my tools, I kept the prompt. So this is the agent. I'll just, I just need to type the person's name. Like this is Demi Asabi, the CEO of DeepMind rather. So it's going to search Google and return only the URL of the. 

Speaker 1
Great. Awesome, awesome. 

Speaker 4
So for the LinkedIn script, I use proxy code that I told you about. So I defined a function that uses the LinkedIn. The result I got as like the URL I got. So I used it to extract details about demi Asabi using the proxy call API. So this is the result. It returns details about demi Asabi. I created another prompt to extract the details and format it. The full name of the person. A little bit of introduction project that the person involved on the experience. The topic of interest of the person based on the data I'm getting from proxy code. This is the output here. I'm using LLM chain for that. So this is the result here. I created another tool before the two year. So I imported the knowledge bees or pastries. 

Speaker 4
Yeah, I'm trying to create a lead qualifier based on the information I got from proxy call. I want to do qualify the lead if it's ran with our something like that. If based on the data I got from proxy call, the person aligns with fast price. So I imported our knowledge. I split it into chunks. I split it into chunks. I created it too for the analyzer. I created the agents for it. So this is it. This is the results. 

Speaker 1
Okay. I like the icebreakers idea. That's a great idea. 

Speaker 4
Jimmy Asabi is the perfect match for our company based on his profile information analyzed with our strategic intelligence. Based on this, I created another agent to write the email using our knowledge bees like information about our knowledge bees and based on information we got about the Miyasabi. So this is the prompt for writing the emails. This is the result. I'm reaching out to introduce you to our company pastries, which is at the forefront of innovation in artificial intelligence, giving an impressive background in artificial intelligence, machine learning and communication science. Your role, I believe there is. So it goes on like that. Our team at focusing on automation, data analysis, and market optimization. 

Speaker 1
And is this the writer agent that's writing this or is this after an evaluator? 

Speaker 4
The writer agent. 

Speaker 1
Okay, awesome. 

Speaker 4
It writes the email and I got the output. Then this is the evaluator. Then I created the prompt asking it to review the email. This is just so this is the input. This is the email generated. So the email is well written and personalized, addressing the recipient background and expertise in a toxic manner. However, there are some areas that can be improved to clarity, engagement and relatability. Identify areas for improvements. The introduction could be more concise. Immediately captures the recipient attention just talking about the. So it's giving us suggestions. 

Speaker 1
Yes. This is great. This is great. 

Speaker 4
That's what I've been up to. That's all for now. 

Speaker 1
Hey, that's fantastic. Great job. Great job. What are your, what are the next steps in your opinion? 

Speaker 4
Yeah. Thinking of recreating or using long graph because landgraph is more flexible. 

Speaker 1
Flexible in what way? 

Speaker 4
Your concept, like now, you can create nodes and edges. The agents can think of the next agent that is meant to under the tax based on the user input. 

Speaker 1
Yeah. 

Speaker 4
Something. It's more flexible to build agents, but I've not really dived deep. I'm just like laying because it's a very new concept. 

Speaker 1
Yeah, for sure. Well, great job. There are some really good gold nuggets in there. Like the icebreakers. Feel very natural. Simple enough, but very natural. The tips of the critic feel very on point, feel very relevant. To make that email better, expressing conciseness, besting relatability, we have to make sure that the writer, agent and the critic can talk to one another back and forth. That might be a next version kind of situation where a writer, critic, writer, critic, writer. Just like a couple of loops might be more than good enough for now, if not just one loop before we start adding layers on and actually doing a campaign for ourselves. So actually sending these out to whom there's a strategic, we're going to be talking with advocates today. 

Speaker 1
And part of this clarity that we gained over this past week is target market for some of these tools, some of what you just showed where right now in reality we're just using it for ourselves? So what if we can leverage not only this tool for ourselves, for massive email campaigns, but also start making content out of it which will essentially by itself help us create reputation credibility building in public? So we'll get to that point. So let's focus on the very much right now, how do we make this massively runnable, meaning not on Google Colab? And would this be running the same program in parallel through a list of names, for example, that finds their Linkedins? Or maybe they can input their Linkedins and we just have this program running a lot in parallel?Speaker 4
I was trying to get an API. If I could get an API, I could make it work. I asked him about it and said, you're not around so I could not use the profile analyzer IPA. 

Speaker 1
Okay, which we're talking is as simple as could be as simple as transferring this to an assistant API and have that running by itself as opposed to GPT and we can start interacting agents with each other. That is what you mean, right? Kuba having the agent available through an API? Yeah. 

Speaker 4
Yeah, that's what I mean. 

Speaker 1
Okay, then make relevance actions into tools for assistant API. Great. Okay, want to pause that for now? And we'll focus on these three items, which is figuring out how to run it in parallel. Actually, once we figure out how to run this in parallel, how do we verify that we have the right LinkedIn account and make relevance actions into tools for assistant API? Defining the right LinkedIn account brings the question of like, well, how do we even find these leads in the first place? How do we get these names? And if they come from different lead lists, then we would have some other resource like their email or maybe even directly their LinkedIn. I don't see that as a main blocker. We can find the right LinkedIn account with very little problem. 

Speaker 4
The LinkedIn account is a very good one because I tried searching for some otoman but it was returning different searches of some Otoman LinkedIn accounts. It was not like the real Sam Otman. So I think the problem. 

Speaker 1
Okay, cool. What else is something that during this week we'll need to solve. In order to have this one step closer to productionized. 

Speaker 2
We'Ll need it linked to an email sender, because we don't want to copy and paste everything. 

Speaker 1
No, we do not. So we have access to the instantly API, which would satisfy that, right? 

Speaker 2
Yeah, sure. 

Speaker 1
Okay, wonderful. We'll get that linked. We'll revise prompts. Great job on the prompts, who are simple enough, straightforward, easily explainable. Let's make sure that they're at production grade and leverage what we have, which is prompt factory, which I think I noticed you might have used in one of the prompts. And it looks really good. So we'll do revision of prompts, which include PFA, adding examples of good to better. This is a good email, but this is an even better email. Give it some examples. The faster ICE bio, which is going to be part of essentially the majority of the context. Okay. So that is quite a few things. We have the massive personalized outreach. Okay, and this last point links to the other project we've been talking about, the knowledge base builder. And, man, I'm excited about this one. Okay. 

Speaker 1
There's a lot that I want to say. Let me just concise it. Pages of the organization has been building a knowledge base for several months, and they didn't even know that they were building a knowledge base. They are surprisingly well set up to have a system that will intake all of this information, which goes from, how do you create a day program for a summer camp? Let's say, imagine a leadership program, a leadership summer camp. How do you create the schedule for the day? From that to how do you create a speech for each key talk? What do you do when you have all these videos of people actually doing the keynote talks? All theory, which also comes, which is very interesting, because they have theory, which they won't follow on purpose, but that is a good foundation. 

Speaker 1
This is theory, and this is how it looks like and feels like and sounds like in the real world when a professional actually does it. This is the framework that they use. All of this is in this big spreadsheet that line by line depends into, honestly, all the details. Hey, we're talking about balance, which is actually the keynote talk. I did. And I did actually a technology space, a technology open space, which was student lest led discussions on the pros and cons of technology. And there's a theory of how to go about that talk, and then there's how we did in practice. And in that it includes, hey, these are different experiences that the kids can actually go through in a kinesthetic way, that they can feel the experience. These are the outcomes. 

Speaker 1
This is the outcome of this experience is for the kids to gain awareness of the choices that they have with technology. And if you have to start from scratch for any of this keynote talks, you're wasting 2 hours at least figuring out where to start and creating an initial draft. But you have all the. They have the knowledge base, and the owner's eyes literally widened when they realized, oh, wait, we can create a good draft and then make it masterful and save ourselves so much time and so much cognitive work. Because they are the masters, they know how to make it masterful, but they don't really need to spend as much time doing an initial draft. So, guys, it seems like we have our first pilot, free but man leverageable. 

Speaker 1
And the testimonial for this, the branches that we can go through this is substantial. It might be our intro into the education industry, or simply, hey, this is what our technology can look like. This is how a first representation of this is how we can put our vision of how companies can work better into reality. And here's their testimonial. So let's review that system real quick, and there are shifts to make. And Avi, I am so glad you're here, because we've been having all these conversations over the last few weeks, and there is a lot to figure out. There's a lot to figure out in a very exciting way. Very exciting way. Let's see if Zoom lets me. There we go. 

Speaker 1
So, I don't know that I've walked you through this one, Abi, and it's been a couple of weeks since I looked at this. Let me keep it simple. Right now, we have a system which will take the transcripts, will take the audios of our meetings, create transcripts with timestamps, create a semantic cleaner, remove everything about the transcript that doesn't serve any purpose, like us catching up, step into a kind of opposite, critical conversation analysis, and then create a contextual executive summary. So what does this executive summary look like? Well, we have our purpose for our meetings. And within each department, a general meeting has a different purpose than dev meeting. So that contextual, that's where that comes in. Okay. 

Speaker 1
This is one system, one subsystem that we almost have up and running that I will fight my hardest to have up and running this week. But there's some two tangents to this, which is the pre context, the company story, who we are as staff, strides all the people that we have and what each person does, each person specializes in. The clients are our ideal customer profiles, clients that we're working with, clients that we're hoping to work with. How does that context feed into what is a relevant contextual summary? That's obviously a redundant question. So with the context of our company and the information from our calls, how can we make useful things out of that? Obviously, having everything vector database, and maybe even in a traditional database, we can step into those details later. 

Speaker 1
We can have, say, a massive outreach system that we can rely on because we know it reads our brand, it understands our brand, it understands what we're looking for. Our ideal customer profiles, maybe it uses a Persona, let's say Alex Promosi frameworks that it can leverage. So these essentially three systems, one, two, you can't really call this a system, but anyway, the components, and three, the actual application is what I envision will be our core product. From there, different things come. But what if we can have this for clients that we work with as a base? And then, oh, hey, I need a massive outreach system. Okay, great. We already have everything that you do, the products that you've done, the context of your company, the history, the people that you have in there, and your ideal customer profile. 

Speaker 1
This is just one step as opposed to, hey guys, we have to design a whole massive outreach system like we did the first time. We started thinking about this massive outreach system from scratch. What if it was the other way around and we can just think about it for ourselves, not about a hypothetical customer that we'll have just for ourselves. Once we have this, what else becomes possible? So that's what we're going to keep developing. And I'm going to stop sharing screen. And when you mentioned about, well, one of the steps for this massive outreach system, revising the prompts is very much tied to the rest of the project. Having a fasterized bio, having examples of good and better. What are the next steps for this knowledge base builder? We're going to pause on that. 

Speaker 1
And once I have a bit more clarity on where we're at, where it's needed to have this up and running, we'll production exit because I could tell you a few things that are going to work on it, but I don't want to lose you guys in lack of context. So I'm going to put out something visual and we'll go from there. For now, I think we have our hands busy with the outreach system and actually getting to test it and such. But as I'm saying that I realized Puba is putting a lot of time into this. 

Speaker 1
So I'm curious, Henry, Avi, if we're to keep it simple, if we're to keep it focused, which of these two projects, which could be the massive outreach system or stepping into the knowledge base builder, which, although there's code and very powerful code, and a lot of these components are already written, it's a bit of a more abstract thing that we're working on. We're not exactly sure what the final product looks like yet. Which one calls your attention more to work on more of the creative design? Let's put it together and then start writing the code or the. We know what it is, it's email writer and we've created the sophisticated system, et cetera. What's your attention? 

Speaker 2
I'm happy to do a bit on both, to be honest, because also whilst you're away, I did those deep learning AI courses on pine cone and rag searches, semantic cleaning, and that's what stuff I can take a look at, find really interesting. So probably that one calls to me more the knowledge base, but I've also been involved in the personalized outreach for a bit, so I do want to see. 

Speaker 1
Cool. You mentioned you started the course or you finished the course. 

Speaker 2
I think I've got like two modules left, but I can get them done today. 

Speaker 1
Well, I guess returning your advice to all of us too, let's do the Feynman method and teach it to us this week. 

Speaker 2
Okay. 

Speaker 1
Even just a one pager. What you learned is going to be very critical. I'll share something after this meeting that I think we all need to be on our toes about, which is along the lines of fine tuning, model fine tuning, LLMs. We were thinking about a paid client. I doubt that they'll go with a vanilla version of GPP four, even if with personalized prompt. But that's something else. I'm getting way ahead of myself. I'm going to share a cool resource I learned, period. If you can summarize what you learned and walk us through some of that, maybe with code, even maybe conceptual. Yeah, that'd be awesome. 

Speaker 2
I'll do it on notebook. Supersonic notebook and just cool. 

Speaker 1
Yeah, great idea. What about you, Avi? 

Speaker 3
Yeah, so, terms of time to contribute, I don't have a lot, but if you need any help with trying to plan out any of this effort, or trying to figure out what components need to put in, how do they interact with each other, things like that. Happy to help out. 

Speaker 1
You're reading my mind, which is what? 

Speaker 3
I guess the purpose for joining this call was to just let you guys know that I don't have time for active development. Cool. And I think we discussed this right at the start. I didn't know how long I would have for being able to contribute a lot. And so yeah, I'm happy to help in whatever way I can. Like for the knowledge base builder, I think, I don't know just what Kuba was talking about, but he mentioned something about using graphs where you have nodes and relationships. I think that's a good thing to explore. I think Microsoft is doing something along those lines with all of their information they collect on clients. So they build for each of their companies using all of their products, which is like Windows OS, their docs, their cloud storage, their email, their slack messages. 

Speaker 3
They have the platform for all of them. And a lot of companies that are not too technical. I've not experienced that in software development companies, but business companies, a lot of them use Microsoft products for their entire stack. So those companies, it's a good sale to make for Microsoft where you already have all your information. With us we can for this additional paid service organize all of your information, answer questions that are relevant to your business in a smart way because we know everything about the business already. Yeah, so they mentioned in one of their talks having like a knowledge graph for all of the information they have on their system. 

Speaker 1
Okay. 

Speaker 3
Which is another reason to explore that route. 

Speaker 1
Use vector data to explore the Microsoft route. 

Speaker 3
You mean just using graphs to figure out how do you want to structure your knowledge? 

Speaker 1
That's right. 

Speaker 3
What do you want to store? What relationships do you want between knowledge based stores? How do they interact with each other? Like when do you access one particular type of knowledge base? You don't want to just put everything in one vector data store, just dump everything in there and expect things to work. Well, I don't think that will, at least in the current state. It's just too much information I don't think will lead to anything valuable. What you need to think about is what is the information you're trying to store in each knowledge base? Like what is important, when do you access it? And then you create a relationship around that. So when you need this sort of information, this is where you go look for it versus if you needed something about information about your internal employee profile, then you go look here. 

Speaker 3
If you want something about your business customer, like target clients or what your business does, there's this other store you look at. 

Speaker 1
It's ease. 

Speaker 3
Separating those makes it easier to keep them clean and make sure the information there is useful is valuable. And you can have mechanisms to add to it that are gated by humans where you don't necessarily change, like have any random meeting or anything like that, adding to what your business does if it's not appropriate. But you can if it's appropriate. That's why you have the gate. So it might be like, oh, from this particular meeting you decided a pivot where your company is going to start shifting focus. And that comes out as like a gated request. You update your company's like what it does sort of knowledge base and things like that. And sometimes vector based database may not be the right answer. Just look for the appropriate source. For you'll want embeddings, but not necessarily just take chunk of text, put it in. 

Speaker 3
You'll need a lot more metadata. I don't know if Davis. I think Ahmed and JFK may have been working on other sources of retrieval which are not just like semantic search, but using metadata or having additional metadata stored along with embeddings. If you've not done that already, definitely worth looking into it. 

Speaker 1
Yeah. So right now the length of the metadata is what type of meeting is it? Dev general marketing outreach. I really like what you're bringing up. It makes a lot of sense and it totally hits again. I could talk 1 hour, 5 hours about the vision that is becoming clearer for these sets of products. This essentially suite of products rooted in a knowledge base. How do we make it so the sales manager and the CEO ask the exact same question and get a wildly different response. The information that gets accessed is different and you just gave the key of how you do it, what you create dates of what is considered relevant. Yeah, go ahead. 

Speaker 3
For this question, you phrase specifically. It sounded to me like they wanted the same information. But how does presentation differ? And that could be the retrieval part of it, right. So the knowledge source is the same, but the agents that go that get the way it gets consumed and the agents that. If you're doing multi agent systems that access that information, that part could be different. If you're using a single LLN to do more, the prompt would be different. Or like the assignment of what needs to be done would be different to either function, calling to the same source and then parsing it in different ways depending on who is the target audience. And those could be other agents you could access when required. If you're making a single interface. 

Speaker 1
Yeah. Okay. I'm very excited that we're aligned on how to best use your time. Makes me happy that it works for both of us. Okay, wonderful. I'm going to go to the drawing board and put some stuff up, share it with you guys on Wednesday. Avi, we'll adapt to your schedule, and whenever that time is, we'll make it happen. 

Speaker 3
Yeah. So if it's okay, I'm probably not going to be doing regular meetings. I hopped on today because most of the people on my team are in the US president's day off. 

Speaker 1
Cool. Yeah, we'll figure it out. We'll figure it out. Thank you for letting me know. Yeah. So, Guba, Henry, let's connect. I'm going to share these notes in the dev discord chat. Let's. Okay. Let's figure it out right now. What is the immediate next step for Kuba to be one step closer to productionizing a few things. 

Speaker 2
Running, we've got to decide how do we run it? Do we run it a thousand leads or one lead at a time and then going from there, and then you've got to get the endpoints, like link up the instantly just to test it out. It would be a first good step. 

Speaker 1
Okay. Yes, that would be a good first step. Henry, could you look into the instantly API? Yep. Awesome. Henry, on the instantly API, I will look into making relevant actions into tools for the assistant API so we get a little more flexibility out of this and not just tied to the chat GBT environment. How do we verify we have the right LinkedIn accounts? We'll table that for now, because as we get more leads, they will likely come with that information, if not just the email. And then from there it's easy and running in parallel. Running in parallel. I doubt that's going to be one of our bottlenecks. And then I'm trying to remember the steps of your colab is an environment that we could all access. So if Kuba shares that notebook with us, we can just run it. 

Speaker 1
And it's one of the most reliable ways to run code without having machine compatibility and all that bullshit. So let's keep it there for now because it's working. Let's also think about where are we going to have it when we have it in production, and we actually want to go test it in parallel, et cetera. And Kuba, what do you need? That doesn't mean any structural change. Keeping the flow, the structure and the classes very similar to what you have right now. What is your next step? To level up the system. 

Speaker 4
He's moving into Langra. Sorry, there's a little bit of noise here. 

Speaker 1
Sorry. 

Speaker 4
So my next step is moving into Langraph, where I'm going to be using new design edges. So that's what I'm trying to figure out. 

Speaker 1
Okay, awesome. So Kuba, dive into Langraph and we'll figure out where it fits. Avi, would if you could share any resource of this gated information access that you mentioned for us to look into, that would be awesome. 

Speaker 3
I don't know if one exists. It was just a suggestion of what to build. I haven't been as involved in this space since. For the last month, almost a month. So maybe there is a tool for it and I just don't know about it because I haven't been in this space. 

Speaker 1
Cool. Great suggestion. Let's look into it because that feels like a very good path to the applications of the knowledge base where one of the requirements would be access this information. This is the only relevant information right now. Or these two sources have the relevant information. Focus on that and nothing else. As opposed to, as you mentioned, having everything jumbled together into one single base. Let's look into that. 

Speaker 3
Simple suggestions for what to do. 

Speaker 1
If. 

Speaker 3
You'Re building something automated for the meeting, as an example, the meeting summarizer as an example, you have something that triggers when a new recording gets uploaded. It processes that information, and if it identifies that a specific knowledge base needs to be updated. You could have a separate trigger which could just be a notification, an email. Like if you want a human in the loop, it can be some sort of notification to the advocates or whatever you want that it would like to make this change to this doc. That's an option. But you can go in any way. It could go be as simple as update a spreadsheet with a bunch of requests or send a notification to specific people. 

Speaker 1
That is such a good idea. That is such a good idea. Yeah, because we wouldn't just want the system to decide when the fasterized bio gets updated, but we do want it to get updated. So let it trigger a message and email asking for confirmation of these changes. That's a fantastic idea, dude. Okay, wonderful. That helps bring stuff together very nicely. 

Speaker 3
Yeah. You could also go fancier or less fancy. Like the spreadsheet would be less fancy if you have a doc that gets constantly mapped to a vector database. I don't know if Google APIs supports this, but if it does, for example, Google, when you are editing the doc, has an option called suggesting. I don't know if that's accessible through API. If it is, that's another option. The other is creating Redline docs which is a document where there's some formatting indicating what is the change you're suggesting from the original doc which is redlining it. This is the change kind of thing. Chat GPD knows what that is and can create an updated version of that doc. 

Speaker 3
So you have this original create a red line version for what you want to change and then it will have a new doc and you can just compare and see if you want to. 

Speaker 1
Yeah. Okay, cool. Oh man, that's so vital. It's going to be critical component. Okay, we're at an hour, we all have clear immediate next step. Let's reconvene tomorrow for a working session for sharing and anything that comes up. We can continue to chat. You guys, I'm excited to be back and I'm excited to move forward. 

Speaker 2
Me too. 

Speaker 1
Let's do this. Thank you, Avi. Thank you Kuba. Thank you Henry. 