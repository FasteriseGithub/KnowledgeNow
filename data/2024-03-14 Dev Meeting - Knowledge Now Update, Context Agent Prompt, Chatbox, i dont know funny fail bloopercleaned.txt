Speaker 1
This was a bit of an exercise to gauge where you're standing and how you're feeling with this specific challenge. Prompting is something that we all need to be very comfortable with. So this is good to know. As we standardize how we evaluate competencies, Powell actually worked on a competency matrix. It's going to be very good for us to know how we want, each of us, what skills do we want to have six months from now, but also which skills do we need to work on over the next six months? And some of us also need to keep working on prompting.

Speaker 1
Tell me a little more about where you are, where you feel you are skill wise. Maybe you've built some sort of project on Python and is Python what you want to focus on or is it something else?

Speaker 3
My python is. I think it's good enough. I surely know basic, which is enough for me. Rest I can do with GTP Python. I know enough to handle that language. From the python side, I think it's okay. But I have to dive into specially that language things. How to build that every step by step. Line by line? 

Speaker 1
Yeah. Okay, then let's step it up. A few questions. Did you and Cuba get a chance to connect over this last day? 

Speaker 3
Last day was Internet connections problem, but we scheduled this for today. 08:00 p.m.. 

Speaker 1
Okay, cool. So, Kubi, you're going to build on your end what Kuba is building on his end? There is something. And were just with Bartek and Powell talking about building systems that are resilient, that a year from now are working at the same quality, even better than they're working today. And that's very hard, especially with AI, especially as models change, especially as industry standards change. So we actually have in parallel been working on three different MVPs now, four different MVPs for knowledge now because we're taking different routes.

Speaker 1
Each MVP, each at least attempt at an MVP is showing us very different things about what the final thing is going to be. That being said, when you connect with Kuba, he's going to show you the code. You obviously have seen the logic in the Figma and we're going to build the first few steps, being able to upload the documents to a pine cone database and being able to query the documents. So the challenge is going to be is number one and I'm going to write this down. Number one, not copy the code. Number two, querying pine cone. Number three, creating some tests of how you would define a successful retrieval. 

Speaker 2
Test or I was just adding here whenever you have to think of something creatively and you kind of don't have idea, it's not like you need to do it all by yourself. Trying to do here I think is like don't copy the code from Cuba but write your own code. But you can ask chat, GPT for example, what test I should write, what I should test even. There you go, how the query should look, right? You can at least use AI for assistance.

Speaker 1
I'm actually referring to knowledge now. 

Speaker 1
Written for that Cuba. Starting writing the first part, right, the uploaded document to pine cone and then query the database. The queries are going to change with the PFA rag extractor agent, right? So the queries are going to become automated. But it's been made clear that Rag is what every single person that is in AI needs to get specialized in, needs to get better at from wherever you are better and I have two resources I'm going to share with all of us, that we're all going to read. 

Speaker 2
For example, I don't know how much this code is, maybe it's just a portion. So there could be two ways of looking at this from Hubert perspective. So one thing I imagine if you, Hubert, have some kind of blockade to write the code. I don't know if you already throw the outreach system cells into PFA for explanation, but what you could do is maybe you start from what Kuba has already written and put that the knowledge base system I refer to now and put that into PFA, explain line by line, but then start to make it from scratch and not look at the lines of code. Just try to read the whole reasoning for this cell that PFA gave you and then close this window and try to write the code yourself. 

Speaker 1
That's what's going to become valuable. Thank you, Bartek. That is such a good point. It's the systems design thinking that is going to be the most valuable thing once AI can write all our code. Even with PSA, right. If you don't have the objective clearly in mind and an idea of how to get there, how will you know when it deviated from the objective? So, great suggestion. Do it with PFA. 

Speaker 4
My update is I fixed the API issue yesterday and I wrote some fonts I could show you. 

Speaker 1
That would be great, man. 

Speaker 4
Let's go.Speaker 1
Hey, do we send it to the merge agent self refinement agent to knowing what to do next and making decisions on refining agents based on priority and the big picture? Okay. It's not wrong, but there were other branches. We talked about the merge agent and it didn't mention the merge agent, so. Cool. The QA agent is going to be really good for the V two vartech. The QA agent is going to be good for partly creating these tests for the rag and evaluating the output. What is another test? Sorry, Bartech, are you talking? We can't hear you. 

Speaker 2
I was muted on my computer. Yeah, I think maybe we should have TDD agent kind of. Because you're referring to the tests on the project discussed, right. Or on the knowledge based system itself? 

Speaker 1
On the knowledge based system on Monday when we designed the whole system and each agent. 

Speaker 2
Yeah, I think we got evaluators and stuff. I think it's already there. Regarding the knowledge based system evaluator, will be the QA supervisor. We got three agents for that. No, I was thinking from the output perspective of the use case. Then if we discussing projects, maybe we can have test driven development agent that will develop the test cases before the programmer agents get to their job. 

Speaker 1
Right. So that would be the programming module of like the tester, the programmer. Yeah, and we'll definitely get around to that. I'm really excited. Have you guys seen Devon? What? It's the newest thing and they're calling it soft AGI because it's a software engineer that just runs man, autonomously and it just runs and it creates the whole thing in its own environment. It has its own web browser. I'm going to send you guys a video. It is something like what we're trying to create, but this one is specialized for software engineering. Kuba, did you see it by any chance? 

Speaker 4
I saw. 

Speaker 1
It's worth checking out. It is insane. And it will give you guys a very tangible idea of what this branch of programmers within knowledgenow would ideally be able to do. But we can discuss that more tomorrow. Where do we go from here? You have a little, nice little chat box. We can ask the queries. 

Speaker 2
There is the contact agent. Sorry, do we have the context agent prompt? It's already in here, Kuba. Okay. 

Speaker 4
Let me check. 

Speaker 1
So if we can add in the context agent into this system, that would be a huge win. That would be a huge win. Let's see. 

Speaker 2
All right, here I am. 

Speaker 1
So Bartek, I'm having a hard time. Oh yeah, you shared in the GitHub. 

Speaker 2
Okay folder with the final version. It's live version or something like that. It's the folder because I make a little mess in this GitHub repo Bartech few working sessions. I mean working files. 

Speaker 1
Yeah. Let's make sure we keep version controlling. Kuba, there's two tasks that you are assigned to, which is integrating the context agent. But the agent is going to need context. So we're going to take it one level up. The context is going to be the fasterized document about who we are and we need to refine it. It needs work for it to work correctly. But let's integrate the context agent, and let's have a way to very easily, at least friction as possible. There's a new document, there's a new text document. Say it's a transcript, and we can just upload it easily to pine cone. Is that a upload button on the chat box? Maybe. Let's come up with a way that we can upload documents to pine cone easily. 

Speaker 1
If I am underestimating the amount of work that would take, let me know as you're working on it. And that's not necessary. But remember how we talked about the components and the subcomponents? Reducing friction is one of those important subcomponents. So maybe in that chat box there's a button to upload a document and that gets directly uploaded to pine cone. And now we would have more context to query from. Thank you, Bartek, for sharing that. 

Speaker 2
I dropped the link because it's on my branch, so maybe you couldn't see that in the first place. Okay, yeah. And this is the best version because I have few versions in there. I also got some working materials in there because I also have a few ideas where to go further with that. But I already spent like 3 hours on this prompt and I was like, okay, it's already good, man. It's already good. Stop doing. 

Speaker 1
I'm glad that, I'm proud of you for stopping yourself. 

Speaker 2
Would I have like three working files where we could explore further? Different kind of different functions, different world. 

Speaker 1
Yes, I see that. Cool. Let's keep it streamlined for now. And all of this is going to be incredible. Test data, each working file. It's going to be really good test data. Okay, let's go step by step because there's a lot of things to keep track of. System in it for knowledge. Now, AI agent context orchestrator. Right, I did see that. Lane. Space activation. Love that. Love that. We might want to, did you? Okay, yeah. Anyway, transcript analysis context enrichment context orchestrator latent space activation in multi agent system dynamic Persona for transcript analysis fix, extrapolate, upgrade data, enriching the AI slate in space and facilitating our best prompted engineering. 

Speaker 2
In the Vs code. 

Speaker 1
No, sorry. 

Speaker 2
It looks way more readable in the. 

Speaker 1
Markdown. 

Speaker 2
And you get those little highlights. 

Speaker 1
Yeah, that is cool about vs code. Just jumping through it though, wondering if you gave it some examples of latent activation. Just like the video that you shared. David Shapiro, latent space activation and that GitHub had. Actually, the examples had take a step. 

Speaker 2
Back, step by step. Yeah, he had this thing with the Romper or something like that. 

Speaker 1
Yeah. 

Speaker 2
I didn't quite see how that conveyed to the use case. This latent space activation is kind of similar to what I use in PFA. I upgraded it a little even and expanded because I had some new ideas while I was going through this. So yeah, it should just try to be relevant because we don't know what user are going to write in. So to be as flexible as possible, I make those kind of variables in the prompt. Maybe I will share my screen. 

Speaker 1
Okay, I see what you're saying. Request enrichment, and then we can have some variability protocol, thrill and Persona dynamically. Yeah. Okay. Before you share screen, Kuba, what clarity do you need about the tasks that you have assigned? Cool. Let's keep communication open. If something comes up, if you hit a blocker, let us know. Awesome progress, Kuba. I love that you added a text box. That makes it everything so much more tangible. Awesome. Okay. Yes. All right. 

Speaker 2
So as you can see, it looks a little different in here. It's way more readable. You actually see all those things that I highlighted by colors. So we're going for the user objective. So that's basically the input. And here this is the variables that are all relevant to what the user query is. And the goal is kind of like also highlighted. Yeah, I'm going to read this. All right. Now I just want to quickly show you guys what this is about. So this is basically like till here we got kind of briefing or in it, I don't say the full initialization. Yeah, I had a problem with speaking, but yeah, later we got steps. So those are the. Maybe some of you who use PFA are familiar with those mean, especially this one is from PFA. So those are the functions for enrichment. 

Speaker 2
And I go crazy with them. And I laid out whole process basically like that. And yeah, this should provide a prompt for the next agent. I still got some ideas in. Wait, the work in progress. Yeah, I comment in here that this could be. Let's see if we can get self refinement function or tool to work with this one continuous improvement loop. So this will be like kind of. Now those all are the prompt functions as I call it. And we could connect it with real function and make a tool that would be connected with the agents also to be done. I marked this like maybe we later want to have some output format to be passed to another agent. I don't know, maybe some kind of JSon or whatever. 

Speaker 1
But I left it for like JSon would be interesting. 

Speaker 2
So to just give you guys of my file structure. So this is like work in progress. So this will be like not finished prompt. Some ideas, some comments like in here and this is the work files. It's just ideas for different versions of things. Basically these are the steps. Version live is the one that this is for testing. Like live is for testing or after testing. Because I did some testing on GPTs. It was working fine. I'll show you guys in a second. And this is like some ready. I actually messed up a little in here because I make like this is ready and this is ready, right? So let's just agree that if there is prompts, live folder is those prompts that were accepted and those are kind of for testing, right? And this is like totally work in progress actually. 

Speaker 2
This is like all work in progress. And the live, I think it's safer, right? 

Speaker 1
No, it's great. So I just want to make sure we're on the same page. I'm going to share screen real quick. 

Speaker 2
I don't know how to stop the sharing because I hide the controls. 

Speaker 1
There you go. All right. You all can see my screen? Yeah? 

Speaker 2
Yep. 

Speaker 1
Cool. So, Bartech, we're going to have a prompt. We're going to have an initial prompt, just like what we asked for Cuba that know, what are the branches of the supervisor agent? And then along with the global context, which is just going to be a document, the PFA context enrichment agent is going to grab the prompt and the global context as a full document or rag query. The full document. Are we essentially copy pasting the full document into the prompt? 

Speaker 2
I don't think so. Maybe we could have like summary in the prompt. 

Speaker 1
Summary, but a summary would lose a lot of information. We could try SPR as far as priming representation. 

Speaker 2
Yeah, but maybe let's try rag and we'll see how that goes. See if it works. And it works. 

Speaker 1
Wouldn't that be too meta? Because now we're trying rag on a document and the prompt is going to be pretty much the same every time. So the rag is going to grab the same answers from the global context almost every time. Obviously the variation is the prompt. In that case, shouldn't we be like, hey, here's the global context. And it's like one page about Max. One page max about fasterized each team and each project. And it's like, hey, here's the context about the company that is asking, here's the prompt, enrich this prompt. And now we go into the rag sub queries. I think what makes sense to have global context and then not give it the context, right. 

Speaker 2
Should have context for each team or each use case of the knowledge. Now, for example, there is dev project, there is dev context, something like that. 

Speaker 1
For HD. That is part of the idea, yes. And part of what we have to figure out for a v two is at which point, is there a gate? Is there gated access? Maybe it's here where the rag extractor agent would create or create optimized queries based on. Oh, this is a marketing question. So only access documents with the metadata marketing. So that would be the rag extraction, because then it would know what questions to create that would create the knowledge base. If we do it too early, then. 

Speaker 2
We'Re losing coming back to the context. Because as I tested on the GPT, I think we don't even need that much context. Because the example, when I see the chat where I tested it, and I say like, extract info from the project and it just did a quite good job, I believe. If you can maybe share that on the screen now. 

Speaker 1
Yeah, let me try to find it one time, shared it on art chat. There we go. Did this one. Yeah. Step one, context gathering, enrichment request enrichment, semantic expansion. Great perspective enrichment. Lovely clarification query. 

Speaker 2
The final output is in the down. Like, you get the prompt that sent. This is all reasoning. And this is the actual prompt for. 

Speaker 1
You know what my issue is that giving the context as a meeting, prong, discussing a project, your task is to create that. It is very important that it knows fasterized. Who fasterizes? The teams that we have, the projects that we're working on. Otherwise, this is just generic. This would be good because PFA is amazing but limited. And when in the future we get to implement this for a client, we would need, essentially the description, the one pager of who they are. So global context. Nobody can debate the quality of the prompt that you made. Well, you can because you're a perfectionist, and I'm glad that you are, because we're building amazing things here. This is very high quality output. Team enrolls, list the key team members involved in the project. It should already know that. So let's put this one pager. We can start. 

Speaker 1
Very simple. We can start with, essentially the real estate one that says, hey, here are the projects, and here is how they relate to real estate. Maybe we can start tweaking it in that direction. I still have to work on a one pager for fasterize of like, hey, here's every team. This is what we're working on. But we do have that for real estate, so let's use what we have. It's very narrow, so we won't get too confused. But if there are some failure states, it'll become obvious what those failure states are. 

Speaker 2
Let's try running this prompt into what we have now into what Kuba made in the button. You have button in that? 

Speaker 1
Yeah, that's right. How do you want to do it? 

Speaker 2
No, just the thing that Kuba showed us. We can just put that in there in this chat. 

Speaker 1
Cool. Hopefully it doesn't break the context window of the chat. I'm posting this on the chat. Your message is too long. Okay, I'm sending you the link to the chat. Kuba. If you could ask that prompt. Ask a question into your chat box. I'm actually curious now. Good idea, Bartek. 

Speaker 2
Because there is quite a metadata that could be coming from how to say the etiquettes, how to say in English. It's a different word. 

Speaker 1
The metadata that is coming from. 

Speaker 2
This is dev meeting. This is the meeting. That's what I was thinking about. I just had the polish version of the word in my head because the etiquette is something like that in English. Like etiquette. 

Speaker 1
It's more of etiquette in English. Yeah. Means the right social of doing things. Social norms. Yeah, social etiquette. 

Speaker 2
For example, in Poland, this is the etiquette. How to say you want a product, have etiquette. All right, whatever. This is off top. 

Speaker 1
Often. 

Speaker 2
Goodbye with us. 

Speaker 4
Yeah. Let me share my screen, show you what I'm doing. 

Speaker 1
Yeah. Awesome. 

Speaker 4
My DSP. 

Speaker 2
Sometimes I think generally I was thinking of myself always like a good English. But the more I get into some more complex stuff, I'm thinking I should maybe go for some english lessons. 

Speaker 1
Honestly, this is great english lessons because you're forced to do English. And perfecting English is also about talking in English with english speakers. So you're coming to Bali. So that'll be a great opportunity to speak with a lot of english speakers. 

Speaker 2
Yeah. Actually, I already spoke with pace today that it's probably going to be postponed a few months because it'll be in Europe rather. So save some money and then later, after some projects start rolling and the money flows in. Definitely. 

Speaker 1
That's ironic because for me, going to Bali is cheap and going to Europe is expensive. We can see your vs. Code right now. 

Speaker 4
Okay. Just my, just my vs. Code. 

Speaker 1
Yeah. 

Speaker 4
Let's try it again. I've kept the prompt. So what do you want to up to? 

Speaker 1
Yeah, so that link to the chat GBT conversation that we put in the chat has a prompt. 

Speaker 4
You mean this one? 

Speaker 1
That should be it. Could you copy it and mark down? 

Speaker 4
Okay, are we prompting it or why is it as a prompt template? 

Speaker 1
Say that one more time. 

Speaker 4
Are we prompting it like prompts that testing with? Are we using agent or want to input it? 

Speaker 1
So the last link we shared in the chat has the whole conversation with this context orchestrator. And at the bottom of that conversation there's a prompt in markdown. 

Speaker 4
Yeah. 

Speaker 1
And we want to copy paste that into the chat box. 

Speaker 4
Okay. 

Speaker 1
Yeah, no, that's the one. Just making sure that it's copying the markdown instead of like dragging and copying, you know what I mean? Okay. Yeah, cool. Yeah, let's send it and see what happens. Let's see if it breaks. Okay, let's see. Project overview, project name MVP, use case objectives, develop a bot that sends two dues after meetings and allows clarification of assignments, scope checking, assigned valuables, tasks and team member capacity, significance enhancing, meeting summaries and project management efficiency, Cuba and then unspecified team members. Sure. Weird. Course experience in starting the rag system from a single document transcript. External stakeholders no specific mention the provided context. So it might not be taking enough immersion. But this is good. This is a good start. 

Speaker 1
Overall, the MVP use case project aims to develop a bot for post meeting to do clarification with a focus on enhancing project management efficiency. The team led by Kuba, lead at Kuba, is currently working on addressing challenges related to prompt structure by considering the use of markdown. That's definitely not how we are. Oh yeah, no, you did mention that Bartek. That's right, using markdown for the prompt. Future plans include implementing the bot functionality and exploring further improvements in using markdown. Feedback from the team emphasizes the important structure information for effective project management. Okay. 

Speaker 2
Well what model for this use? 

Speaker 1
GPD? 

Speaker 2
Four or 3.53.5? 

Speaker 1
Oh well, let's try the same thing with four and see what happens. The rag, though I might be tripping, but the rag query wouldn't change based on the model. Or yes, the actual words that are being asked to the vector database change based on the model. Or is it the interpretation of the answer from the vector database that changes based on the model? Because that is kind of what we're trying to solve with the rag extractor is creating better queries for the vector database. 

Speaker 2
Well, instead of thinking about it, let's do it. 

Speaker 1
Yeah. Is it clear what we asked? Yeah. If you can change the model from 3.5 to 4 January 25 and repeat the same question. 

Speaker 4
All right. 

Speaker 1
Bartech, could you start working on the rag extractor agent? That feels like the hardest problem, creating good vector database queries. 

Speaker 2
Yeah, the one thing I was wondering about, because I will have to make some research because I wasn't really using that much of vector database. I mean, I played around one time like three months ago, I was playing with pine cone. 

Speaker 1
But since then I have some resources for you. 

Speaker 2
Yeah, that would be useful. 

Speaker 1
Yeah. Thank you for the honesty. We can't all be experts at everything, but we can try. 

Speaker 2
Actually, we haven't even do much of rug at all. We just make automations that most of the time they rather generate stuff than answer stuff. Yeah, I've been focusing mostly on prompt engineering this past month. Really deep, deep into what you can achieve with prompting. And we most of the time do like make automation and then some prompting. That's the main engine of the automation in. 

Speaker 1
Right, right. We have committing the changes in Kuba, commit changes to GitHub and we can actually, it's cool that we can actually all test it. So cool. Okay, let us see what happens. Shut the fuck up, bro. Are you kidding me? It answered, I don't know. Fantastic job. And GBT four goes. I don't know, dude. 

Speaker 4
What? 

Speaker 2
The honesty. The honesty. 

Speaker 1
Maybe we shouldn't make models that are that honest. 

Speaker 3
Excuse me. I was gone for a minute and everything. What happened? Is it answered, I don't know. 

Speaker 1
We improved the model and now it answers, I don't know. Could you try one more time? Let's put stochasticity on our no. For a new chat because now it thinks that it doesn't know and it'll try to self justify itself. Another thing I learned from the David Shapiro video you shared. I guess you got to restart from terminal. Oh, yeah. Let's try running that one more time in a clean chat because, I don't know, it's not satisfactory. 

Speaker 2
For me. It feels like maybe there was some problem with rag. 

Speaker 1
And that's weird. Why? The rag extractor agent is priority. 

Speaker 2
Yeah. I'm also thinking how much of the heavy lifting can do PFA if we just give the document that's in the pancon to the PFA. Yeah. I think I can walk around my lack of the vector database querying skills by just giving the prompts for the context agent and redo this prompt to be querying this knowledge base. 

Speaker 1
But we can do better than that. Let's find some resources. I will send everybody some resources on good database querying and then we feed that to PFA. 

Speaker 2
Yeah. Awesome, Goldie. 

Speaker 1
Sweet. Yeah. And we learn while we're at it because I also need work on that. I think we all need work on proper querying. Avi would be able to teach us on that. Avi would be able to guide us. Oh. Live demos. How. I love you. You always fail. You always fail. 

Speaker 4
Let me. 

Speaker 1
Yeah, sounds good. Take your time. Well, we're already at 1 hour. Man, time flies with you guys. This is so fun. I want to make sure that I capture everything. Bartek, you are working on rag extractor. And Alejo, you are sending resources for Lang chain. Lang chain sending resources for rag querying. And we're going to keep it there. Hubby, I'm going to send you some tutorials, examples, colab notebooks that would be with a certain level of complexity to then try to replicate on your end. 

Speaker 2
Okay. Also, discord channel for this project. 

Speaker 3
Good idea. 

Speaker 2
Yeah. 

Speaker 1
Thank you. Thank you, Barta. Good idea. Very good idea. Otherwise we're blowing up the development channel project. Personalized? No, not personalized. Knowledge. Now, I think it's all one name, but let's see how I feel. 

Speaker 2
One word, don't know. Again, something is very wrong. 

Speaker 1
Yeah. Did you terminate the program and then. 

Speaker 4
Yeah, I think. Is there like a system prompt? Like a system prompt? 

Speaker 1
We need a system prompt. We need a system prompt. We need a system prompt. We need a system prompt. Okay, we need a system prompt. The prompt goes with the context into the context agent. Okay? Kuba. The system prompt is the context agent prompt. So we're going to add the system prompt and then we're going to have the user prompt be this question, whatever question we ask it, plus the global context or the other way around. The system prompt is the context agent. 

Speaker 2
Prompt, and then context agent as a separate prompt. And the system prompt is the context. The one pager, maybe you have some tweaks. 

Speaker 1
Okay, so I think we're kind of on the same page. But let's see. Go to figma and we can draw it out real quick. So this human input and the global context, the PFA context enrichment agent, the objective to fix an enriched prompt. So it's going to be the prompt that Barta came up with, system prompt. And at the end of the system prompt, and this is my ideal, we can talk about it. At the end of the system prompt is, here is the context of the team or company that is asking context document. Well, global context document. And then we put as input is the human prompt. So when this prompt is like, hey, what does the supervisor agent do? It would already have the context agent prompt. And at the end of the prompt. So these are one. 

Speaker 1
This is part of the system prompt. At the end of the system prompt, it would be, here's what the company is about. Now that you know what the company is about, here's what the human wants to know about. And human prompt, what does the supervisor agent do? 

Speaker 2
Looks good. I would just switch the global context to be first, like before the context prompt, because you need to know the context first to enrich the context. Okay, what you're saying after the prompt, this should be in the beginning of the prompt. And then the prompt goes, yeah. 

Speaker 1
Just so we're on the same page. Oh, I wasn't sure the screen was I. Oh, no, I was. Very quickly, Bartech. I just want to make sure, because this is a big difference. Fuck. Where is it? I lost it. Where is it? If you have to go. Okay, I found it. Knowledge. Now I'm sharing it, that the global context would be up here. The global context. Okay. Yes. Global context goes up here and now. It's like, hey, with this global context, this is who you are. 

Speaker 2
Yeah. 

Speaker 1
Okay, well, good things to test knowledge. Now, remember that we are going to test the placement of the global context at the system prompt. These are going to be fun to look back on. Okay. Yeah. Thank you, Bartek. 

Speaker 2
Or down or in the rack. 

Speaker 1
We'll see. 

Speaker 2
All right, let's continue this asking and send me the one pager. 

Speaker 1
We'll do. 

Speaker 2
Yeah. 

Speaker 1
All right. 

Speaker 2
See ya. 

Speaker 1
See you, Bartek. See ya, Kuba. We are going to, for now, put that big prompt as the system prompt of your agent. And when Bartech fixes that part, when Bartech creates that new version with the global context document, then we'll change it and then we'll go from there. Cool. If you could commit your changes to GitHub, that would be awesome. So we can all have access? No, you're good. 

Speaker 4
Could you share the resource for the route you mentioned? 

Speaker 1
Yes, I'll send it in the discord. 

Speaker 4
All right, thanks. 

Speaker 1
Cool. And Kuba. Hubi connect. And Hubi, your challenge is going to be to build the same. Well, build a similar system that Kuba built in your own words, in your own code. 

Speaker 3
Sure. I would be ready till evening. 

Speaker 1
Awesome. Let's keep going forward, you guys. 

Speaker 4
Bye bye. 

Speaker 2
Thanks. Bye. 