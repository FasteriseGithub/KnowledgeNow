Speaker 2
And then it print out the similarity score and the title with the header.

Speaker 1
Nice. What algorithm does that use? Just collaborative filtering.

Speaker 2
It just uses pine cone and.

Speaker 1
Okay, right, because of vector databases. That makes sense. Okay, cool. So can you walk me through the rag lesson?

Speaker 2
Yeah, I can try. This is one I did a while ago. So when you import the warnings, so you don't see the warnings, and you've got to import pandas and everything else, and then they give you. What's great about this deep learning AI is they use their own API keys.

Speaker 3
That's zoom settings, vector embeddings out of the articles. Then you will look at what search results look like by doing a simple document retrieval from pine cone. Then while working with OpenAI, you will build a nicely summarized article out of these results. All right, let's dive into the code. Now we're going to build a classic retrieval augmented generation.

Speaker 3
Hey, bartek engineering out of the responses from. Send those back prompt of OpenAI. And get back a beautifully written response from OpenAI.

Speaker 2
Let me just run loads of it. Max articles. Yeah. So that will give you the head of. So it will set up the database that will give you the head. Prepare the embeddings and upset to pine cone. So I'm not exactly sure what upset means, but I think it just means add stuff to you get your prepped array, and then you basically decide what's in the array, the metadata, and you'll see this command used a lot as well, most of the time. So there's the dimension vector count, total vector count. So every time you upset something, your total vector count will go up.

Speaker 2
Connect to OpenAI. And then if were to run a query, "What is the Berlin Wall?" After we just upseted a bunch of stuff, it will return text that matches anything. This is multiple pieces.

Speaker 1
It's intriguing.

Speaker 2
Yeah. So writing article titled get Embeddings query.

Speaker 1
Ok, cool. Interesting, right? Because that's the GT 3.5 instruct.

Speaker 2
Yeah.

Speaker 1
Very specific prompt start and prompt end, which used to be one of the pain points of working with these models.

Speaker 1
Thank you for showing me that. 

Speaker 2
I'm going to go through. Probably do each of these twice just because. Wrap my head around it. 

Speaker 1
Yeah, that's definitely one way to do it, especially for that rag portion. And also doing is 100 times more effective than watching. So it's awesome that you have that next to it. So as you go over the second time, how do we level up? How do we implement, how do we apply and apply to what? We'll think about all the documents we have and we'll figure out how all these lessons transfer. And it'd be really cool. These short videos we've been talking about making to be that. To be. Hey, this is what I learned in this lesson, and this is how it's relevant to our company. Right. Instead of the Berlin wall, we'll be asking about this. Instead of these types of documents, we'll have these types of documents. The principles are the same.

Speaker 1
So in two minutes we can have the person watching actually get, oh, this is how these concepts work in practice.

Speaker 2
Yeah. Do you have a pine cone API key?

Speaker 1
Then? If I were to run it's free. You can sign up. I'm using one for the transcript knowledge base system. So that account is now in use and you can just create one super easy and they'll give you a million vectors or something ridiculous. For free.

Speaker 2
Yeah, I thought the pricing was really high, though, on Pinecore.

Speaker 1
After the first one. The first one is free.

Speaker 1
Cool. No worries.

Speaker 1
What did you say?

Speaker 5
In a rush today.

Speaker 1
Oh, you're in a rush today. Well, no worries. We will keep this one simple and short. Okay, so I want to give you a bit of a refresher and dig into some of what we've been working on. Let's first. First, look at this one. And this is something that I've shown you before, so let's just do a quick refresher. This meeting is getting recorded, and I'm going through this system. I don't want to have to go through this system over and over again. So, one of the things that we came up with is creating transcripts and off of these transcripts with timestamps, clean up all the fluff, find the critical parts of this. Say we're here for 30 minutes, only the critical parts, and create an executive summary of, hey, this is how the knowledge based system works, and it's a bullet point.

Speaker 1
And that's our contextual executive summary. So, that is the 32nd version of what we have done so far with creating knowledge bases for ourselves. There's another component, which is context. The context of fastrise's story, the context of who's involved, and what each of our skills are. Clients we've worked with, clients we want to work with. Our ideal customer profile, that's all. Information that feeds into what? Well, that feeds into our applications. So, by having the context of who we are, what we do, who we work with, and having this contextual, summarized information of all our meetings, of each of our meetings, how can we mix those two?

Speaker 5
It's all understandable. Most of it I've seen already before.

Speaker 5
One thing I'm thinking now in high level picture, this is envisioned to be something like a situation in a company that buy this from us would be like, okay, they just want to have meetings, right? And then everything is done automatically. That's the end goal, to have just basically people meeting and then all the things considered on that meeting will be executed by AI.

Speaker 1
That's a great way to summarize it. Yeah.

Speaker 5
All right, that's great. So we're starting from just transcript analysis and then we're building up on top to have something like, I don't know, SaaS product. I see. This could be very expandable.

Speaker 1
Yes, exactly. So when it comes to finding the right focus of the product and the fit of the market, that is part of what we are going to be doing over the next few weeks. Honestly, over the next few months, we have some idea of what the ideal customer profile is. Think early, think medium sized startup, remote, majority remote startup already involved in something related to technology. And since they have everything remote, since they have everything on the cloud already, then what a great first few customers it would be for these startups that are already digital. First, we don't have to convince anybody of this is a good idea, just we are able to implement. We have to show how will we do that.Speaker 1
Hey, you're actually not following the framework, or you're following the framework, but this could be improved. So evaluate the effectiveness of the email. Leveraging the data analyst, making sure like, hey, which of these five insights are actually the most valuable? So to summarize, find the person on LinkedIn. Evaluate which pieces of information about their profile are actually most important and most relevant to us. Create an email. Evaluate the email. Rewrite the email. And when both critic and writer agree, the email gets sent. 

Speaker 5
Beautiful. 

Speaker 1
We created an initial prototype of v zero. I call it a V minus one because it's not even a V zero. And it was surprisingly good. Man. It was weirdly good. It was able to be funny, to be direct, but keep it simple, not use crazy language or anything. It was very nice. It's an email like, hey, we're ready to send this email. It was actually really cool. And we haven't sent that email yet. Henry. So we should definitely send that email. Question Bartek. A rhetorical question. The data analyst is supposed to find gold nuggets that are relevant to the email we would want to write. But how does it know what relevant means? 

Speaker 1
Well, what if we had a knowledge base that had relevant, up to date information about who we are, what we do, what clients we work on, what kind of products we've built and are thinking about building? So it has access through this knowledge base. It makes this application possible, not even possible. It makes it so the quality that we're shooting for is possible without this knowledge base, without the context creating this at the quality that we need to create, it wouldn't be possible. So that's how these two projects connect. 

Speaker 5
Yeah. One thing I'm thinking is whenever it should be exactly. From the meetings, the knowledge base for the outreach system, I think it should be more of curated knowledge base because I don't think it's like every meeting have impact on relevance to the sales. Right. 

Speaker 1
That's a point that most people have brought up as the first point. We've developed something to tag the different meetings between general sales, marketing and development and operations. So that's number one. Avi yesterday brought up, hey, when we're actually retrieving information. Yes, when we're uploading to the knowledge base, of course. But when we're retrieving information, if the CEO is asking about sales, we don't really want to step into the marketing knowledge base or the marketing knowledge base. We would want to step into operations because it's the CEO asking and he's asking about sales but not the other knowledge bases. They would just add noise. So that's one of the considerations that have been brought up that was very much on point. What else comes up to you, Bartek? 

Speaker 5
Let me think for a, I think nothing comes to my mind right now. I think I need to go deep into those projects and have my own some time about it thinking. And then I would bring up something definitely. Maybe we could talk about the stage of those projects. So we push to those. Foul one, foul two for that. Because I see the Asian is already thorough. Like you guys probably think that through so many hours. So to me to put something on top, I would have to really go deep into this. Oh yeah. To the agendic I'm thinking we could have more. But the general rule is if it works. So if you guys see that the outputs were good enough or even surprisingly good, I don't think we need to add more agents at this point. 

Speaker 5
Maybe we could add more agents in the future to make it because it's only adding more OpenAI calls for, let's say 5% better. Something like that. 

Speaker 1
Yeah. 

Speaker 5
So it might be not cost effective. And so the knowledge base. Yeah, I would like to see that the project, the call. Maybe then I can have some ideas later. 

Speaker 1
Yeah, let's start there. Why don't the. I'm sharing the code, the GitHub code with all of you. Check the discord. So I'm sharing the, okay, so check that one out and you can kind of read it on your own time. Henry, there's a lot of things that are not going to click yet because it's the latter parts of development, almost education. These are very technical things and commands that you've never seen before. And that's fine. You can go to the code within services within API. You'll find all the code and that's going to be python more understandable. Let's see, it's all lang chain. So if you were thinking about getting into lang chain, this would be one opportunity. And as you're trying to understand this, don't read it by yourself. Also use chat GPT to help you. 

Speaker 5
Yeah, obviously I will use PFA for that. Actually, I don't know if you guys aware, but the PFA can be used for everything. Now, the latent space version I use it for instead of normal child GPT. 

Speaker 1
Dude, that's awesome. 

Speaker 5
Literally everything I do with AI, with chat GPT I do with. 

Speaker 1
That's really cool. 

Speaker 5
And I noticed giving the non generic content more than usual chat. 

Speaker 1
Good. That's awesome. 

Speaker 5
But to this project, I was curious about this, how you guys make the self learning of self updating knowledge base. I had something about that. Is that already implemented or it's just like idea? 

Speaker 1
That is an idea. 

Speaker 2
Yeah, I did do it though, in voice flow. Okay. But that sort of basically just gets chat GPT to answer the answer and throws it into the knowledge base. But what you want to do is you want to iterate it. So for example, it would get the host of the actual chalet to answer the question and then you'd get that taken from WhatsApp or something and into the knowledge base. 

Speaker 5
But. 

Speaker 2
It'S not that hard. It depends what you're adding. If it's just general queries or if it's, I don't know, something else. But I know the flow in voice flow of how you do it. 

Speaker 5
I was thinking that maybe you guys make something like API to update the vector database. So every time new information is ingested by the AI, it would make an API call to update the vector base. 

Speaker 1
Yes, that would be along the lines of reimagining. There's also part of the discernment, the deciding what is worth adding and what is which Avi seemed to have fair grasp on. And I am sure that we can figure out, especially having PFA, because it's chat GBT discerning. Hey, this is the current, let's say the simplest one. Our project. Hey, this is a document that holds every project that we've worked on and that we are going to work on or currently working on. During today's meeting, did we talk about any new projects, looking at the transcript and looking at the dev document holding all the projects. Oh yeah, we did talk about a new project or. No, we only talked about previous projects. Oh, we only talked about previous projects and what new about each of those projects did we talk about? 

Speaker 1
Hey well, we found that there's a new client, potential client, for this one previous project. Is that something that we need to add to the dev document? No, because that's referring to sales, it's not referring to development. It shouldn't be too hard. Token consumption is not my worry, especially as cost keeps going down and as Ethereum keeps going up. That is not the worry. And by the way, Bartek, we talked about giving you an API key to properly test PFA to level that up. So hit me up, we'll get you a key and whatever. We'll figure out what that cost is. 

Speaker 5
Because. 

Speaker 1
If that is a blocker to leveling up PFA one more time from what it is now, which I would call, we've called good enough, more than good enough. If now comes a point where we need to test how thorough, how generalized, how effective it is, I'm more than willing to put some dollars into that. But that's just an aside. Didn't want to forget about that. Point being this gated information access is a concept we're going to continue playing with. For now. Let's have a rough V one. Let's have everything, one knowledge base. Let's do it as rough as we can and having as much information as possible in there. Let's put as much noise in there as possible, kind of on purpose, to see how, at what point is ineffective, how much information is ineffective. 

Speaker 1
At which point do we need to separate knowledge bases and say, if this is regarding sales access, sales knowledge base versus the one in everything in one knowledge base. 

Speaker 5
Yeah. For logical thinking, it probably would better to have many knowledge bases. But back to the previous I appreciate what you said, but I don't think at this moment it's a blocker. We can definitely go on to the testing, because this is testing the output prompts, this is definitely useful for us. I don't know if user, like a typical user would like to use the PFA to also test the prompt, or they just get the prompt and don't give a fuck and they just want to use it and whatever to the progress of the mean. It's good to have it, but it's not a blocker right now. I mean, I have still so many ideas to improve it. I have on my whiteboard the whole chain for the process should go. 

Speaker 5
And I still don't have even time to sit and actually think through this because the problem is that the prompt is so long and so complex. 

Speaker 1
It'S. 

Speaker 5
Actually being how to say it's tipping my maximal cognitive ability to understand the prompt. So it's very tedious and it takes like at least 4 hours to get in the development end. Okay, so that's why the newer version is not coming, because it takes a day, whole day probably, to make some work on top of this that's already in there. So that's the blocker. It's my time and capabilities. But yeah, I'm thinking we could do that. But there is also the subject of ICP and the subject of how we might sell it. 

Speaker 1
Yeah, for sure. That's definitely a big topic. 

Speaker 5
On the other hand, I think we can just do that for ourselves because the testing will beneficial for us first. Like for the developers. 

Speaker 1
Right? For sure. 

Speaker 5
So I think we could implement that on the site and just try using that not really thinking commercial yet, maybe just see how that goes. 

Speaker 1
Okay. Yes. And let's also think commercially and we believe we've had a few conversations already. We strongly believe that short videos showing it in practice, showing anything that we're working on in practice. Quick explanation. Here's the result. And this is why it's so good, is the best, most effective first step towards commercialization of any of our products. It's a very show not tell environment nowadays. So let's do that. A blog post is a great idea, but is that showing or is that telling? For me personally, I do not absorb the sort of almost kinesthetic part. I don't absorb the experience of. Oh, now I understand why PFA is so good by reading about it. But if you show me a video, it clicks a lot more. That's for me and I would argue for most of the world nowadays. 

Speaker 5
Yeah, I think I agree with that. Definitely with the younger generations. But the one thing that's a detail, but I heard on the other call I've been to that you want to make the 1 minute shorts. So there is one detail I've been known to as I've been doing some YouTube, not much, but some. And I've been educating myself and there is a rule because people who watch shorts are most of the time their attention span is very low. So it's best to make those shots around 30 seconds. 

Speaker 1
Now you're thinking. Yes, exactly. Because we can still do four shorts of 30 seconds each. Yes, you already got it. Yeah, that's exactly right. So we'll keep them extra short, extra impactful. And if you already have a blog, if you already started writing stuff around it, you already have the script, you just remove some intro sentences and you keep one sentence per paragraph. And that's your script and that's your video. 

Speaker 5
Yeah, can definitely think about that. I still have the article for you to read because I wanted to include our little story because I got inspired by the article you sent. They had a story about the pies. You had to have different story. So me and PFA came up with a story that was about the knowledge base and transcript AI. So I make the story that we have a project, we have a very soon deadline, and we had to extract something from the transcript, and we couldn't do that with normal promptings. And then out of nowhere, metaprompting came up and we make PFA. And now PFA got the thing that you were testing it first time. I don't know if you remember that. It got you the prompt for the transcript. That was something you couldn't voice before. 

Speaker 1
Yes, that's exactly right, dude. It was the audio analysis for finding critical parts of the conversations based on voice inflections. Yeah, I had it in my mind, but I couldn't find the words for it. And PFA found the words and added it into the know. 

Speaker 5
I think one the article can be about it, but also for the show. If we just recorded your reaction back. 

Speaker 1
Then, I'm pretty sure we have the reaction recorded. 

Speaker 5
Oh, so let's dig it up, man. 

Speaker 4
Yeah. 

Speaker 5
This is why we have a short already. We have a short. 

Speaker 1
That's my point, dude. So we will get together with marketing people, which right now it's pretty much jorg, and we'll come up with a plan. We'll come up with like, hey, this is the short video series for the ski chalet MVP. This is the short video series for PFA. And we'll keep it super simple. We'll keep it short, and we'll just start posting. That's just where it is. It's a really solid step in the right direction. 

Speaker 5
Yeah, I agree. I just have to make new version. 

Speaker 1
I don't think that you do, Bartech. I think that the new version is a wonderful thing to be maybe showing building in public and doing short videos about what you want to improve. You don't have to show the prompt. That's obviously intellectual property. But hey, I'm going to work on this and that, and maybe it helps you. It's a day to start developing one new idea for PFA. The best use of your time, and I'm going to let you decipher that. What we know right now is that we need you with us that we need your hands, we need your brain to put some, let's call it productionized touches on the massive outreach system and on the knowledge base builder. What is that going to look like exactly? 

Speaker 1
I'm not sure, but I'm going to send you a screenshot of what I showed you and give it some thought, see what you come up with, and we can talk tomorrow and dig further into how to make these systems what they will become, because they are what they are today, and they're going to become something different. And your brain is going to help us make one of those leaps. 

Speaker 5
Yeah, sure, you can do that. I'm just thinking, if we need more to look fist on the knowledge base or on the outage system, I will. 

Speaker 1
Let you decide what calls your attention more right now. 

Speaker 5
All right, so do we have a code base also for the agentic system, for the outage? 

Speaker 1
We will make sure that we get that today from Cuba. 

Speaker 5
All right, so I will look into the knowledge base first, and after I have access to no agency system, I will look there. 

Speaker 1
Cool. 

Speaker 5
Hopefully I will have time for today. Try to make it tight. Okay, we have something more to discuss. 

Speaker 1
Now, let's see. I don't think so. Just give me a second. Could you share the Google Colab system we have artec map of ab system. It's going to be this one. Okay. So you should have access to the maps that I just showed you on Figma right there. So check the development channel and what else? And then I sent the transcript to Knowledge base project GitHub already sent that. Okay. I'm going to pin some of these so they're always available. Okay. 

Speaker 5
On the finished note, maybe that's not for now, but for the later applications of the knowledge base. Because we've been thinking internally with Pavlo about something like chief of staff AI, keep us accountable, keep every task to be hanging until it's completed and pinging us around, because there is so much things going on, so much clutter around. And I think it'll be cool if everybody would have AI. That would be kind of, I don't know, maybe some people wouldn't like that, but being the manager of them, everybody should have its own AI. That this is your task for today. The situation in the company is like this. We need to prioritize this and this. You know where I go with that. 

Speaker 1
Yeah. I'm trying to find words to write it down because that's a great idea. Kind of like a personal business coach. Personal chief of staff is the role. 

Speaker 5
That does that because I've been googling that, like who is the manager of CEO and then the manager of CEO is actually chief of staff. 

Speaker 1
Interesting. Okay. That is one of the big ideas that we've had that we see immediate use for, which might include, hey, what was done yesterday and what was not finished yesterday. What do I also have to do today and what are some first steps? 

Speaker 5
Yeah, and most importantly, what's the priority? Because the tasks are just 1000 of them. You can just walk 24 hours a day. 

Speaker 1
Yeah. 

Speaker 5
There needs to be some priorities. 

Speaker 1
Cool. Awesome. Okay, Henry, you're working on that course. Bartek, you're going to look at the GitHub and at the knowledge base map and start making sense of it. I'm going to also go to the knowledge base code. 

Speaker 2
Yeah, I'm looking at the transcribe to knowledge base. Are we using agents and what are we using agents for? 

Speaker 1
Inside of it prompts. 

Speaker 2
So transcribe to knowledge base and. Oh, so it's transcribing. Right. And it's doing the knowledge base. 

Speaker 1
Yes. Different steps, because I just whisper for description, which we don't call really an agent. Right. Not an agent with tools, but yes, in that case it's just LLMs in general. 

Speaker 2
So it takes it and audio transcription, but it takes it and then it goes here. 

Speaker 1
Yes, it cleans up everything that doesn't need to be there. And then it finds the critical portions of the conversations. 

Speaker 2
Okay, and what does it do with the text file? 

Speaker 1
Right, that's a good question. So I should clarify that it does the exact same thing, but with a text file you don't need a transcription with timestamps because it's just already in text. You usually won't need a semantic cleaner for a text file. And then critical conversation analysis, we could have a step that identifies, hey, these are the important parts of this document or this is the important paragraphs or topics. Or we can go straight into the contextual executive summary. 

Speaker 2
Yeah, and then it upsets that to the DB. 

Speaker 1
Right, exactly. 

Speaker 2
Okay, what I think I could do, I want to test pulling from getting the data from the database when it's already in there. 

Speaker 1
Yeah. If you put the project into chat GBT and you ask that exact question, I'm sure that you'll be able to figure it out. 

Speaker 2
Yeah, I mean, that's what I'll do. Anyway, when I'm going through this course the second time, I'll use our own stuff. So if you got examples of contextual executive summaries, then I can just throw them into an index and test that out. 

Speaker 1
Yes, you got it. 

Speaker 2
Yeah, no, I understand it now. I thought were just uploading straight up text files, but that makes more sense. Yeah. 

Speaker 1
So technically we will be uploading straight up text files. 

Speaker 2
I know, but I thought with timestamps and like. 

Speaker 1
Yeah, cool. And we can debate whether the full transcript deserves to be in the knowledge base or just the executive summary. The executive summary would have to be thorough enough to not have to have the full transcript in there. 

Speaker 5
Yeah. 

Speaker 2
And Nan hasn't worked on this in like a month. What's with Nan and his relation to this project? Is he. 

Speaker 1
Yeah, he's been busy. He has a job. He's working on a manual job. So he's going to be busy this weekend next. And we want to continue this. Obviously he wants to see this through too because he sees the potential of this project. Right. So for now we assume that none doesn't exist and we continue it by ourselves. We come up with ideas by ourselves. We understand the project just like we would understand any other project by reading the code and running it. So I'm going to work on some kinks that we can figure out for a manual upload. Do either of you have Ubuntu or Linux? 

Speaker 2
No, but I could get a VM. I could virtual machine it. 

Speaker 1
I guess that would be useful. If you can send me what you find on that, on what VM to use for Linux, that'd be useful. 

Speaker 2
I wish I paid more attention now three years ago when they were showing me how to set up a VM in fucking Linux. 

Speaker 1
Remember when were talking about the three channels that we absorb information through? There's much of looking and hearing the professor speak and watching them do things, but there's so little of the put in practice, little of like, hey, why is it this even useful? Otherwise your brain can't make associations. It won't be able to remember three years from now. Oh yeah, ubuntu, VM easy. Because you never created the proper associations. That's what with the YouTube videos, that's it. 

Speaker 2
They're just buzwords to me now. I'll look into it. 

Speaker 1
So that's why I'm insistent on you teaching us the rag module. Even if just the rag module, that'd be awesome. 

Speaker 2
Yeah, I think that's what I'll do. I'll do semantic search, rag and maybe one other. But I'm going to do the whole course and then go back on rag and semantic search a bit more cool. 

Speaker 1
Don't push yourself too hard if you lose interest in the other modules. 

Speaker 2
Yeah, but. 

Speaker 1
Yeah, I know you got this. What's up, Bartek? 

Speaker 5
I'm asking if you try to put the prompts from the PFA, the one who just discussed the situation from the transcript knowledge base. If you try to put that in this code, because I see this is the V one of this prompt in here. In the code. 

Speaker 1
We have not, there's one prompt that I think was passed through PFA, but assume that none of them did, which is on purpose. What happens, how well or how badly does this system work when we don't fine tune any of it? It's something that we need to have awareness of, otherwise when we sell it, we can't have a scale of how good it is. So let's make it as bad as it can be, but functional, which is what it is. You can look at the transcript it created. I'll tag you on the transcript it created with just these prompts. It's fine, and it can be ten times better. That's when we put it into PFA, so we can start that now we have tests of how good and how bad it is, so we can put those into PFA. 

Speaker 5
Yeah, and that also would be a great way to show why PFA is important and why. 

Speaker 1
Damn. There you go. 

Speaker 5
Yes, there you go. 

Speaker 2
So to run it, we need to run it on Ubuntu or Linux, right? 

Speaker 1
Nan is able to run it on his end, no problem. And I have a Mac and I'm just not able to upload files for some reason. 

Speaker 2
Let me take a look. 

Speaker 1
So very strange, and there might be some confusion going on there. So that's why we need to have continuity on project. But that's a different thing using. 

Speaker 2
The file app. Path to your speech. MP3. 

Speaker 1
Exactly. 

Speaker 2
I've had problems with Mpegs before on Mac. Okay, so might be file type, I don't know. 

Speaker 1
Yes, that's one of the fixes that keep reposed. I'll try to figure out on my end and we'll reconnect tomorrow around this. Just give it a read and definitely take down some notes of what calls to you, what is confusing. That might be start. 

Speaker 2
I think my first commit will be to the readme and I'll add a diagram of maybe a bit more of the flow. 

Speaker 1
That's a fantastic idea, dude. Yes, that's a great idea. Hey Kuba, how's it going, brother? 

Speaker 2
Yeah, we already have a diagram of the flow once. Copy that in there. 

Speaker 1
Great. Idea. 

Speaker 4
Hi, guys. 

Speaker 1
Hey, man. Doing great. Doing really good. 

Speaker 4
Yeah, I shared the link to the charts. 

Speaker 1
Oh, nice. Thank you, man. 

Speaker 5
There we go. 

Speaker 1
So you should now have access. Check the development channel, Bartek, and you can check out the code for the outreach system. And Kuba, if you can maybe share a screen and share with Bartek, walk him through the code for the outreach system. That will be awesome. In Bartech. I hope that it will become evident how, number one, PFA will be able to help. And number two, how the knowledge base feeds into creating an optimal system, an optimal email outreach. 

Speaker 5
So, yeah, that would be very good. I assume we're all assuming I need to read it later. Slowly. 

Speaker 1
There you go. Kuba sharing so you can check it out with him. 

Speaker 5
All right. 

Speaker 2
How would I add an image to a readMe? 

Speaker 1
You might want to google that, but it's not. 

Speaker 5
I would ask GPT and just pass the URL and it will just do it all for you. 

Speaker 1
Yes, do that. 

Speaker 5
Some kind of bracket, kind of magic. 

Speaker 1
The bracket and then exclamation sign, something like that. 

Speaker 4
These are the libraries, but. 

Speaker 5
Again, can. 

Speaker 4
You guys hear me? 

Speaker 1
Yeah, it's a little rough, but we can hear you. 

Speaker 4
Okay, so these are the libraries I installed because I built it with Langchain. So I need to install all these libraries. 

Speaker 5
All right. 

Speaker 4
So this is API for Langsmith, which is like, to track my logs. Let's go to the code. 

Speaker 5
Is the line chain available now to everybody or you need to have the whitelist still. I had that on my task list to check this out. It was wide listed, as I remember, in the. 

Speaker 2
Graph, is also widely available. 

Speaker 5
Now I would finally have motivation to do it, to get into this. 

Speaker 1
That's what I'm talking about. That's how it works. Finally you get a reason to learn this new tool. 

Speaker 5
Yeah. 

Speaker 4
Awesome. This is a class for the top three searches on Google. That is what we're using to search for the name of the person. So let me just go. Let me just start from the prompt so you understand. So this is the prompt. So I'm giving it a google search tool. I'm giving the agent a google search tool. I'm telling the agent that given the full name of a person, I want you to get the URL link to the person's LinkedIn profile page, given the name I'm going to impute. So I said, your answer should only contain a LinkedIn profile URL. Then I gave you the two. And this is just a chain of thought prompt for it to reason. So this is just the input I need to capture. So this is the prompt template here. 

Speaker 4
Then I initialized the agent, then I executed the agents, then I just imputed them. Google DeepMind so this was the result. I should use the get LinkedIn. That's the tool that I created. Search for them in Asabi on LinkedIn. Then it gave me this result back, this URL. So I use proxy call. I use proxy call using this URL. I use proxy call to extract data about the person, about demiyasabi. So this was the result. I go back after extracting details about demiyasabi. 

Speaker 5
Is the extraction happening through some external API? 

Speaker 4
Yeah, proxy call is like an external API just to extract particular details about. 

Speaker 1
All right. 

Speaker 4
So I created another prompt for the LLM to format the data in a certain way. So I said, given the LinkedIn information about the person, that is like the information I got from proxy core. To extract the following detail, make sure the final output has to be just one single value JSON dictionary without any notes and explanation. Each key map to be a value which is a nested value JSON dictionary with the following requirements. So I kept the phone name, the full name of the person, the introduction, a short introduction about the person, the project that the person has done, the experiences, topic of interest, a list of created icebreaker. So this is just the chain. I do not use an agent for that. I just use the chain, an LLM chain for it. So I'm analyzing the chain here around the data. 

Speaker 4
So it gave me the output, the full name demon Sabi, the introduction, then the experience topic of interest. So now I created another agent for qualifying this lead. Like the information it got, if it's the perfect match to fast, right? So I got faster knowledge base, which is the txe file. This is like uploading it into launching. Then I split it into chunk because I want to retrieve just the very word documents. So I created another tool, which is this for qualifying the lead. If it's like, if it's related to password, if the lead is related to fast price. So I'm thinking if we want to be creative, create a very comprehensive knowledge base because it needs to be very accurate when it's comparing the client and our knowledge base. So this is just like the prompt template for it. 

Speaker 4
So after I qualified deliver, this is the result. Then we establish the perfect smart for our company based on its profile information and align with our strategic goals in artificial intelligence. So that is the second agent. I created another agent for creating a personalized image based on the information I've gotten about the client. So this is the tool for creating the image template. So this is the prompt for it. So this is like initializing. This is the results. So this is the agent results. I know this message finds you. I'm reaching out to introducing you to our company, Fastride, which is at the front of innovation in artificial intelligence, giving you an impressive background in artificial intelligence, neuroscience and machine. So this is just like the output of the email. 

Speaker 4
This is the last agent I created another tool based on the email that it's created. If you evaluate it, if it is like, how can I put it? If it is personalized and it is like the person's profile, the person's data. So that's what this agent is just about. After I initialized it, I created my prompt. This is the result. The email is well written, personalized, addressing the recipient background and expertise in a toastful manner. However, there areas that can be improved to ask. Clarity, engagement and relatability identified areas for improvement. The introduction could be more concise and impactful to immediately capture the recipient's attention. The call to action could more specific and component to encourage your response for the recipient. Email could benefit your case. In our fast resolution aligns with the recipient's interest and expertise. 

Speaker 4
So you suggested how we can make the email better. This is the final. 

Speaker 5
That's pretty cool. What? I think for this particular stage, we should have also the agent to make a review. 

Speaker 1
I'm not. 

Speaker 5
Not review, but redraft or rewrite like that. 

Speaker 1
Right. The next step is that. Yes. A second draft. 

Speaker 5
Yeah. And also I'm thinking maybe that just will be inside a writer prompt or maybe we can have separate agent for that to kind of make the email more human like human writing. Because while the system is looking very good, if you could, I could scroll up to the initial email output. Little up. Yeah. So for me personally, the first almost two sentences, I hope this message finds you well. I'm reaching out to introduce you to company that's already like, probably red flag for some CEOs that seen a lot of these messages. So we would have to introduce some kind of either, maybe even not a human writing level, but some unique writing level, like have some unique starter, because I hope this message finds you well. It's like very standard. Yeah. I mean, I'm not here to criticize. 

Speaker 5
I just want to add some ideas on top of, because it's still good work. And I see it's very prompt to be perfect in some, how to say, polishment. 

Speaker 1
Right. And that's part of the prompt tuning. Right. That's obviously like one of the next steps that we're doing. So that's a good observation regarding the structure of the agents talking to each other. Do you think something else could be improved beyond just a couple redrafts for this version? 

Speaker 5
I would have supported agent for drafting the icebreakers as this is currently one agent extract the information at the same time, in the same step it goes, and draft the icebreaker. I think we should have specific agent for the icebreakers. And the icebreaker should be where the message begin. 

Speaker 1
Yes, I see. So then, hey, here's the icebreaker. Here's the information about this person, their experience, their posts. Continue, this email. 

Speaker 5
Yeah, something like that. And I had something for PFA recently that I call Persona matrix or matrix. It should be pronounced matrix, I think. Persona matrix. So I'm really excited to put this to test with those prompts. Yeah, I think we could make some more detailed Personas in here and separate agent for the icebreakers. I think that's going to be golden. 

Speaker 1
Okay. 

Speaker 5
Because we're going to just specify one prompt to just do icebreakers. Yeah. And let's have some frameworks in it. Let's have some methodologies how to do icebreakers. Dig into that. Yeah, I think it might require some research on how to do that from how humans do that. 

Speaker 1
Right. 

Speaker 5
To make it as perfect. But I think definitely PFA can get us at least the 80% in or even 90% in. And later if we need that few little more, then we can just make some research. We'll see how that goes fit. Like how much really will the separate icebreaker agents improve halting and then we'll iterate from that. I think that's the initial idea. 

Speaker 1
I love that we're thinking through it. Okay. 

Speaker 5
I'll definitely read this all at my own pace and have some notes and bring that to you tomorrow with some more thought of ideas rather than just from the top of my head. 

Speaker 1
I would not like it any other way. Man, that sounds awesome. 

Speaker 4
Yeah. Just to add in the system is just like a sketch. It's not like the main version though. That's what I'm just saying. Do you understand? 

Speaker 1
Do it. Are you asking me or are you telling us? 

Speaker 4
No, I'm telling you. The system is just like I said, v one is not like there are still a lot of things that we still need to make it perfect. That's what I'm just saying. 

Speaker 1
Right. 

Speaker 4
I see a lot of fine things to the prompts and make it better so I can get more accurate outputs. That's what I'm saying. 

Speaker 1
Cool. 

Speaker 5
That's actually better approach that I'm visualizing things because I'm trying to be perfect from the start. Yeah, that's a good approach. You guys doing over there? 

Speaker 1
Yeah. And we appreciate your perfectionism because it'll help us get that extra 20, that final 20%. We also want to help you with keeping as effective as we know you can be. And this goes for each of us. Right? What are we spending our time on and how effective is it versus how effective that time was yesterday working on this thing? What we know for sure is that for these projects, any time we spend on them is going to be effective because there's work to do, there's things to improve. And also it's directly related to faster being able to make money in the near future. 

Speaker 5
Yes. That's great. 

Speaker 1
Awesome. I got to go, you guys. Thank you for the awesome work session. Let's reconnect tomorrow at the same time and. 

Speaker 2
No, do we have another meeting later? 

Speaker 1
Not today. Yes, not today. Okay, let's do this, you guys. Such a pleasure. 

Speaker 2
I'll see you soon. Thank you, guys. 

Speaker 5
See ya. Bye. 