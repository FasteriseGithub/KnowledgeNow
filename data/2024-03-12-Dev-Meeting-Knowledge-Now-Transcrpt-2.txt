
01:09
Alejo
Okay. Hi, see you all again. 

01:17
Bartek
Waiting for us or it's only three of us here? Hi guys, I'm hearing you right now. I just had a dinner, so excuse me, eating. Aleo, I think you have something with your audio. I can't hear you. Aleo, you're not here. 

02:49
Alejo
Okay, I guess no headphones it is. Hey you guys. 

02:53
Bartek
Yeah, sounds good. 

02:54
Alejo
Cool. 

02:55
Bartek
Hi again. 

02:57
Alejo
Hey, did you say something? Is there something you wanted to share? 

03:05
Bartek
I just wanted to share that I have great. Dinner or lunch? Lunch. I messed that up every time. Lunch. 

03:13
Kuba
Hi guys. 

03:15
Alejo
Hey Kuba. 

03:23
Kuba
Let'S see how you doing, bro? 

03:35
Alejo
1 second, you guys, thank you guys for sharing your update on Friday. It makes me very happy to see progress on what you get to work on or what you want to work on. I hear a lot of rag, I hear a lot of lang chain. As you said, kuwa, rag is the future. And it's been very exciting to talk to developers this last week. A variety of experiences and expertise and they all say the same thing. It's like Rag is where it's at. Rag is the future, Rag is what I want to learn. So we're taking that strong indication and running with it. We're building knowledge now. Okay, first of all, before we step into that, because start rattling on, wanted to share an update. I'm working on the real estate automations. 

04:57
Alejo
I'm working on the free side on the two free real estate automations. When those are ready, I'll share the demo. In the next few days. They'll be ready. In the next few days. I'll share the demo. We can make sure we get some testing in together and I will make sure that each of us can follow the exact same process for when we actually have the paid clients that will come through referrals that we can emulate this system for their side. For some of those that might include importing contacts to the follow up boss CRM and just setting them up from scratch. For some of them that might be like, hey, I would like these automations and each of us needs to already know the API and how does the CRM actually look and feel? 

06:09
Alejo
So I kind of tried to do that last week, but I realized I don't understand it well enough to guide others. So I took a step back. It's like, let me work on these automations, finish them, let me fall into the pits of working with any new API and make sure that I set up you guys for success once the money actually comes in. So that's the update on that. On real estate automations, client is still very excited. We got introduced to two people that she's working with, the manual follow up boss guy that's kind of importing her contacts manually and her social media person. And we're going to be able to find ways to help in both of those areas. 

07:09
Alejo
We got some questions around profit sharing and we will make sure that we have a genexac to clarify, to share, to have questions, and to make sure that everything is clear. It's very important to us, to all of us, to each of us, that we know what's going to happen with the money once the money hits the account. Right. So we'll make sure that everybody has clarity on that and that everybody agrees. Yes, this is fair. Okay, so that's on the real estate side and that's the short term. Yeah, barta, go ahead. 

07:58
Bartek
Because we are kind of starting to work this week, probably internally on some content automation. So I think we can actually work simultaneously on the automation for the real estate. We have this idea to make notion integrated with relevance AI. Like make some agents, and for example you have idea for your content, you write it in the notion, you have this kanban in notion. And then for example, you have this raw idea and then some ideas you want to put to AI to draft. And then that will trigger the relevance AI agent, for example, first kind of EDH version of it. And then basically it would draft a post or whatever and then send it back to notion. So that's where I'm thinking, and we're probably going to start working on it this week if there is a time, if the winds are correct. 

09:04
Alejo
Yeah, cool, that's good to know. 

09:11
Bartek
And I also have updates now from the call just a second ago. 

09:17
Alejo
Go in a circle and do updates. 

09:18
Bartek
So go crazy. Yeah, so I was talking to this guy from the prompt hub, and we can have collaboration there, like constant collaboration or whatever. I was talking to him on this kind of note, but the thing that really clicked after this call, because I was showing him PFA and the output was kind of short. I mean the use case was for a recipe and for a cuisine, sending and generating receipts. So I see that the details couldn't be there more. But I got thinking like PFA sometimes does that PFA sometimes give a short prompt and you need to regenerate. And I was thinking like, we need the swarm, we fucking need the swarm. It's not a product until we have the swarm. This is just a proof of content. And if user have to know that the prompt. 

10:10
Bartek
I know from my eyes that the prompt is not good, but users want. So we need to have this. The thing that I'm doing manually, like regenerating, like looking the prompt is not good. Or regenerating, or saying, like, use more markdown or make this prompt more detailed. We need a feedback loop for that in the PFS form, like some agents doing basically what I'm doing now. So the prompt is too short, the prompt lacks markdown, lack structure. We should really go there. 

10:42
Alejo
Okay, perfect. 

10:42
Bartek
And I'm thinking about maybe we could repurpose some of our agent systems. Like, I'm not sure how we can. Maybe we can use the outage system a little bit to change it in a way that we could have those. Or maybe it's better to make it from scratch. I'm still not sure, but we kind of have this structure already where we have those agents talking to each other. I mean, they are not really talking. That are in a chain, right? Yeah, it's kind of chain of action rather than conversation. I think we need to step into the conversation part where we have some kind of hierarchies. Like this is agent one that making the context enrichment. And then there is another one, let's say in a simplest form, generating. And then we would have some agents that above them and check their work. 

11:44
Bartek
And they need to talk, basically, yeah. I think we need to make it from scratch. 

11:50
Alejo
Okay. Make what from scratch? 

11:55
Bartek
The communication PFA is warm, like the lang chain framework for PFA, basically. 

12:02
Alejo
Okay. 

12:03
Bartek
Maybe we can step into some kind of crew AI thing. It's popping recently. Crew AI on my. 

12:11
Alejo
So let's. Let's get there. I want to make sure that Kuba and Hubi are with us on this dive into the possibilities I'm following. So let's get to the point where everybody's on the same page and we can actually make some decisions because there's a lot of things that we don't need to do from scratch. Right. There's a lot of research on communication frameworks that we can probably just grab from an open source and then just tune for the use case of prompt regeneration of PFA. So that's what we will step into. Since we're there. 

13:05
Bartek
Let's just go there, Kuba, we'll get. 

13:07
Alejo
Around to personalized our system, and I'll give you an update on that. I would like to ask you, Kuba, were you able to start with this rack system from the single document transcript? 

13:24
Kuba
Yeah, I created it with pine cone. I tested pine cone and abute system. One with pine cone and one with. 

13:41
Alejo
Pine cone and the other one with. 

13:48
Kuba
Open source vector database. 

13:50
Alejo
Okay. 

13:51
Kuba
Yeah, I'm just testing, like cosine similarities between the vectors. 

14:01
Alejo
I'm just testing, yeah. 

14:07
Kuba
Updates the two system. I will show you demo like that. 

14:13
Bartek
Cool. 

14:14
Alejo
Yeah, you have it now. You said you have it now. 

14:17
Kuba
Yeah, I do. 

14:19
Alejo
Awesome. Let's do it. Let me allow sharing. It's great. Yeah. 

14:27
Bartek
Also, on the note of databases, I wanted to ask if, yeah, go ahead. In the meantime, I wanted to ask if we have capabilities on the AWS in our developer team or generally, because there is those two things. Like there is the vector databases and the new stuff, and there is the old stuff, the relational databases, non relational databases. And actually right now we are facing the problem, the challenge, more of them, the problem. Let's see. Challenges, not problems. So we're facing challenge to actually offering the chatbot that will kind of pick four different data inputs into a chatbot interface so the client can basically talk with it. Yeah, I refer to that Us client. And we're thinking if there should be one database out of those four, so we're going to have some data migration and stuff. 

15:36
Bartek
So I'm just thinking if there may be somebody who already been doing some of those stuff. I saw Kuba actually posting something on the discord about AWS, so maybe I can ask you if you've been doing some stuff with. 

15:50
Kuba
Yeah, yeah. During the weekend, I played around using streamlit. I created a little QC generator. So I created the front end with extremely, and I hosted it on AWS server. So it was like playing around it. 

16:09
Bartek
Have you been doing some with daca migration? 

16:12
Kuba
No, not yet. 

16:15
Bartek
All right, so maybe we connect later after this call and maybe talk about this more, or are you aware of somebody else having AWS experience? 

16:25
Alejo
Yes, because at another company we worked with AWS. So I have experience with AWS storage. I have experience with limited experience with AWS systems, but they don't feel strange to know. I will ask around. And you're essentially looking for a systems engineer, like somebody that could do potentially a migration. 

16:55
Bartek
Yeah. 

16:56
Alejo
Okay, I'll ask around. Knowledge. Now remind me to ask for a systems engineer. Already getting used to it. 

17:09
Bartek
Basically we need to do like centralized database for the chatbot interface. Like initial. 

17:15
Alejo
Okay, cool. 

17:16
Bartek
That's probably going to be migration of. 

17:17
Alejo
The data migration into a data migration Aws into a central database. Okay, let's pause on that and we can talk more about it later. Kuba, the stage is all yours. Yeah. 

17:36
Kuba
So this is like the chart now. So first of all I put in my pocket, let me just keep this. So yeah, remember I told you earlier I'm not going to use Google Collab I have because number one, it's crashing my system for now because I'm testing, I found a way to build visual code. So this is like the other one I'm building like debugging. 

18:09
Alejo
Colab is great. Colab is fantastic. Prototyping on Colab is a great idea. As we look at versioning and actually making it more usable, that's when we'll transition out. Colab works great for now, but thank you for clarifying. 

18:30
Kuba
Let me remove, so let me walk you through the code. First of all I imported the meetings transcript using planchain. So this is like the transcript. So I splitted it into chunks. So this is a chunk of it. 

19:02
Alejo
Wow. What are those? 

19:06
Kuba
Just the chunk of the data. So this is the total length after the trunk of the data. So I embedded it using open AI embedding. 

19:17
Alejo
Cool. 

19:18
Kuba
So I imported into the panic on vector database. So this is the name of the index here. So I just queried it. This is just a normal query like to just get the similarity search. So you just return the most very bad document. So this is it here. When I ask what type of agents can we create? So this is like the documents. So in this document I can indicate how many I want it, but I just listen to just. So now I want to pass the document into an LLM. Once you get the document you can answer my query better knowing the context. So I asked the question again, what type of agents can we create? It seems like the conversation is discussing creating agent for real estate or mortgage learning purposes. 

20:18
Kuba
This is not clear specifically what type of agents they are referring to, but it can potentially be an automated agent. Sorry, an automated agent or a human agent. It is also mentioned that they are trying to reduce the amount of agents. Keep the process simple and programmatic. So this is just like for querying it continuously, like putting it in a. 

20:46
Alejo
Loop at the very bottom. What's that output? 

20:53
Kuba
Yeah, it's just like keeping it in a loop that I can keep on asking. Like chatting with it conversational. 

21:07
Alejo
Yes, but what is that result from? The meeting was about implementing automation services. 

21:17
Kuba
Okay, this is like from another question I asked actually. Okay, I'm going to show you. Let me run. 

21:25
Alejo
So you have great start, man. This is a great start. That's the one thing that's really annoying about Colab that you have to import upload the documents every single time. 

21:54
Kuba
Yeah. 

21:59
Bartek
Guys, I thinking for the first version, for the MVP or proof of concept, I think we should list the most required functionalities we need. So I'm thinking definitely who is saying the stuff like participants. 

22:18
Alejo
We're doing that with fireflies. So we are going to have that. Yeah. And if we can do it through zoom cloud, then it'll be even easier. So hold that thought and we will get to that point. We'll talk about that too. 

22:48
Bartek
And one thing on the processing side, I'm thinking maybe we should use, I mean, it looks quite good over here, but the beginning of the transcript, weird. 

23:00
Alejo
Words. 

23:04
Bartek
We should have. Maybe. 

23:09
Kuba
There are a lot of weird words in the document. 

23:13
Bartek
Yeah, I'm thinking maybe we should have agent that corrects the words like extract the meaning. 

23:25
Alejo
So that is already built. I can show you. I want to go from big picture to small picture. And we can talk about the components and the subcomponents. And fixing the transcript is one of those subcomponents. All right, call out. Cool. Let's see what it comes up with. I wonder how stochastic it is. Yeah, that's unfortunate. What if you try it again? 

24:04
Bartek
What if you instead of agents say product? Because I think this was about the real estate how to say listing description generator. 

24:19
Alejo
Right? 

24:19
Bartek
I saw it in the transcript. It was actually me talking about the first project of celebrities. So I think it's more of a product. Oh yeah. 

24:37
Alejo
Go. There we go. 

24:40
Bartek
You see, you need a prompt engineer. 

24:44
Alejo
That's where that comes in. 

24:45
Bartek
The prompt registration. 

24:51
Alejo
Should we. Wow, this is just. 

24:59
Kuba
Like imputing, like incrementing continuously. 

25:05
Alejo
Okay, got you. Let's try. This call was about knowledge. Now could you ask what is the product called, how is it used about. 

25:44
Bartek
Extract and either eight project documentation. 

25:49
Kuba
Extract. Sorry, I didn't get that. 

25:54
Alejo
Extract and ideate product documentation. 

26:00
Bartek
Project. 

26:14
Alejo
I wonder how well it does with typos. Summary. So this is just extracting and interpreting the chunks from. 

26:28
Kuba
The vector store and the vector database. 

26:31
Alejo
Yeah. 

26:34
Kuba
What I need now is like using a prompt to guide its output. Instead I was just like typing just requesting. 

26:51
Bartek
When need sort of extractor agent, like extract first and then ask later for something. In this situation we'll have two agents. One is extracting the information required, or even better, we start from what's required for the documentation for this project, from this little extraction, and then another extraction agent knows basically more where we're going with it. So say extracting. Then the documentation agent tries to make the documentation but lacks context. So it goes back to the first agent, to the extractor, and give me more context on this and this. And then it's kind of a feedback loop in here. 

27:35
Alejo
Okay. Yeah, totally. So we're noticing a few things. We're noticing the quality of the extracted documents from pine cone varies in quality, which is normal. It's only one transcript and the transcript is not even clean, so that's normal. Number two, we're noticing that the output of the queries is limited to only the context that it is given from the low quality extraction of the chunks. So it doesn't have much to work with. What if the next step was giving it more context and using that context to actually create a proper answer? Yes. And then number three or number four is the prompt regeneration so that the query being asked can be regenerated, say, by PFA, based on the context of essentially who's asking. In this case, let's just say it's the normal quote unquote faster ICE is asking. So just answer, faster ICE. 

28:58
Alejo
Who is faster ICE. Here's who faster ICE is. And we just feed the knowledge base of faster ICE. So there are some components there. Thank you, Kuba. This is a great start, man. This is wonderful. I wanted to be able to visualize these components, so let's pause so we can keep going forward. So we talked about a lot of things last meeting, it was brainstorming session, and we're taking all these ideas and all these use cases and we're running with it. So let's make it a little more visual. Number one, the thing that we know for sure, which is at the end of a. Sorry, I'm trying to remove the captions. They're in the way. Okay, well, it is what it is. At the end of. 

30:11
Bartek
The end of. 

30:12
Alejo
The day, what we need is answer. Sounds obvious, but how do we get. So let's see. 

30:30
Bartek
I think we definitely need to let PFA into the wild. I'm actually tired of the GPT version now today. It's really. I agree. Making me angry about this. 

30:45
Alejo
Good, get angry. Create new from that anger. 

30:50
Bartek
Let's make it into the wild. Yeah, I'm thinking it will best if, for example, in this collab we would have PFA as a hint text. Can you imagine writing prompt and in real time it gets like autocompletion hint text kind of thing. How do we do that? 

31:14
Alejo
I like that. Okay, that's a whole different component. Let's figure out where that fits, because that probably fits here somewhere. 

31:24
Bartek
Yeah, knowledge. 

31:25
Alejo
Now let's start from the end of it, which is the answer. And I want to dig into this a little bit because, Bartek, you and I connected earlier today and we threw out some great brainstorming. I want to make sure that everybody's with us because we said some really interesting things that we could do with knowledge. Now we talked about a little more space. We talked about a bot that measures messages. You with your to dos say the call ends. We're in a dev meeting. At the end of this dev meeting, the objective for each of us is to have clarity on which of these tasks of this whole system that we're going to look at. We are tackling, it's a subcomponent of a component and we're going to make sure that we are each set up for success. 

32:31
Alejo
What that looks like with knowledgenow in the future, with knowledgenow, is that right after the meeting we can get a list of to do's. It's like, hey, this is what you're working on and these are the subtasks that you have to. Oh, right, okay. Yeah, thank you, Hubi. We'll get you the recording and we'll make sure that you have a clear task to work on. So at the end of the meeting, Hubi that now has to leave will get a list of tasks that he has to get done and maybe he's not super clear on what those tasks really mean. So you can message the bot to catch up on the meeting, get clarity on the meeting. That's kind of one use case in itself. So number one, great. Another use case is at a deaf meeting. We have a new project. 

33:34
Alejo
We're talking about knowledge. Now we figure out the objectives of knowledge. Now we figure out the use case, right? So let's say it's this first use case. We figure out the success criteria, that it actually messages each person after the meeting. That it's clear on the tasks, that the tasks are actually what we talked about, that they're assigned to the right person. So we set up the success criteria and we figure out the step by step. This whole thing that we're doing now is going to be that step by step. So all that knowledge exists in the meeting. After the meeting, there's already a prototype being built. So that might look like a documentation writer. A documentation writer. It might look like a project manager, multi agent, anybody. It might look like actual programmers. 

34:39
Bartek
Let's make digital twins. Of all the dev team partners of. 

34:45
Alejo
All the dev team. Hey, I am good at this, but I want to learn rag. 

34:52
Kuba
Great. 

34:52
Alejo
Now you have a Bartech digital partner that is an expert at Rag and can help you build those projects while guiding you through it. Because code, in the very near future we won't even need to write. But systems design is something that we need to keep honing in on Cuba. The fact with a personalized outreach system, the fact that were able to throw you a picture of the system that we wanted, and you were able to write the code to put each agent and how it would work together, what tools each agent would need. That is freaking awesome, man. I believe that in the future. 

35:41
Kuba
That'S. 

35:42
Alejo
Going to be a minor value added, which is huge value today, that the great value is going to be able to be in coming up with the system in the first place. So say we have a call and we come up with this system, and by the end of the meeting, there's already a prototype being built, there's already documentation written. The steps, the project manager figure out the steps because of the objective and the success criteria that we set up and the programmers are already working on it. Kuba, you wanted to add something? 

36:25
Kuba
No, what I'm thinking is we can actually build all this. All I was watching videos on cool AI, and it's very cool. It can enable us to do this. That was saying like the documentation writer, the projects manager, the programmer, then we have like a supervisor for all of them. Supervisor is the one that will be assigning the rules when a query comes in. So the supervisor understands that. Okay, this message belongs to the documentation writer. Okay, let's say agent. Then this rule belongs to the project manager. Agent. It's just like routing h query to the right. 

37:19
Alejo
Something like perfect. Okay. Yes. And that exactly fits in with what Bartek was mentioning of. Hey, we need somebody to kind of moderate and manage the conversation. Could you text what that service thing that you were looking at is called? 

37:43
Kuba
The service Aws. Is that what I mean? 

37:50
Alejo
I'm not familiar. Could you write it? You were watching something that does this? Did I capture that? 

37:59
Kuba
Yeah, yeah, I was watching like a video. That's what I was saying. Like a video on YouTube. You know this guy Matthew Berman now? 

38:08
Alejo
No. 

38:12
Kuba
He'S like an AI influencer. He did a video about it, about the framework. 

38:20
Alejo
Okay, cool. Could you post it in the chat and we'll definitely take a look? Yeah, thank you, man. Great. And having other frameworks that we can get inspired by is a great idea. It's not a great idea. It's necessary to figure out what others have worked on and how we can make it better for ourselves. Another one that we threw out there is a scrum master assistant, which you can kind of call a project manager. It's a type of project management, but earlier, and we mentioned it last week, at the beginning of faster eyes, we had this sort of scrum format, and then it was really hard to keep up with because there were a lot of people and there were very few people. It was mostly like Henry and I and most dev calls. So this kind of fell off. 

39:18
Alejo
But if we can have this, and I wonder if this scrum master assistant mixes in with messaging you with your to Dos, you can ask the scrum master assistant for clarity on what your tasks are and the programmers on how to, and creating a draft for that task that then you can go and make better. So this all comes together really beautifully to work together as different components, different use cases working in harmony. So we're coming up with these use cases. Okay, what are the steps to get there? We know a few things. We know that before the answer happens, we need a good evaluation of the answer. How close is this to a full, accurate, relevant answer? Is this an agent? Is this a second moderator that can then kick it back to supervisor? 

40:36
Alejo
We'll figure out how these components play together, but we definitely need an evaluation before we ever send any answer out. We're also talking about a supervisor agent. We can call it whatever we want. I'm going to put supervisor, moderator. Who is this supervisor moderating. What is that conversation that is being moderated and what information gets. We know the output, right? It's an evaluation. And the final answer, what is the input? Well, we have the knowledge base, and this knowledge base has information about all these things. We have real time Zoom call transcripts, close to real time. Every other transcript we have about who we are and what we do, knowing skills of each person and what each person wants to specialize in, like rag and knowledge of the project, et cetera. There's a bunch of things, clients, industry. 

41:43
Bartek
Focus. 

41:46
Alejo
That'S part of the input. We also have the initial prompt. Okay. And now that we know the prompt leads to the knowledge base in what exact capacity? When is the repropting? Let's figure that out together. So. 

42:11
Bartek
I think the PFA swarm framework is pretty reusable in here. We can have the input like you write a prompt, you make a type or whatever. Later. We have like a context enrichment. So basically, just like PFA enhances your input, this can also enrich your input, and then it's kind of trying to get maybe using the fasterized knowledge base. Like, okay, see we are in fasterized right now. This guy asking me for this and this. Now I enrich this to be more relevant to pastorize the query itself. 

42:57
Alejo
Yes, exactly. 

43:01
Bartek
And then next thing we have is innovative angles. We not use that in here. Next thing I need to come back to the diagram. I already don't have it on my whiteboard. So first time I'm going to look at the actual photos of the whiteboard. So let's get back there. 

43:24
Alejo
We are putting the output to be kind of enriched prompt. So I wonder if there's a knowledge base and then a base kind of system prompt about sort of very brief, like a paragraph about fasterize. Right. Because how do we make sure that if the prompt doesn't mention anything about AI, fasterize any projects, anything. This also has the context of what faster is. What is the global context? Maybe there's some component here of global context. 

44:12
Bartek
I think we need to have two separate knowledge base calls, let's say. So you would have first, before the transcript knowledge base comes in, need to be the fasterized knowledge base. And actually the knowledge base from transcript will be after enrichment. 

44:34
Alejo
I think that's exactly what I was thinking. Okay. I love how this is coming together. So we go from prompt to global context knowledge base. 

44:49
Bartek
Actually, enrichment. Enrichment first, before you get to the global context, you need to fix the typos and enrich the input. 

44:58
Alejo
Okay, got you. I wonder if it's because you're already. 

45:02
Bartek
Querying the global context with this prompt that comes. 

45:07
Alejo
Yeah. So. So we put vanilla PFA to fix the prompt without other context. Maybe like slight context in its system. Prompt, vanilla PFA. The whole point is enrich fix. 

45:28
Bartek
Actually the enrichment agent could be having the faster. 

45:33
Alejo
Right. 

45:33
Bartek
Knowledge base in the enrichment agent knowledge. 

45:41
Alejo
Okay, question. When we're talking this component from the initial prompt, are we already talking multi agent? 

45:51
Bartek
I guess. 

45:53
Alejo
Okay, we'll put a maybe in there. Maybe already multi agent wondering if we need to do the heavy lifting without even putting the global context in already. But that's minor. 

46:11
Bartek
Actually, it's even better when we have multi agent system from the start. And then this enrichment is an agent. An agent can have its own knowledge base and that could be the global context because actually I doubt thing now the enrichment without the context I don't think will be good enrichment. So the enrichment agent already needs to know the pasteurized thing. 

46:32
Alejo
Well, I mean, your fagpt without any context is pretty freaking good. Like excellent. Yeah. 

46:41
Bartek
But if it knows where we're going and from where we're coming from, actually the fasterized knowledge base. Okay. I think it will enrich even better. 

46:51
Alejo
Okay, so then would this step be redundant because we're going from prompt to add global context into PFA? It's not a rhetorical question. 

47:08
Bartek
I think the global context has to. 

47:10
Alejo
Be. 

47:13
Bartek
In the context of context enrichment. The context enrichment agent has to have the context to enrich from. It's kind of like meta enrichment. 

47:26
Alejo
Yeah, no, I'm with you. I'm with you on that one. Okay, so the PFA specifically, we're talking about the context enrichment agent with general knowledge of general context. General context. So that's my question here. And then we throw that into the global context knowledge base. 

47:52
Bartek
No, actually this global context gets merged into the first step as a knowledge base. So we don't have a separate call later in the air. We don't calling the knowledge base by itself. We're calling it through the context management agent. 

48:13
Alejo
Okay, something like this then. 

48:18
Bartek
Yeah, I guess we can have it like that. 

48:24
Alejo
And this is a draft. It has lots of room for improvement. But yeah, this makes sense. There's a simple not well written prompt. We have global context and PFA. The heavy lifting in this case is done by the context and reinstrument agent with the general context fixes and enriches the prompt. Maybe it's already multi agent, maybe it's one. Good. Well, it's PFA, so yes, multi agent. Great. Wonderful. 

48:57
Bartek
Next step will be extractor agent. 

49:03
Alejo
Is that within this component? Because this component. 

49:07
Bartek
No, it's next step. 

49:09
Alejo
Okay. 

49:17
Bartek
Actually I'm looking at the diagram for the PFA swarm, but we're going to. 

49:21
Alejo
Have diagram next time. 

49:27
Bartek
Yeah, I don't know if you will be able to see that. 

49:34
Alejo
Cool. I love learning. 

49:38
Bartek
I don't know if you can read that. 

49:40
Alejo
I cannot. It's the context. 

49:44
Bartek
And then maybe I'll just share with. 

49:46
Alejo
The image later if we can get something kind of in the figma board. Maybe just throwing the word. 

49:56
Bartek
Maybe I will draw this again because this is kind of mess in here. I had it on my whiteboard for a few days and I was just adding stuff on top. So I will redraw this from scratch. 

50:10
Alejo
Awesome. Yeah. Even just getting like a general idea of what the swarm is going to be like. Because we know what PFA is and we know what swarms are. 

50:20
Bartek
Right. 

50:21
Alejo
We get the general idea. Okay. So there is now an enriched prompt that comes from the initial prompt and the global context PFA creates that enriched prompt. What happens next? You mentioned a extractor agent. 

50:42
Bartek
An extractor agent has the transcript as a knowledge base. 

50:48
Alejo
Has transcript. So it has the full knowledge base. 

50:54
Bartek
Yeah. 

50:55
Alejo
Okay. 

50:57
Bartek
So we kind of shift the usual way of calling the knowledge base. We have like every agent has the knowledge base, right? I mean, maybe not every, but these two agents have a knowledge base and he would be extracting from his knowledge through the prompt that we enriched before. 

51:19
Alejo
So this prompt gets passed as a rag query into the knowledge base. Is that what you're saying? 

51:28
Bartek
It's passed to the extractor agent. Then extractor agent gets to the rival. 

51:40
Alejo
Okay, I think I'm following now. So the extractor agent will intake the enriched prompt and make it a query adapted for rag. Optimized for rag. Yeah. Okay, cool. So the output of this is query optimized for rag, which as we know is not actually. 

52:11
Bartek
Wait, we have that already. This is the output of the first agent. Well, the query optimized, I think that's. 

52:22
Alejo
Kind of a question because this prompt is going to be like, tell me about the real estate project. Then we add the global context into that. And then this enriched prompt, this outfocus, just on the output would have, tell me about the real estate project. This is kind of like what I'm interested about it. Be very explicit about the step by step, be clear about what the client wants. Takataka. Takataka. So the enriched prompt based on that global context, based on the initial prompt and the PFA extractor agent may or may not have to do multiple calls to get. 

53:30
Bartek
That's where we're going. 

53:32
Alejo
Multiple queries to the knowledge base in order to actually extract all the components that the enriched prompt is talking about. 

53:41
Bartek
So we're kind of going like, Gemini produces three outputs and lets you choose. 

53:47
Alejo
Yeah. 

53:52
Bartek
Next we have agent that chooses the best version of the output of those queries. 

54:01
Alejo
So then with all that. So the PFA extractor agent is going to come up with multiple queries. Multiple queries optimized for rag. We call the knowledge base with each of those queries and the output of that. Man, this is fun. 

54:33
Bartek
It goes to the supervisor now. And then we have a feedback loop. 

54:37
Alejo
You mentioned something different, which was, we need an evaluation of all that data, all the answers of the queries. And I just want to make sure that we're on the same page, that the supervisor will lead the free for all conversation where now agents are just talking with each other and the supervisor decides what is relevant for it. Yeah. Okay, cool. 

55:02
Bartek
All right. So now it's evaluator. 

55:04
Alejo
So it's the evaluator agent which will evaluate the quality, relevance, et cetera, of all the outputs of each kind of sub query to the vector database. And the output is going to be output. Let's keep it simple for now. These are the most relevant. 

55:52
Bartek
Can also add a scoring in there, like from one to ten. 

55:56
Alejo
Yes, score one to ten and we can start with top three. So let's say that ten chunks are extracted for each query out of the vector database and we do top five out of those. Top ten. Based on what? Well, the input is going to be. Input is going to be the. 

56:29
Bartek
Enriched prompt. 

56:31
Alejo
Yeah. The global context. It's going to be all the queries each query. Let's call it sub query or rag query. Yeah, let's do that. Rag query. Each rag query and the global context. Maybe there's some other stuff in there, but that's good for now. 

56:58
Bartek
I'm thinking if we should add transcript in this one or there should be like separate agent that is focusing on rereading the transcript to kind of check the evaluator or if the evaluator should also do that. But I think that will be too much job for evaluator. We also pass the transcript. We need to think about the context window here. 

57:22
Alejo
Yeah, that's where it starts getting interesting and let's experiment. That's where I say, let's see how many tokens we can spend. And then when we get the best output, we can, we reduce, we simplify. Yeah. So, yes, to all your ideas, let's have a kind of, I'm not going to get too meta, but kind of an evaluator to the evaluator. So let's let the supervisor in now to say what is needed from here. 

58:04
Bartek
Maybe we can also add like transcript. I'm thinking like kind of code review to the evaluator, but it's a transcript review. So transcript review agent. 

58:22
Alejo
So this is kind of a tester. 

58:26
Bartek
Yeah, it brings back the whole transcript and slashes that with the evaluator output. 

58:36
Alejo
Yeah. 

58:37
Bartek
And kind of make a semantic check on the evaluator. 

58:46
Alejo
Kind of semantic quality check on the evaluator. Cool. So as we are testing the system, this will definitely be necessary because what if the evaluator is the one that's wrong? 

59:01
Bartek
Right? 

59:02
Alejo
What if the evaluator is the one that. So part of the input that this transcript reviewer is going to need is kind of its own examples. Here's the whole transcript, here's the query, here are the relevant chunks and we can kind of give its own few shot prompting. I'm not going to call it knowledge base right now because we have way too many knowledge bases to keep track. 

59:35
Bartek
Of, but few shot prompt. Yeah, but that's good. I mean like every agent should have a knowledge base and every knowledge base should be different. 

59:43
Alejo
Yes, I agree with you. Let's keep Fusot prompt for now and. 

59:49
Bartek
We can go from there. 

59:50
Alejo
Fusion prompt of query plus transcript plus relevant chunks plus score from one to ten. So tester of QA agent transcript. There you go, QA agent, which we'll do like a check on the evaluator agent. Okay, I'm going to pause now because I want to be considerate to all the other human being in this conversation because I feel like we're robots right now. Kuba, what clarity, what questions. Maybe everything's clear, but I know sometimes. 

01:01:04
Kuba
I go often, to be honest, I enjoyed the conversation. I like the way you guys think. This is like a new picture to the entire system. So I understand. I just need to go over the stigma body again to understand it. 

01:01:24
Alejo
Well, cool. Awesome. Well, if you have any questions, there's the chat, whatever comes to mind, ideas, feel free to pitch in. Okay. 

01:01:39
Bartek
Refinement loops, definitely in the evaluator to. 

01:01:43
Alejo
The extractor, my mind. So before you go into that, Kuba, you asked me the other day, what's the thought process for these icebreakers for the personalized outreach system? And I mentioned this reinforcement learning with human feedback, or at least trying to emulate that self refinement getting better over time. And this very much we want to go in that direction with this. So that's where the QA agents might come in too, right? How do we make sure that this system gets refined over time, that it doesn't hit a ceiling. 

01:02:27
Bartek
Or at least. 

01:02:28
Alejo
Delay the ceiling as long as possible? So you're talking self refinement, which sounds like a branch from the QA agent, may or may not. 

01:02:45
Bartek
The evaluator agent, an evaluator agent into the extractor agent. And also I'm thinking like this is refinement on the process one time. But I'm thinking we could also have agents that if the refinement happens, so the initial output was somewhat wrong because maybe not always could be wrong, maybe sometimes it will just go fine. 

01:03:09
Alejo
Right? 

01:03:09
Bartek
And the evaluator has nothing to say. QA agent has nothing to say. But if they have something to say, we should save that and have agent that keeps track of the refinements that happened and use that as later maybe knowledge base. Oh fuck yeah, dude, let's go. 

01:03:29
Alejo
Okay, that sounds like we're wondering like hey, where does the supervisor get into the conversation you just mentioned? Sometimes there might be like space for the self refinement agent, for the Q agent, and we might need to go back or reroute the conversation. So now we know a point where we want a supervisor to say hey, who's next? And it will have obviously knowledge of each agent, what they do, maybe a summary of their system QA. 

01:04:11
Bartek
The QA agent needs to also report the supervisor agent like the evaluator agent do. And then supervisor makes the refinement loop. 

01:04:23
Alejo
And now the supervisor. And now we start routing. Okay, we run out of figma board. We have the evaluator agent, then the QA agent. 

01:04:46
Bartek
So we can go either to the evaluation or to the extraction from supervisor. 

01:04:52
Alejo
Now. So we have PFA extractor which creates multiple queries optimized for rag. Then we have the knowledge which goes to parts of extraction from the knowledge base. We have the evaluation of that answer. What are the most relevant chunks then QA agent. We haven't defined yet what we do with these chunks. Trying to answer the prompt, right? So if we don't forget about what the user is asking, we're trying to answer the prompt. We now have the most relevant chunks to answer the prompt. At least we think we do. We pass it through the QA agent and we confirm yes, we have the most relevant chunks. Are we ready to answer the query? No. What is missing? 

01:05:57
Bartek
So we need like aggregator agent that, wait, aggregator agent or something else. We just need to now get these things that come out of the evaluator or QA agent. 

01:06:17
Alejo
And have a path. 

01:06:18
Bartek
Downwards I guess to the, something should happen before the answer is now. And now we have evaluator that has scored the outputs and now those best scored we need like a merger agent. 

01:06:36
Alejo
I think that will take the go ahead. 

01:06:40
Bartek
The merger agent could take the best scoring from the evaluator, best scoring answers and then analyze them. Let's say there is the best chunk, but in the second best and the third best chunk there is also some stuff that is not in the first chunk. You get me? So the manager agent take the best pieces out of the say three most scored chunks and takes the best pieces into the answer. 

01:07:18
Alejo
Yes. So take the best chunks from evaluator agent and create a full answer for each rag query, basically submerging the best. 

01:07:28
Bartek
Pieces now merging the best pieces. It's good now. No, it was good. You just add it at the, yeah, you take the best chunks and then for each rack query you merge the best pieces from those chunks. 

01:07:48
Alejo
Best pieces from each chunk. We will work on the wording later because we are following. Okay. The merger agent takes the best chunks from the evaluator agent and creates a full answer for each rag query by merging the best pieces from each chunk. Okay. And merge the best pieces from each chunk to create a full answer for each rack query. Yes. Awesome. We're going to put the self refinement agent somewhere around here and we're going to start creating the routing function, essentially, which is most likely literally a function call with the input being which agent is next, if that makes sense. Kind of like the tool is function calling for routing to most relevant next agent. To continue the conversation. Okay. 

01:09:16
Bartek
I think that the supervisor is actually making those loops back to where it was the mistake, but the self refinement agent, it's more of like, I would say it's like a self refinement bookkeeper. So the one that keeps track of the refinements that happened and puts them in a knowledge base so we can have, this is where the self learning happens. Self learning knowledge base is happening right here. 

01:09:48
Alejo
Okay. So a supervisor could fulfill that role, technically could fulfill that role because he is keeping track of everything. He is tasked with being like the bright mind that can put all the pieces together and know who to call and kind of know what's missing. At the same time, the supervisor only knows what it knows. It's not necessarily there to judge what it was given. It's tasked with, take what it's given and run with it. It's like what's next, not what could have been better. So the supervisor says, hey, maybe there was room for improvement here. That's when the self refinement agent might create a kind of full evaluation of everything up till now and kind of find the blind spots which agent it was where the process went astray went wrong. 

01:11:15
Bartek
Yeah. Now this agent will have a kind of bookkeeper agent that's kind of working after the self refinement happens, it gets noted to the bookkeeper agent, which then keeps track of all the refinements that happen. 

01:11:32
Alejo
So then we would function more than another agent. It's like it could call the function of bookkeeping. 

01:11:42
Bartek
Oh, yeah. If refinement happens, then call the function to save the refinement process that happened. 

01:11:50
Alejo
If refinement happens, keep a log of full combo into what was wrong, evaluation of what was wrong, into improvements suggested, and at the very least, for now, let's not let the conversation just loop back. Let's just keep a log and that's going to be great. Training data to know what might need refinement as opposed to creating a crazy loop of agents that might end up no one knowing where to go next or like a feedback loop of bad data. So bookkeeping function, great. 

01:12:53
Bartek
I think that supervisor role is to know what to do next from there. 

01:12:59
Alejo
Actually, yeah, that's the function routing to most relevant next agent. Yeah, you mean from the self refinement agent? 

01:13:09
Bartek
Yeah. So the self refinement make decision what to refine and then supervisor makes a loop to that agent that needs to be refined. Okay. 

01:13:21
Alejo
Through all this we have to figure out, you talked about low hanging fruits, we have to figure out what's like. 

01:13:27
Bartek
Priority because that's the big picture now. 

01:13:32
Alejo
And this is great, you guys, this is truly going to be the future. Okay, so we know, let's assume that no refinement is needed. What we do know that we need is now a merger agent to take the best chunks from evaluator and merge the best species from each chunk to create a full answer for each rag query. Now that we have a full answer for those sub queries, we need to actually answer the prompt answer formatting agent. Okay, this is where if you talk. 

01:14:23
Bartek
In one prompt, this is the output format. 

01:14:27
Alejo
Yes. 

01:14:28
Bartek
And then from the merge chunks from the merger agent, it will have a structured output. 

01:14:39
Alejo
I see your mic going on Kuba, if you want to jump in, feel free. Okay, so we have answer formatting agent, but we're running out of figma space. Again, this is great. Okay, so what happens before the final evaluation of the answer? Well, there's answer formatting agent and in between evaluating the answer and deciding how the answer is going to be formatted, there's answer agent. So somebody that actually creates the final answer. 

01:15:32
Bartek
I found blind spot in all of this because the final answer is bot messages you with to do we need a knowledge base with the competency metrics or something like that? Like at least information about who is in the team. 

01:15:49
Alejo
At very least that's part of it. Knowing skills of each person and what they want to specialize in matrix. Good catch, man. 

01:16:01
Bartek
But yeah, I think that it should be at the end rather than in here. 

01:16:07
Alejo
So for each different use case, this is something great, this is a great point you're bringing in. It's like, hey, what's the actual use case? But this is not the answer agent. This is the formatting agent. What's the actual use case. What other info might be needed? But then is this, what other info might be needed? The answer formatting or the supervisor. 

01:16:49
Bartek
Or sort of like team manager agent that we are getting the answer, but now we need to actually choose who going to do what from this answer we got. 

01:17:06
Alejo
Okay. So we could subdivide this supervisor into other sub agents, like an HR agent. 

01:17:15
Bartek
Or team lead agent. 

01:17:20
Alejo
Yeah. It would feel slightly redundant to this supervisor because they can have that ability. Yeah. 

01:17:32
Bartek
I'm just thinking if it wouldn't be too much for one agent, but let's talk MVP and maybe it will work. 

01:17:38
Alejo
Okay. Yeah, it's 02:20 a.m. For me already. But we're in a roll. We're in a roll. And then decide which agent comes next. Right off the bat is keeping track of the conversation, identify what info might be needed and then decide which agent comes next. Doesn't feel like too much. There's going to be other things that we add on top. 

01:18:08
Bartek
Also assign team members. 

01:18:10
Alejo
Assign team members. So what's the actual use case? For example, E. G, for the to do task use case, we would need to check relevant skills. Assign team members. We would need to. What else? 

01:18:43
Bartek
Decompose tasks. 

01:18:46
Alejo
Decompose tasks? Yes, decompose projects into components. Into tasks. 

01:19:02
Bartek
Assign deadlines. 

01:19:05
Alejo
Assign deadlines. Which ideally we're saying out loud during the call. 

01:19:16
Bartek
It'S like deadline for the whole project. Right. We talk on the call, but there is another deadline for the tasks and for the components, right? 

01:19:27
Alejo
Yes. We then have to figure out over time how much autonomy do we want to give it, even if the output is perfect, the nuances of humans and hey, I'm actually quite swamped this week and I'm only now learning rag. So how big of a deadline, how long of a deadline or how big of a task can I really take on? Let's keep that human for now. And the scrum assistant can help with the evaluation, sort of the analysis, evaluation of all of that. 

01:20:18
Bartek
Yeah. We could also have at some point availability checker, something like that. So checks tasks already assigned to the person. 

01:20:33
Alejo
Yeah. So like, checks tasks already assigned. So we need project manager management tool to keep track of this, which is likely going to be notion. So we're actually already migrating a lot of stuff to notion and we can then automate the project manager within notion. Check tasks already assigned, deliverables missed and delivered, missed. And it can help sort of adapt like, oh, well, maybe this person is overloaded right now and kind of like checks capacity and then assigns. 

01:21:29
Bartek
This is already fault three we're talking. But that could also be like contribution calculator or whatever. 

01:21:41
Alejo
Yeah, contribution calculator. And I actually found a great template to do that. It's an airtable template where you can create a project and then keep progress logging. Yes, absolutely. And maybe even that can be filled automatically during the call live. That'd be cool. Kind of like project automated auto project logging, progress logging. 

01:22:32
Bartek
Okay, and after that we have like a UI thing going on. After the answer we are stepping out of this agent. Now we have UI, so either yes or no. For V one, for example, you get the to do list from this and then you have option to say like. 

01:22:52
Alejo
Yes or no, yes or no, like. 

01:22:57
Bartek
If you take the task or you don't take the task because you get assigned to something. AI already checked. You can do this, but now it's human decision if you want to do see? 

01:23:09
Alejo
I see, yep. 

01:23:17
Bartek
Now we're getting to the human, to. 

01:23:19
Alejo
The UI confirm task. 

01:23:23
Bartek
I think that should be like separate card because we are stepping out of this is not AI anymore. We are going to the UI, to the human. So that should be like another card. 

01:23:37
Alejo
I think so. These are use cases. Each of these subcomponents may or may not contain AI. I want to just make sure that we're not now dividing the use cases into what we'll need, just so we can refer back to these and look at the whole use case as a whole. It's going to be very important to be very clear and almost like simplify use cases so we know what the success criteria is of each use case. Yes. Now knowledgenow completes this to do task successfully and we don't have such large variations of branches of the use case itself. So I'm putting here confirm task assignment. We'll figure out how that works and where that fits in. 

01:24:37
Bartek
Right. So. 

01:24:42
Alejo
Let'S look at it backwards so we get the final answer. Hey, these are your to dos based on the project, based on the deliveries that you have, the capacity that you have. This is what has been assigned to you. Do you accept these? Which ones do you accept or do you want to review this? Yes, I accept. Contribution calculator comes later. You can message bot to catch up on meetings and get clarity on assignments. Which was the first low hanging fruit that we identified even as a subcomponent of this. We asked about this, right? What are the low hanging fruits? 

01:25:33
Bartek
Okay, I think what we should do now because we have this high level thing and now we should maybe go backwards like you say, and mark the things that are required for the minimal version. 

01:25:45
Alejo
Yeah. 

01:25:48
Bartek
Let's have this green sticker. Where is things required? 

01:25:54
Alejo
Okay, cool. So we know that the actual output is required and we'll just tag like MVP. That's a little too small. MVP. Bam. Evaluation. We're going to be doing manual evaluation. 

01:26:17
Bartek
Yeah, I think all evaluations can go to the V two. 

01:26:21
Alejo
Yeah. Answer. Obviously we need answer. It feels like depending on the use case. Well, we're going to start with one use case. So the format is already going to be set. Maybe we don't need an agent to come up with a format to give summaries of meetings that is already set. Then we have merger agent. 

01:26:50
Bartek
We are doing agent comes from evaluation. 

01:26:54
Alejo
So no supervisor, I think supervisor. Yeah. We ended up not having any branches. This is all sequential. The only branch is the self refinement agents, which is probably not the MVP. 

01:27:19
Bartek
So. 

01:27:23
Alejo
I'm sure that a free for all conversation is going to be important, especially for coding tasks. So does this task require multiple agents having an open conversation. 

01:27:48
Bartek
For example. But we are talking like a board of the company. Like this is the board. And then later, if we have some tasks like coding and stuff, we would have another kind of system or swarm. That is the worker agents. Yeah, I don't think the programmers are in this diagram. This should be like another diagram of the worker agents because this is high level. Like a board. Like a seaboard. This thing we just built is like a seaboard. 

01:28:22
Alejo
So kind of like, well, I'm just leaving at programming team. So programmer, tester, whatever, which for coding tasks we would need to route to here. You've definitely been watching the has framework. When you throw out the word. This is the board. The supreme oversight board. Yeah, no, it's a great concept. It's a very well developed concept. So yes, supervisor, moderator board. So these in itself could be a multi agent system because alignment, again, is probably the hardest problem in all of AI. So is this really a single agent question for not the MVP? Okay, we have the evaluator agent, which grabs the relevant chunks for each query. So we need an agent to grab those relevant chunks to grab chunks, period. So that's the extractor. 

01:29:33
Alejo
So we need an extractor which will break down a prompt into break down prompt into multiple queries optimized for rag. I think we have something in our hands with you guys. And then, well, the knowledge base will need it, which is not trivial. And then finally we need context enrichment. So we need global context and this is human input. 

01:30:15
Kuba
Guys, I have to bounce. 

01:30:17
Alejo
Okay, we're pretty much done, so thank you for sticking through it. Kuba, great to have you here. 

01:30:28
Kuba
The prompt engineering resources that I told you about. 

01:30:33
Alejo
Yes, thank you for reminding me. Bartek. Kuba asked about some prompt engineering resources to sort of keep learning, keep getting better. I think it'll be good for all of us to sharpen our prompt engineering skills. Would you share some intermediate into advanced resources with Kuba? 

01:31:00
Bartek
I already shared at some point the documentations. 

01:31:04
Alejo
Documentation. Right, right. 

01:31:06
Bartek
And the OpenAI guide. That's the thing for me. This is very beginner stuff. So if you talk intermediate, I would recommend reading markdown syntax and getting familiar with all the markdown things can. All the things markdown can do. Because that's actually how before going to latent space, because I'm referring to how I upgraded PFA because field version of PFA is already the documentation level stuff. But then the next version, like the PFA overseer was about, I was reading the markdown syntax and I was thinking, okay, I have this markdown syntax. I know Markdown is using the prompts. How do I use all those things markdown have? Because Markdown have quite a lot of things you can do with Markdown. So getting familiar with Markdown, I would recommend. Definitely. And then later I would recommend for more advanced stuff. 

01:32:02
Bartek
Getting familiar with the latent space activation. 

01:32:05
Alejo
Okay, cool. Like sparse representation and all that stuff. 

01:32:14
Bartek
Yeah. Also there is actually the latent space activation function written by David Shapiro, so that you can also find it on his GitHub. Also on my GitHub, you can find it's still not finished, but I've been doing a Vicky for PFA. And in this Vicky, I have a little bit like two kind of little articles about latent space activation from my point of view and from point of view on property engineering. So how to use latent space in writing? Persona for the AI for the sale. You make an agent and you want a Persona, and you want this Persona to be with the latent space activation included. So you can read about this at my GitHub. 

01:33:02
Alejo
Okay, I will share the latent space activation video with. 

01:33:12
Bartek
Shapiro. Okay, cool. 

01:33:14
Alejo
So, Kuba, I'm sending you two resources to start, and let's evaluate from there, if you need, where you feel like you want to go from there, if more into the very specific and advanced Personas, et cetera. 

01:33:33
Kuba
All right, thank you, guys. Thank you, Batik. 

01:33:37
Alejo
Yeah, I'll see you soon, and we'll talk about the personalized outreach system. I went in a bit of a rabbit hole of evaluating which LLM is best at refactoring a whole big project into a proper repo that we can actually maintain. So all these different files and all that stuff. But I will add that to you by tomorrow. 

01:34:05
Kuba
All right, no problem going with your stuff. 

01:34:08
Alejo
I'll send you some more documents and we can with a bigger knowledge base. 

01:34:13
Kuba
All right, guys. 

01:34:15
Bartek
Good job, brother. Yeah. 

01:34:21
Alejo
Prompt engineer. 

01:34:22
Bartek
All right, so we've got like 1234 agents for the MVP. 

01:34:34
Alejo
We have to figure out the use case. There's the answer. Agent one, evaluator, extractor four. 

01:34:46
Bartek
All right, but the problem is that the first agent is a swarm itself. 

01:34:54
Alejo
Sure. It need not be. Remember, you have built an amazing product just by itself, and we're going to make it even better. Dude. 

01:35:11
Bartek
I'm striving to make it like, don't make a mistake, because now, because of the randomness, you cannot control in the GPT because you cannot even set the temperature. I'm not even talking about the other parameters, but you cannot even set the temperature. So that's why it's so random. And that's why sometimes the prompt is just like one line. I hate it. 

01:35:35
Alejo
So this is what I'm going to need from you. I need you to pat yourself on the back for creating an amazing product that we are going to put in a whole different category of amazing once it's multiagent. And right now, we really need to focus on creating the bigger product because again, that's one amazing, but just one component of the whole system. And I am absolutely sure that through these testings, through these. Hey, now create, break down this enriched prompt into multiple queries optimized for rag. You're going to find new things to make better, not from this 8000 character prompt, but how to actually make it into these multiple agents. And then we'll step into that. 

01:36:38
Alejo
So let's give it a little bit more freedom by taking it out of the chat OpenAI context window and limitations and putting it into a new environment where it can be a little more free and we'll see what it does. 

01:36:59
Bartek
Yeah, actually, I already drafted the prompts for, like, context agent. There is like, wait, there's context agent. There is the PM agent. Like a Pmidation agent. 

01:37:13
Alejo
I'm going to write this down. 

01:37:14
Bartek
This is the context. 

01:37:15
Alejo
Context agent. 

01:37:18
Bartek
Then there is the pmidiation agent. Iteration, iteration, like ideation. 

01:37:28
Alejo
And then there is ideation agent. 

01:37:31
Bartek
Yeah. And this ideation agent is like technic choice, fusion structure and latent space activation. 

01:37:42
Alejo
Fusion, latent space and what else? 

01:37:46
Bartek
Technic choice. Like a prompt. Technic choice. 

01:37:51
Alejo
Oh yeah. Fuck yeah. I love that. So it'll know if it'll go like tree of thoughts or chain of reasoning. That's cool, man. 

01:38:01
Bartek
That's such a good idea. 

01:38:03
Alejo
I love that. I've had that in my brain for so long. I love that. Okay, awesome. 

01:38:11
Bartek
And it's been on my whiteboard for quite a long time. 

01:38:15
Alejo
That's cool. 

01:38:17
Bartek
And then later is the generation agent. 

01:38:20
Alejo
The what? Generation. 

01:38:22
Bartek
Generation agent. The actual generation of the prompt. 

01:38:25
Alejo
Okay. 

01:38:26
Bartek
And that's where I'm at currently. But the ideation PM agent is still work in progress. So I finished the context and I finished the generation because that was basically had before. I just had to take that out to the one, to the separate prompt. So that's why in my vs code is the current state of the PFA swarm. Later on there will be obviously after generation there is evaluation and there the iterator. 

01:38:55
Alejo
Okay. And what we need to do progress. And what we need to do is knowledge. Now wait, Tor, remember this, we are checking which agents we've yet to build. And these are going to be the tests of this whole system. 

01:39:16
Bartek
Right. 

01:39:16
Alejo
So we're calling knowledge now. I love this. Okay. Evaluator agent. 

01:39:23
Bartek
Yes. And then iterator agent. 

01:39:25
Alejo
Iterator agent. 

01:39:28
Bartek
Then I have still cloudy talk. 

01:39:33
Alejo
Extractor agent, or we've yet to build. We need to break down a prompt into multiple queries optimized for rag. 

01:39:41
Bartek
Yeah. So that's also to do. 

01:39:44
Alejo
Okay. 

01:39:45
Bartek
Extractorate, because that's not part of the PFA swarm itself, it's just part of the knowledge. 

01:39:50
Alejo
Right, right, exactly. Okay. 

01:39:57
Bartek
And then also I got an idea. This is like a very raw idea. Like after the iterator, if you can see that after the iterator, there is prompt levels. Upgrade, swarm. I'm thinking like upgrading of the prompt will be another swarm upgrade. I still don't have that laid out completely because for V One there will be the iterator agent doing the upgrades. But what I'm thinking later, after iterator make a fish upgrade, we can have levels of upgrades like level one, upgrade Markdown, level two, upgrade complexity. Level three, upgrade latent space activation. 

01:40:44
Alejo
So that is what I would love us to have as a testing framework of the PFA system. Like talking about that. We can integrate here, of course, but as a whole different system, these multi agents. And have the testers be kind of like what you showed in promptful, but on steroids, of course, evaluation and leveling up. So is that what we're doing for MVP? 

01:41:23
Bartek
No, that's for like, that's poultry or something. 

01:41:26
Alejo
Okay, so I'm then going to put this in green and it's MVP. Yeah. Okay. 

01:41:37
Bartek
And then we will have like a testing upgrades form for later testing. 

01:41:46
Alejo
Upgradeswarm. And that's going to be V two. Okay. No, the other way around. V two is going to be testing an upgrade swarm with levels E. G. One, markdown two. What would level two be? 

01:42:15
Bartek
Complexity or like details. 

01:42:18
Alejo
Details. Three, accurate context capture. Okay. Anyway. Oh yeah. Actually run on the environment. Actually run the code and we'll figure this one out later. This is not V one, the programming team. 

01:42:49
Bartek
So. 

01:42:52
Alejo
Input we have. So what do we need to do? We need to do the for agents. This is what we need to do. And then for other stuff we need global context. We need knowledge base. 

01:43:20
Bartek
No, I got to beard back 1 minute. 

01:43:23
Alejo
Yeah, we need answer agent. And I'm glad we budgeted $800 for fast rice. This is going to get fun. Make a message bot to catch up on meetings, declaring assignments. It discord. Discord. Right. Amak. 

01:44:48
Bartek
Let'S sum up what prompts we need for those agents. So prepare those prompts for the MVP of the knowledge now. 

01:45:07
Alejo
One sec. And then answer agent. And then for other stuff is the global context, the actual knowledge base which I'm working on. And then the discord bot web. Love it. This is looking so nice. Prompts. 

01:45:43
Bartek
We have four agents. The context enrichment is like 90 or 80% done because I had it done for PFA. So I would just tweak it a little bit for the knowledge now. So it's enriching in the transcript case rather than prompting case. 

01:46:03
Alejo
Yeah. 

01:46:05
Bartek
Later we have the query agent, direct query agent. 

01:46:18
Alejo
Which is the rag extractor. 

01:46:22
Bartek
Yeah. 

01:46:25
Alejo
Aha. 

01:46:30
Bartek
Then we have evaluation in V one. 

01:46:36
Alejo
The evaluator agent that will actually. So the rag query extractor agent. The rag query agent will create the queries from the prompt. And then the evaluator agent will say, these are the best chunks from that. Extract from that cosine, similar. 

01:47:02
Bartek
But the iterator agent is for. 

01:47:06
Alejo
Oh, you mentioned for V one that would be V two. Yeah. 

01:47:12
Bartek
But now I'm talking about the knowledge now. So yeah, for the PFA there is an iteration agent. 

01:47:19
Alejo
Right. 

01:47:19
Bartek
But I'm talking about knowledge now because I'm thinking about the prompts needed for the knowledgenow system. 

01:47:25
Alejo
I'm talking about knowledge now too. But you had mentioned an iterator. 

01:47:30
Bartek
Oh, it's for. 

01:47:36
Alejo
PFA swarm. So that would be an iterator. 

01:47:44
Bartek
Just I thought like, both of these green cards are for the PFA swarm, right? 

01:47:51
Alejo
Well, technically, yes, they are, but this is also for knowledge now. So I'm going to put different colors and we're going to call this V two for V two. This is what we're focusing on now. And the other stuff we're focusing on after we have the MVP, not that we can't keep thinking about it, but in terms of output. 

01:48:26
Bartek
Right. So the progress part is actually for the PFS world. 

01:48:32
Alejo
Gotcha. Gotcha. Great. So progress, bam, we put here. Great. Thank you for clarifying. And are any of these agents relevant to our MVP, which would be the context agent. Context enrichment agent, which is at 80%. Yeah. 

01:49:07
Bartek
Because for the PFA swarm, it's finished. It's just that I will have to make a little different vanishing for the knowledge now. So be more relevant to. 

01:49:24
Alejo
Evaluator, iterator agent was the other one. That was not that. Then evaluator agent, rag extractor agent, query builder agent, and then we have the answer agent. And then for other stuff that we need to have build is the global context, which is sort of a short system, prompt kind of style knowledge base. All of our transcripts. All of our transcripts or detailed summaries of our transcripts. It would probably be the full transcripts. 

01:50:09
Bartek
Or the cleaned transcript. Clean from those weird words. 

01:50:13
Alejo
Yes, cleaned transcript. And I think we are going, I have that code. 

01:50:24
Bartek
I think we should be going like one transcript per one use of the knowledge now. Because if you throw all of the transcript in the one knowledge base, I'm not sure how that's going to go. I mean, you want to extract from one meeting, right? You don't want to extract from every meeting at once. 

01:50:43
Alejo
The whole point is that there is continuity from meeting to meeting. 

01:50:50
Bartek
Yeah, but at one, say, run of the knowledge, now you're extracting from one particular meeting. 

01:50:57
Alejo
Right. 

01:50:58
Bartek
The all meetings is like a global context, like infrastructure, knowledge base, something like that. In my variant there is the run. It's on a one transcript, and then we have output of that and that should be saved into the all transcript knowledge base. Not the transcript itself, but the result of the knowledge. Now doing the work, analyzing transcript, and then have like summary or something like that. 

01:51:41
Alejo
Okay. I'm not 100% sure. What is the difference. We'll be testing this most likely with a few transcripts and see what it pulls. Because there is relevant information for the same question in different days, different meetings. Right. System or knowledge. Now we will limit it because it's a good point that you're bringing like are you really going to put like 100 hours of context of transcript just to grab from a knowledge base? That would be pretty messy and confusing for the rag. 

01:52:34
Bartek
So. 

01:52:38
Alejo
But that is part of why we have the evaluator agent, because it's like, hey, based on the enriched prompt, the rag queries, this chunk that you withdrew, we're talking about AI agents. We're not talking about real estate agents. So this is irrelevant or the other way around. We're talking about a real estate solution. So AI agents doesn't make sense. So the evaluator would figure that out. Good question. Let's test it. Let's get the MVP. Let's test it. We'll figure out what we change and also obviously how we manage our knowledge base, which is going to be garbage in, garbage out. The quality of the data, the underlying data has to be high and we'll do our best to have a solid data quality standard for our MVP and we'll make it better over time. 

01:53:34
Bartek
And you see that we are making, let's see, the call ends. The transcripts get rendered automatically or you have to do that yourself. 

01:53:47
Alejo
We will be able to render them. 

01:53:51
Bartek
Automatically and then also we should automatically have them cleaned. 

01:53:56
Alejo
Yes, correct. 

01:53:57
Bartek
And the question is now if we also want them automatically to be pushed into the knowledge now. 

01:54:07
Alejo
That is definitely a pending question because what? Oh, that's what the global context is. Oh my God. Global context is. This is what the dev team does, has worked on, is working on. This is the marketing team. This is who composes the marketing team. The upcoming strategy does say videos published, et cetera, et cetera. And that's the global context that, based on what the original query and the enriched query is, will have certain relevance. So we can create what makes sense to me as a gated access of information to guide. I don't know if that's what you meant by global or global meaning every single component, every single transcript is there. But we'll figure that out at the start. 

01:55:30
Alejo
If we want to enrich a prompt, let's give it some context and then we can dig into all the details and the transcripts and all that stuff. 

01:55:40
Bartek
Yeah, I think it also depends on the use case. I feel like some use cases could be done automatically. Like we automatically render the transcript, automatically clean the transcript and let's say for the to do we also automatically run it through the knowledge now. But I guess some use cases will be like run manually and some use cases will be run automatically. 

01:56:01
Alejo
Yeah. So I'm going to write dockup considerations, auto run or human check or fully manual, e. G. Modifying the dev team global context document. Because when a new project comes in and we have a new project we're working on a new project, the dev team global context document needs to be updated, but we want to do a human check. 

01:56:52
Bartek
That's like. 

01:56:53
Alejo
Yes, that's how you should update it. Dev team deserves human check. Okay, cool. Okay. You threw out other considerations there. What was it. 

01:57:15
Bartek
I was just saying before about the automation of rendering and cleaning? So I guess that happens automatically all the time. And then we only have differentiation for. 

01:57:28
Alejo
The use case rendering and cleaning. Yeah, auto cleaning, but auto rendering. 

01:57:41
Bartek
And also we can have, how to say, categorizing the transcript into like dev call or marketing call. 

01:57:52
Alejo
We're lucky because Zoom already does that for us. This right now that we're on is a dev meeting. And if you look at the chat. 

01:58:01
Bartek
Oh yeah, I forget the name of. 

01:58:03
Alejo
The meeting, and you scroll up, all of our chats of every dev meeting are there, including the summaries. So it's pretty cool. 

01:58:13
Bartek
All right. 

01:58:17
Alejo
And just to be funny, I'm going to ask the AI companion. Catch me? 

01:58:32
Bartek
Yes, I think that's the end of my idea for today. 

01:58:37
Alejo
Well, that was 2 hours of idea. So I'm asking the zoom AI companion to give me an in depth explanation of knowledge now. I'm sorry, but the meeting transcript does not provide enough information to give an in depth explanation of knowledge now. So the rag sucks. 

01:59:00
Bartek
But this is like the zoom out of the box transcript analysis, right? 

01:59:06
Alejo
Yes. Okay, I'm going to walk through this real quick and we can close it. So I input a prompt, there's global context about who fasterize is, who the teams are, and who each person is. That context allows the PFA context enrichment agent to fix and enrich the prompt with the context and outputs an enriched prompt. A lot of the word enrich in there. We'll fix that. We'll ask PFA to fix that. That follows into a PFA rag extractor agent which has access, full access to the knowledge base. The output of, wait, that goes after. The output of this extractor agent is to break down a prompt into multiple queries optimized for rag. Those queries going to the knowledge base which will be living in pine cone. And that knowledge base has the most recent Zoom call transcript, plus every other transcript we have. 

02:00:27
Alejo
It knows skills of each person and what they want to specialize in through the competency matrix and it has knowledge of projects, clients, industry, focus, et cetera. Then comes the evaluator agent because we extracted for each query several relevant based on semantic similarity, based on cosine similarity, several chunks of information. We now need to evaluate which chunks are relevant because if we're talking about real estate agents, AI agents shouldn't be part of the answer that we're integrating, or maybe yes, depending on the automations that we're building for them. So we have an evaluator agent to say, hey, these are the most relevant chunks for each query. This is the score from one to ten for each chunk, and here are the top five chunks. From there we will have a QA agent that will do a full transcript review. 

02:01:28
Alejo
So what chunks were retrieved and then do an evaluation of how well did the evaluator agent do its job. We will integrate an oversight board agent that will be able to route to the most relevant next agents to continue the conversation. So we'll keep track of the conversation. Identify does this task require multiple agents to have an open conversation? What other information might be needed? And it will decide which agent comes next, which might be a self refinement agent to log potential refinements to the system. It might be the programming team or most commonly it will be the merger agent which will take the best chunks from the evaluator agent and merge the best pieces from each chunk to create a full answer for each rag query. 

02:02:23
Alejo
Each individual rag query and the final steps are we have answer formatting agent prompt format no wait, that goes to the beginning. We will have answer formatting agent for hey, what's the actual use case and how we make sure we are effective at answering. And there's a big one here who is asking how can we give them a relevant answer that they care about? The CEO doesn't care about the same thing as the engineering manager. So we'll give the output format to the answer agent. It'll grab all of the relevant information and create a final output. Finally, we will have an evaluation answer evaluation agent which will help us keep track of the accuracy of our system. How close is this to a full accurate relevant system? 

02:03:36
Alejo
The first use case is going to be the first MVP use case is going to be you can message the bot to catch up on meetings and get clarity on assignments, which is going to be one component of our V one use case which is the bot messages you with your to Dos after the meeting checks the tasks that you already have assigned your deliverables checks the capacity and then assigns the tasks. It will confirm with you which tasks you actually want and can take on. It will actually help calculate your contributions and you can have a conversation with the bot to get clarity on those assignments and do your best work. That's knowledge now. 

02:04:24
Bartek
Yeah. And also it will attack everybody to make a post on social media. 

02:04:31
Alejo
It will what? 

02:04:33
Bartek
It will attack everybody with a message to write something for the social media. Seriously, I need like, attacker to attack me every day. 

02:04:46
Alejo
I don't know that attack is the right word. It, but yes, we need, it's more. 

02:04:53
Bartek
Of a peeing, but I don't know. I want this AI to be aggressively making me write a post because otherwise I won't. 

02:05:02
Alejo
Dude, this is going to be a huge part of the knowledge base of knowledge. Now don't use the words aggressive and attack. That's funny. We'll cut that out. We'll cut that knowledge now. Cut that last part out. But I'm with you. I'm with you. Let's have something that we're proud to show PFA. You should be proud to show it. The real estate automations, as simple as they will be. We're proud to show it. It's our first client and we're actually delivering something great for them. So let's get on that social media game and let's grind these projects out for now. This is what this project and fastrase needs from you. Bartek working on the agents. Let's get some drafts for these three agents. 

02:05:58
Bartek
Can you send it to me in a chat in a private message? 

02:06:03
Alejo
That's exactly what I was about to do. Awesome. So we need draft prompts. 

02:06:15
Bartek
For. 

02:06:19
Alejo
Great. 

02:06:22
Bartek
And also context agent, right? 

02:06:27
Alejo
Oh, did I not put that in there? Oh, yeah, you said the context agent was 90%, but yeah, I'll add that in there. It was in a different section. 

02:06:37
Bartek
Yeah, because it's finished for the PFA swarm, but for the transcript, it has to be a little tweaked, I think, because it's kind of a little different. Context enrichment in case of transcript analysis and in case of prompt engineering, it's a different thing. 

02:06:53
Alejo
Yeah, makes sense. 

02:06:54
Bartek
Okay, cool. And do you need any help with the real estate agent projects? Maybe Hubert can help you with that. 

02:07:05
Alejo
Thank you. Not for now, because it would be more lift, it would be more time spent kind of guiding someone through all of the components of number one, the CRM, number two, the API, and then most importantly, what the client wants and how they want it. So I am going to show, not tell. I'm going to first work on these two free automations that we're making for them. And then I'm going to show hooby, for example, and walk him through the final build the output, and then go backwards from there. And we can all work on those. They'll be relatively simple and we all want to make money. So I want to integrate everybody into at least one part of those real estate automations. 

02:08:02
Bartek
Yes, awesome. 

02:08:06
Alejo
Knowledge. Now draft 1 March twelveth 2024. Let that date be remembered. 

02:08:19
Bartek
Yeah. And check out the messages I sent you before this call. I found some transcript. 

02:08:26
Alejo
Oh yes. 

02:08:26
Bartek
And also those videos. We can use them also for this. 

02:08:31
Alejo
Cool, cool. Lovely. I'll check them out in between tomorrow. I'll check them out tomorrow. I'll find some bartech, thank you for your. This is, this has been very fun. I'm honored. 

02:08:46
Bartek
Yeah, sure, man. Yeah. Happy to work on this one. Seems that it's going to be revolutionizing. 

02:08:56
Alejo
Yeah, absolutely. We can help a lot of people make better lifestyles, better work, better everything. 

02:09:04
Bartek
Yeah. 

02:09:04
Alejo
Take care, brother. I'll see you tomorrow. 

02:09:07
Bartek
Yeah, bye. 
