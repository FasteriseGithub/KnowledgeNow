{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Lbraries\n",
    "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "import os\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93072522-ca0d-440f-b702-dfecafedce05'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file from directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(data):\n",
    "    loader = DirectoryLoader(\"data\",\n",
    "                    glob=\"**/*.txt\",\n",
    "                    loader_cls= TextLoader)\n",
    "    text_documents = loader.load()\n",
    "    return text_documents\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"\\n01:09\\nAlejo\\nOkay. Hi, see you all again. \\n\\n01:17\\nBartek\\nWaiting for us or it's only three of us here? Hi guys, I'm hearing you right now. I just had a dinner, so excuse me, eating. Aleo, I think you have something with your audio. I can't hear you. Aleo, you're not here. \\n\\n02:49\\nAlejo\\nOkay, I guess no headphones it is. Hey you guys. \\n\\n02:53\\nBartek\\nYeah, sounds good. \\n\\n02:54\\nAlejo\\nCool. \\n\\n02:55\\nBartek\\nHi again. \\n\\n02:57\\nAlejo\\nHey, did you say something? Is there something you wanted to share? \\n\\n03:05\\nBartek\\nI just wanted to share that I have great. Dinner or lunch? Lunch. I messed that up every time. Lunch. \\n\\n03:13\\nKuba\\nHi guys. \\n\\n03:15\\nAlejo\\nHey Kuba. \\n\\n03:23\\nKuba\\nLet'S see how you doing, bro? \\n\\n03:35\\nAlejo\\n1 second, you guys, thank you guys for sharing your update on Friday. It makes me very happy to see progress on what you get to work on or what you want to work on. I hear a lot of rag, I hear a lot of lang chain. As you said, kuwa, rag is the future. And it's been very exciting to talk to developers this last week. A variety of experiences and expertise and they all say the same thing. It's like Rag is where it's at. Rag is the future, Rag is what I want to learn. So we're taking that strong indication and running with it. We're building knowledge now. Okay, first of all, before we step into that, because start rattling on, wanted to share an update. I'm working on the real estate automations. \\n\\n04:57\\nAlejo\\nI'm working on the free side on the two free real estate automations. When those are ready, I'll share the demo. In the next few days. They'll be ready. In the next few days. I'll share the demo. We can make sure we get some testing in together and I will make sure that each of us can follow the exact same process for when we actually have the paid clients that will come through referrals that we can emulate this system for their side. For some of those that might include importing contacts to the follow up boss CRM and just setting them up from scratch. For some of them that might be like, hey, I would like these automations and each of us needs to already know the API and how does the CRM actually look and feel? \\n\\n06:09\\nAlejo\\nSo I kind of tried to do that last week, but I realized I don't understand it well enough to guide others. So I took a step back. It's like, let me work on these automations, finish them, let me fall into the pits of working with any new API and make sure that I set up you guys for success once the money actually comes in. So that's the update on that. On real estate automations, client is still very excited. We got introduced to two people that she's working with, the manual follow up boss guy that's kind of importing her contacts manually and her social media person. And we're going to be able to find ways to help in both of those areas. \\n\\n07:09\\nAlejo\\nWe got some questions around profit sharing and we will make sure that we have a genexac to clarify, to share, to have questions, and to make sure that everything is clear. It's very important to us, to all of us, to each of us, that we know what's going to happen with the money once the money hits the account. Right. So we'll make sure that everybody has clarity on that and that everybody agrees. Yes, this is fair. Okay, so that's on the real estate side and that's the short term. Yeah, barta, go ahead. \\n\\n07:58\\nBartek\\nBecause we are kind of starting to work this week, probably internally on some content automation. So I think we can actually work simultaneously on the automation for the real estate. We have this idea to make notion integrated with relevance AI. Like make some agents, and for example you have idea for your content, you write it in the notion, you have this kanban in notion. And then for example, you have this raw idea and then some ideas you want to put to AI to draft. And then that will trigger the relevance AI agent, for example, first kind of EDH version of it. And then basically it would draft a post or whatever and then send it back to notion. So that's where I'm thinking, and we're probably going to start working on it this week if there is a time, if the winds are correct. \\n\\n09:04\\nAlejo\\nYeah, cool, that's good to know. \\n\\n09:11\\nBartek\\nAnd I also have updates now from the call just a second ago. \\n\\n09:17\\nAlejo\\nGo in a circle and do updates. \\n\\n09:18\\nBartek\\nSo go crazy. Yeah, so I was talking to this guy from the prompt hub, and we can have collaboration there, like constant collaboration or whatever. I was talking to him on this kind of note, but the thing that really clicked after this call, because I was showing him PFA and the output was kind of short. I mean the use case was for a recipe and for a cuisine, sending and generating receipts. So I see that the details couldn't be there more. But I got thinking like PFA sometimes does that PFA sometimes give a short prompt and you need to regenerate. And I was thinking like, we need the swarm, we fucking need the swarm. It's not a product until we have the swarm. This is just a proof of content. And if user have to know that the prompt. \\n\\n10:10\\nBartek\\nI know from my eyes that the prompt is not good, but users want. So we need to have this. The thing that I'm doing manually, like regenerating, like looking the prompt is not good. Or regenerating, or saying, like, use more markdown or make this prompt more detailed. We need a feedback loop for that in the PFS form, like some agents doing basically what I'm doing now. So the prompt is too short, the prompt lacks markdown, lack structure. We should really go there. \\n\\n10:42\\nAlejo\\nOkay, perfect. \\n\\n10:42\\nBartek\\nAnd I'm thinking about maybe we could repurpose some of our agent systems. Like, I'm not sure how we can. Maybe we can use the outage system a little bit to change it in a way that we could have those. Or maybe it's better to make it from scratch. I'm still not sure, but we kind of have this structure already where we have those agents talking to each other. I mean, they are not really talking. That are in a chain, right? Yeah, it's kind of chain of action rather than conversation. I think we need to step into the conversation part where we have some kind of hierarchies. Like this is agent one that making the context enrichment. And then there is another one, let's say in a simplest form, generating. And then we would have some agents that above them and check their work. \\n\\n11:44\\nBartek\\nAnd they need to talk, basically, yeah. I think we need to make it from scratch. \\n\\n11:50\\nAlejo\\nOkay. Make what from scratch? \\n\\n11:55\\nBartek\\nThe communication PFA is warm, like the lang chain framework for PFA, basically. \\n\\n12:02\\nAlejo\\nOkay. \\n\\n12:03\\nBartek\\nMaybe we can step into some kind of crew AI thing. It's popping recently. Crew AI on my. \\n\\n12:11\\nAlejo\\nSo let's. Let's get there. I want to make sure that Kuba and Hubi are with us on this dive into the possibilities I'm following. So let's get to the point where everybody's on the same page and we can actually make some decisions because there's a lot of things that we don't need to do from scratch. Right. There's a lot of research on communication frameworks that we can probably just grab from an open source and then just tune for the use case of prompt regeneration of PFA. So that's what we will step into. Since we're there. \\n\\n13:05\\nBartek\\nLet's just go there, Kuba, we'll get. \\n\\n13:07\\nAlejo\\nAround to personalized our system, and I'll give you an update on that. I would like to ask you, Kuba, were you able to start with this rack system from the single document transcript? \\n\\n13:24\\nKuba\\nYeah, I created it with pine cone. I tested pine cone and abute system. One with pine cone and one with. \\n\\n13:41\\nAlejo\\nPine cone and the other one with. \\n\\n13:48\\nKuba\\nOpen source vector database. \\n\\n13:50\\nAlejo\\nOkay. \\n\\n13:51\\nKuba\\nYeah, I'm just testing, like cosine similarities between the vectors. \\n\\n14:01\\nAlejo\\nI'm just testing, yeah. \\n\\n14:07\\nKuba\\nUpdates the two system. I will show you demo like that. \\n\\n14:13\\nBartek\\nCool. \\n\\n14:14\\nAlejo\\nYeah, you have it now. You said you have it now. \\n\\n14:17\\nKuba\\nYeah, I do. \\n\\n14:19\\nAlejo\\nAwesome. Let's do it. Let me allow sharing. It's great. Yeah. \\n\\n14:27\\nBartek\\nAlso, on the note of databases, I wanted to ask if, yeah, go ahead. In the meantime, I wanted to ask if we have capabilities on the AWS in our developer team or generally, because there is those two things. Like there is the vector databases and the new stuff, and there is the old stuff, the relational databases, non relational databases. And actually right now we are facing the problem, the challenge, more of them, the problem. Let's see. Challenges, not problems. So we're facing challenge to actually offering the chatbot that will kind of pick four different data inputs into a chatbot interface so the client can basically talk with it. Yeah, I refer to that Us client. And we're thinking if there should be one database out of those four, so we're going to have some data migration and stuff. \\n\\n15:36\\nBartek\\nSo I'm just thinking if there may be somebody who already been doing some of those stuff. I saw Kuba actually posting something on the discord about AWS, so maybe I can ask you if you've been doing some stuff with. \\n\\n15:50\\nKuba\\nYeah, yeah. During the weekend, I played around using streamlit. I created a little QC generator. So I created the front end with extremely, and I hosted it on AWS server. So it was like playing around it. \\n\\n16:09\\nBartek\\nHave you been doing some with daca migration? \\n\\n16:12\\nKuba\\nNo, not yet. \\n\\n16:15\\nBartek\\nAll right, so maybe we connect later after this call and maybe talk about this more, or are you aware of somebody else having AWS experience? \\n\\n16:25\\nAlejo\\nYes, because at another company\\xa0we worked with AWS. So I have experience with AWS storage. I have experience with limited experience with AWS systems, but they don't feel strange to know. I will ask around. And you're essentially looking for a systems engineer, like somebody that could do potentially a migration. \\n\\n16:55\\nBartek\\nYeah. \\n\\n16:56\\nAlejo\\nOkay, I'll ask around. Knowledge. Now remind me to ask for a systems engineer. Already getting used to it. \\n\\n17:09\\nBartek\\nBasically we need to do like centralized database for the chatbot interface. Like initial. \\n\\n17:15\\nAlejo\\nOkay, cool. \\n\\n17:16\\nBartek\\nThat's probably going to be migration of. \\n\\n17:17\\nAlejo\\nThe data migration into a data migration Aws into a central database. Okay, let's pause on that and we can talk more about it later. Kuba, the stage is all yours. Yeah. \\n\\n17:36\\nKuba\\nSo this is like the chart now. So first of all I put in my pocket, let me just keep this. So yeah, remember I told you earlier I'm not going to use Google Collab I have because number one, it's crashing my system for now because I'm testing, I found a way to build visual code. So this is like the other one I'm building like debugging. \\n\\n18:09\\nAlejo\\nColab is great. Colab is fantastic. Prototyping on Colab is a great idea. As we look at versioning and actually making it more usable, that's when we'll transition out. Colab works great for now, but thank you for clarifying. \\n\\n18:30\\nKuba\\nLet me remove, so let me walk you through the code. First of all I imported the meetings transcript using planchain. So this is like the transcript. So I splitted it into chunks. So this is a chunk of it. \\n\\n19:02\\nAlejo\\nWow. What are those? \\n\\n19:06\\nKuba\\nJust the chunk of the data. So this is the total length after the trunk of the data. So I embedded it using open AI embedding. \\n\\n19:17\\nAlejo\\nCool. \\n\\n19:18\\nKuba\\nSo I imported into the panic on vector database. So this is the name of the index here. So I just queried it. This is just a normal query like to just get the similarity search. So you just return the most very bad document. So this is it here. When I ask what type of agents can we create? So this is like the documents. So in this document I can indicate how many I want it, but I just listen to just. So now I want to pass the document into an LLM. Once you get the document you can answer my query better knowing the context. So I asked the question again, what type of agents can we create? It seems like the conversation is discussing creating agent for real estate or mortgage learning purposes. \\n\\n20:18\\nKuba\\nThis is not clear specifically what type of agents they are referring to, but it can potentially be an automated agent. Sorry, an automated agent or a human agent. It is also mentioned that they are trying to reduce the amount of agents. Keep the process simple and programmatic. So this is just like for querying it continuously, like putting it in a. \\n\\n20:46\\nAlejo\\nLoop at the very bottom. What's that output? \\n\\n20:53\\nKuba\\nYeah, it's just like keeping it in a loop that I can keep on asking. Like chatting with it conversational. \\n\\n21:07\\nAlejo\\nYes, but what is that result from? The meeting was about implementing automation services. \\n\\n21:17\\nKuba\\nOkay, this is like from another question I asked actually. Okay, I'm going to show you. Let me run. \\n\\n21:25\\nAlejo\\nSo you have great start, man. This is a great start. That's the one thing that's really annoying about Colab that you have to import upload the documents every single time. \\n\\n21:54\\nKuba\\nYeah. \\n\\n21:59\\nBartek\\nGuys, I thinking for the first version, for the MVP or proof of concept, I think we should list the most required functionalities we need. So I'm thinking definitely who is saying the stuff like participants. \\n\\n22:18\\nAlejo\\nWe're doing that with fireflies. So we are going to have that. Yeah. And if we can do it through zoom cloud, then it'll be even easier. So hold that thought and we will get to that point. We'll talk about that too. \\n\\n22:48\\nBartek\\nAnd one thing on the processing side, I'm thinking maybe we should use, I mean, it looks quite good over here, but the beginning of the transcript, weird. \\n\\n23:00\\nAlejo\\nWords. \\n\\n23:04\\nBartek\\nWe should have. Maybe. \\n\\n23:09\\nKuba\\nThere are a lot of weird words in the document. \\n\\n23:13\\nBartek\\nYeah, I'm thinking maybe we should have agent that corrects the words like extract the meaning. \\n\\n23:25\\nAlejo\\nSo that is already built. I can show you. I want to go from big picture to small picture. And we can talk about the components and the subcomponents. And fixing the transcript is one of those subcomponents. All right, call out. Cool. Let's see what it comes up with. I wonder how stochastic it is. Yeah, that's unfortunate. What if you try it again? \\n\\n24:04\\nBartek\\nWhat if you instead of agents say product? Because I think this was about the real estate how to say listing description generator. \\n\\n24:19\\nAlejo\\nRight? \\n\\n24:19\\nBartek\\nI saw it in the transcript. It was actually me talking about the first project of celebrities. So I think it's more of a product. Oh yeah. \\n\\n24:37\\nAlejo\\nGo. There we go. \\n\\n24:40\\nBartek\\nYou see, you need a prompt engineer. \\n\\n24:44\\nAlejo\\nThat's where that comes in. \\n\\n24:45\\nBartek\\nThe prompt registration. \\n\\n24:51\\nAlejo\\nShould we. Wow, this is just. \\n\\n24:59\\nKuba\\nLike imputing, like incrementing continuously. \\n\\n25:05\\nAlejo\\nOkay, got you. Let's try. This call was about knowledge. Now could you ask what is the product called, how is it used about. \\n\\n25:44\\nBartek\\nExtract and either eight project documentation. \\n\\n25:49\\nKuba\\nExtract. Sorry, I didn't get that. \\n\\n25:54\\nAlejo\\nExtract and ideate product documentation. \\n\\n26:00\\nBartek\\nProject. \\n\\n26:14\\nAlejo\\nI wonder how well it does with typos. Summary. So this is just extracting and interpreting the chunks from. \\n\\n26:28\\nKuba\\nThe vector store and the vector database. \\n\\n26:31\\nAlejo\\nYeah. \\n\\n26:34\\nKuba\\nWhat I need now is like using a prompt to guide its output. Instead I was just like typing just requesting. \\n\\n26:51\\nBartek\\nWhen need sort of extractor agent, like extract first and then ask later for something. In this situation we'll have two agents. One is extracting the information required, or even better, we start from what's required for the documentation for this project, from this little extraction, and then another extraction agent knows basically more where we're going with it. So say extracting. Then the documentation agent tries to make the documentation but lacks context. So it goes back to the first agent, to the extractor, and give me more context on this and this. And then it's kind of a feedback loop in here. \\n\\n27:35\\nAlejo\\nOkay. Yeah, totally. So we're noticing a few things. We're noticing the quality of the extracted documents from pine cone varies in quality, which is normal. It's only one transcript and the transcript is not even clean, so that's normal. Number two, we're noticing that the output of the queries is limited to only the context that it is given from the low quality extraction of the chunks. So it doesn't have much to work with. What if the next step was giving it more context and using that context to actually create a proper answer? Yes. And then number three or number four is the prompt regeneration so that the query being asked can be regenerated, say, by PFA, based on the context of essentially who's asking. In this case, let's just say it's the normal quote unquote faster ICE is asking. So just answer, faster ICE. \\n\\n28:58\\nAlejo\\nWho is faster ICE. Here's who faster ICE is. And we just feed the knowledge base of faster ICE. So there are some components there. Thank you, Kuba. This is a great start, man. This is wonderful. I wanted to be able to visualize these components, so let's pause so we can keep going forward. So we talked about a lot of things last meeting, it was brainstorming session, and we're taking all these ideas and all these use cases and we're running with it. So let's make it a little more visual. Number one, the thing that we know for sure, which is at the end of a. Sorry, I'm trying to remove the captions. They're in the way. Okay, well, it is what it is. At the end of. \\n\\n30:11\\nBartek\\nThe end of. \\n\\n30:12\\nAlejo\\nThe day, what we need is answer. Sounds obvious, but how do we get. So let's see. \\n\\n30:30\\nBartek\\nI think we definitely need to let PFA into the wild. I'm actually tired of the GPT version now today. It's really. I agree. Making me angry about this. \\n\\n30:45\\nAlejo\\nGood, get angry. Create new from that anger. \\n\\n30:50\\nBartek\\nLet's make it into the wild. Yeah, I'm thinking it will best if, for example, in this collab we would have PFA as a hint text. Can you imagine writing prompt and in real time it gets like autocompletion hint text kind of thing. How do we do that? \\n\\n31:14\\nAlejo\\nI like that. Okay, that's a whole different component. Let's figure out where that fits, because that probably fits here somewhere. \\n\\n31:24\\nBartek\\nYeah, knowledge. \\n\\n31:25\\nAlejo\\nNow let's start from the end of it, which is the answer. And I want to dig into this a little bit because, Bartek, you and I connected earlier today and we threw out some great brainstorming. I want to make sure that everybody's with us because we said some really interesting things that we could do with knowledge. Now we talked about a little more space. We talked about a bot that measures messages. You with your to dos say the call ends. We're in a dev meeting. At the end of this dev meeting, the objective for each of us is to have clarity on which of these tasks of this whole system that we're going to look at. We are tackling, it's a subcomponent of a component and we're going to make sure that we are each set up for success. \\n\\n32:31\\nAlejo\\nWhat that looks like with knowledgenow in the future, with knowledgenow, is that right after the meeting we can get a list of to do's. It's like, hey, this is what you're working on and these are the subtasks that you have to. Oh, right, okay. Yeah, thank you, Hubi. We'll get you the recording and we'll make sure that you have a clear task to work on. So at the end of the meeting, Hubi that now has to leave will get a list of tasks that he has to get done and maybe he's not super clear on what those tasks really mean. So you can message the bot to catch up on the meeting, get clarity on the meeting. That's kind of one use case in itself. So number one, great. Another use case is at a deaf meeting. We have a new project. \\n\\n33:34\\nAlejo\\nWe're talking about knowledge. Now we figure out the objectives of knowledge. Now we figure out the use case, right? So let's say it's this first use case. We figure out the success criteria, that it actually messages each person after the meeting. That it's clear on the tasks, that the tasks are actually what we talked about, that they're assigned to the right person. So we set up the success criteria and we figure out the step by step. This whole thing that we're doing now is going to be that step by step. So all that knowledge exists in the meeting. After the meeting, there's already a prototype being built. So that might look like a documentation writer. A documentation writer. It might look like a project manager, multi agent, anybody. It might look like actual programmers. \\n\\n34:39\\nBartek\\nLet's make digital twins. Of all the dev team partners of. \\n\\n34:45\\nAlejo\\nAll the dev team. Hey, I am good at this, but I want to learn rag. \\n\\n34:52\\nKuba\\nGreat. \\n\\n34:52\\nAlejo\\nNow you have a Bartech digital partner that is an expert at Rag and can help you build those projects while guiding you through it. Because code, in the very near future we won't even need to write. But systems design is something that we need to keep honing in on Cuba. The fact with a personalized outreach system, the fact that were able to throw you a picture of the system that we wanted, and you were able to write the code to put each agent and how it would work together, what tools each agent would need. That is freaking awesome, man. I believe that in the future. \\n\\n35:41\\nKuba\\nThat'S. \\n\\n35:42\\nAlejo\\nGoing to be a minor value added, which is huge value today, that the great value is going to be able to be in coming up with the system in the first place. So say we have a call and we come up with this system, and by the end of the meeting, there's already a prototype being built, there's already documentation written. The steps, the project manager figure out the steps because of the objective and the success criteria that we set up and the programmers are already working on it. Kuba, you wanted to add something? \\n\\n36:25\\nKuba\\nNo, what I'm thinking is we can actually build all this. All I was watching videos on cool AI, and it's very cool. It can enable us to do this. That was saying like the documentation writer, the projects manager, the programmer, then we have like a supervisor for all of them. Supervisor is the one that will be assigning the rules when a query comes in. So the supervisor understands that. Okay, this message belongs to the documentation writer. Okay, let's say agent. Then this rule belongs to the project manager. Agent. It's just like routing h query to the right. \\n\\n37:19\\nAlejo\\nSomething like perfect. Okay. Yes. And that exactly fits in with what Bartek was mentioning of. Hey, we need somebody to kind of moderate and manage the conversation. Could you text what that service thing that you were looking at is called? \\n\\n37:43\\nKuba\\nThe service Aws. Is that what I mean? \\n\\n37:50\\nAlejo\\nI'm not familiar. Could you write it? You were watching something that does this? Did I capture that? \\n\\n37:59\\nKuba\\nYeah, yeah, I was watching like a video. That's what I was saying. Like a video on YouTube. You know this guy Matthew Berman now? \\n\\n38:08\\nAlejo\\nNo. \\n\\n38:12\\nKuba\\nHe'S like an AI influencer. He did a video about it, about the framework. \\n\\n38:20\\nAlejo\\nOkay, cool. Could you post it in the chat and we'll definitely take a look? Yeah, thank you, man. Great. And having other frameworks that we can get inspired by is a great idea. It's not a great idea. It's necessary to figure out what others have worked on and how we can make it better for ourselves. Another one that we threw out there is a scrum master assistant, which you can kind of call a project manager. It's a type of project management, but earlier, and we mentioned it last week, at the beginning of faster eyes, we had this sort of scrum format, and then it was really hard to keep up with because there were a lot of people and there were very few people. It was mostly like Henry and I and most dev calls. So this kind of fell off. \\n\\n39:18\\nAlejo\\nBut if we can have this, and I wonder if this scrum master assistant mixes in with messaging you with your to Dos, you can ask the scrum master assistant for clarity on what your tasks are and the programmers on how to, and creating a draft for that task that then you can go and make better. So this all comes together really beautifully to work together as different components, different use cases working in harmony. So we're coming up with these use cases. Okay, what are the steps to get there? We know a few things. We know that before the answer happens, we need a good evaluation of the answer. How close is this to a full, accurate, relevant answer? Is this an agent? Is this a second moderator that can then kick it back to supervisor? \\n\\n40:36\\nAlejo\\nWe'll figure out how these components play together, but we definitely need an evaluation before we ever send any answer out. We're also talking about a supervisor agent. We can call it whatever we want. I'm going to put supervisor, moderator. Who is this supervisor moderating. What is that conversation that is being moderated and what information gets. We know the output, right? It's an evaluation. And the final answer, what is the input? Well, we have the knowledge base, and this knowledge base has information about all these things. We have real time Zoom call transcripts, close to real time. Every other transcript we have about who we are and what we do, knowing skills of each person and what each person wants to specialize in, like rag and knowledge of the project, et cetera. There's a bunch of things, clients, industry. \\n\\n41:43\\nBartek\\nFocus. \\n\\n41:46\\nAlejo\\nThat'S part of the input. We also have the initial prompt. Okay. And now that we know the prompt leads to the knowledge base in what exact capacity? When is the repropting? Let's figure that out together. So. \\n\\n42:11\\nBartek\\nI think the PFA swarm framework is pretty reusable in here. We can have the input like you write a prompt, you make a type or whatever. Later. We have like a context enrichment. So basically, just like PFA enhances your input, this can also enrich your input, and then it's kind of trying to get maybe using the fasterized knowledge base. Like, okay, see we are in fasterized right now. This guy asking me for this and this. Now I enrich this to be more relevant to pastorize the query itself. \\n\\n42:57\\nAlejo\\nYes, exactly. \\n\\n43:01\\nBartek\\nAnd then next thing we have is innovative angles. We not use that in here. Next thing I need to come back to the diagram. I already don't have it on my whiteboard. So first time I'm going to look at the actual photos of the whiteboard. So let's get back there. \\n\\n43:24\\nAlejo\\nWe are putting the output to be kind of enriched prompt. So I wonder if there's a knowledge base and then a base kind of system prompt about sort of very brief, like a paragraph about fasterize. Right. Because how do we make sure that if the prompt doesn't mention anything about AI, fasterize any projects, anything. This also has the context of what faster is. What is the global context? Maybe there's some component here of global context. \\n\\n44:12\\nBartek\\nI think we need to have two separate knowledge base calls, let's say. So you would have first, before the transcript knowledge base comes in, need to be the fasterized knowledge base. And actually the knowledge base from transcript will be after enrichment. \\n\\n44:34\\nAlejo\\nI think that's exactly what I was thinking. Okay. I love how this is coming together. So we go from prompt to global context knowledge base. \\n\\n44:49\\nBartek\\nActually, enrichment. Enrichment first, before you get to the global context, you need to fix the typos and enrich the input. \\n\\n44:58\\nAlejo\\nOkay, got you. I wonder if it's because you're already. \\n\\n45:02\\nBartek\\nQuerying the global context with this prompt that comes. \\n\\n45:07\\nAlejo\\nYeah. So. So we put vanilla PFA to fix the prompt without other context. Maybe like slight context in its system. Prompt, vanilla PFA. The whole point is enrich fix. \\n\\n45:28\\nBartek\\nActually the enrichment agent could be having the faster. \\n\\n45:33\\nAlejo\\nRight. \\n\\n45:33\\nBartek\\nKnowledge base in the enrichment agent knowledge. \\n\\n45:41\\nAlejo\\nOkay, question. When we're talking this component from the initial prompt, are we already talking multi agent? \\n\\n45:51\\nBartek\\nI guess. \\n\\n45:53\\nAlejo\\nOkay, we'll put a maybe in there. Maybe already multi agent wondering if we need to do the heavy lifting without even putting the global context in already. But that's minor. \\n\\n46:11\\nBartek\\nActually, it's even better when we have multi agent system from the start. And then this enrichment is an agent. An agent can have its own knowledge base and that could be the global context because actually I doubt thing now the enrichment without the context I don't think will be good enrichment. So the enrichment agent already needs to know the pasteurized thing. \\n\\n46:32\\nAlejo\\nWell, I mean, your fagpt without any context is pretty freaking good. Like excellent. Yeah. \\n\\n46:41\\nBartek\\nBut if it knows where we're going and from where we're coming from, actually the fasterized knowledge base. Okay. I think it will enrich even better. \\n\\n46:51\\nAlejo\\nOkay, so then would this step be redundant because we're going from prompt to add global context into PFA? It's not a rhetorical question. \\n\\n47:08\\nBartek\\nI think the global context has to. \\n\\n47:10\\nAlejo\\nBe. \\n\\n47:13\\nBartek\\nIn the context of context enrichment. The context enrichment agent has to have the context to enrich from. It's kind of like meta enrichment. \\n\\n47:26\\nAlejo\\nYeah, no, I'm with you. I'm with you on that one. Okay, so the PFA specifically, we're talking about the context enrichment agent with general knowledge of general context. General context. So that's my question here. And then we throw that into the global context knowledge base. \\n\\n47:52\\nBartek\\nNo, actually this global context gets merged into the first step as a knowledge base. So we don't have a separate call later in the air. We don't calling the knowledge base by itself. We're calling it through the context management agent. \\n\\n48:13\\nAlejo\\nOkay, something like this then. \\n\\n48:18\\nBartek\\nYeah, I guess we can have it like that. \\n\\n48:24\\nAlejo\\nAnd this is a draft. It has lots of room for improvement. But yeah, this makes sense. There's a simple not well written prompt. We have global context and PFA. The heavy lifting in this case is done by the context and reinstrument agent with the general context fixes and enriches the prompt. Maybe it's already multi agent, maybe it's one. Good. Well, it's PFA, so yes, multi agent. Great. Wonderful. \\n\\n48:57\\nBartek\\nNext step will be extractor agent. \\n\\n49:03\\nAlejo\\nIs that within this component? Because this component. \\n\\n49:07\\nBartek\\nNo, it's next step. \\n\\n49:09\\nAlejo\\nOkay. \\n\\n49:17\\nBartek\\nActually I'm looking at the diagram for the PFA swarm, but we're going to. \\n\\n49:21\\nAlejo\\nHave diagram next time. \\n\\n49:27\\nBartek\\nYeah, I don't know if you will be able to see that. \\n\\n49:34\\nAlejo\\nCool. I love learning. \\n\\n49:38\\nBartek\\nI don't know if you can read that. \\n\\n49:40\\nAlejo\\nI cannot. It's the context. \\n\\n49:44\\nBartek\\nAnd then maybe I'll just share with. \\n\\n49:46\\nAlejo\\nThe image later if we can get something kind of in the figma board. Maybe just throwing the word. \\n\\n49:56\\nBartek\\nMaybe I will draw this again because this is kind of mess in here. I had it on my whiteboard for a few days and I was just adding stuff on top. So I will redraw this from scratch. \\n\\n50:10\\nAlejo\\nAwesome. Yeah. Even just getting like a general idea of what the swarm is going to be like. Because we know what PFA is and we know what swarms are. \\n\\n50:20\\nBartek\\nRight. \\n\\n50:21\\nAlejo\\nWe get the general idea. Okay. So there is now an enriched prompt that comes from the initial prompt and the global context PFA creates that enriched prompt. What happens next? You mentioned a extractor agent. \\n\\n50:42\\nBartek\\nAn extractor agent has the transcript as a knowledge base. \\n\\n50:48\\nAlejo\\nHas transcript. So it has the full knowledge base. \\n\\n50:54\\nBartek\\nYeah. \\n\\n50:55\\nAlejo\\nOkay. \\n\\n50:57\\nBartek\\nSo we kind of shift the usual way of calling the knowledge base. We have like every agent has the knowledge base, right? I mean, maybe not every, but these two agents have a knowledge base and he would be extracting from his knowledge through the prompt that we enriched before. \\n\\n51:19\\nAlejo\\nSo this prompt gets passed as a rag query into the knowledge base. Is that what you're saying? \\n\\n51:28\\nBartek\\nIt's passed to the extractor agent. Then extractor agent gets to the rival. \\n\\n51:40\\nAlejo\\nOkay, I think I'm following now. So the extractor agent will intake the enriched prompt and make it a query adapted for rag. Optimized for rag. Yeah. Okay, cool. So the output of this is query optimized for rag, which as we know is not actually. \\n\\n52:11\\nBartek\\nWait, we have that already. This is the output of the first agent. Well, the query optimized, I think that's. \\n\\n52:22\\nAlejo\\nKind of a question because this prompt is going to be like, tell me about the real estate project. Then we add the global context into that. And then this enriched prompt, this outfocus, just on the output would have, tell me about the real estate project. This is kind of like what I'm interested about it. Be very explicit about the step by step, be clear about what the client wants. Takataka. Takataka. So the enriched prompt based on that global context, based on the initial prompt and the PFA extractor agent may or may not have to do multiple calls to get. \\n\\n53:30\\nBartek\\nThat's where we're going. \\n\\n53:32\\nAlejo\\nMultiple queries to the knowledge base in order to actually extract all the components that the enriched prompt is talking about. \\n\\n53:41\\nBartek\\nSo we're kind of going like, Gemini produces three outputs and lets you choose. \\n\\n53:47\\nAlejo\\nYeah. \\n\\n53:52\\nBartek\\nNext we have agent that chooses the best version of the output of those queries. \\n\\n54:01\\nAlejo\\nSo then with all that. So the PFA extractor agent is going to come up with multiple queries. Multiple queries optimized for rag. We call the knowledge base with each of those queries and the output of that. Man, this is fun. \\n\\n54:33\\nBartek\\nIt goes to the supervisor now. And then we have a feedback loop. \\n\\n54:37\\nAlejo\\nYou mentioned something different, which was, we need an evaluation of all that data, all the answers of the queries. And I just want to make sure that we're on the same page, that the supervisor will lead the free for all conversation where now agents are just talking with each other and the supervisor decides what is relevant for it. Yeah. Okay, cool. \\n\\n55:02\\nBartek\\nAll right. So now it's evaluator. \\n\\n55:04\\nAlejo\\nSo it's the evaluator agent which will evaluate the quality, relevance, et cetera, of all the outputs of each kind of sub query to the vector database. And the output is going to be output. Let's keep it simple for now. These are the most relevant. \\n\\n55:52\\nBartek\\nCan also add a scoring in there, like from one to ten. \\n\\n55:56\\nAlejo\\nYes, score one to ten and we can start with top three. So let's say that ten chunks are extracted for each query out of the vector database and we do top five out of those. Top ten. Based on what? Well, the input is going to be. Input is going to be the. \\n\\n56:29\\nBartek\\nEnriched prompt. \\n\\n56:31\\nAlejo\\nYeah. The global context. It's going to be all the queries each query. Let's call it sub query or rag query. Yeah, let's do that. Rag query. Each rag query and the global context. Maybe there's some other stuff in there, but that's good for now. \\n\\n56:58\\nBartek\\nI'm thinking if we should add transcript in this one or there should be like separate agent that is focusing on rereading the transcript to kind of check the evaluator or if the evaluator should also do that. But I think that will be too much job for evaluator. We also pass the transcript. We need to think about the context window here. \\n\\n57:22\\nAlejo\\nYeah, that's where it starts getting interesting and let's experiment. That's where I say, let's see how many tokens we can spend. And then when we get the best output, we can, we reduce, we simplify. Yeah. So, yes, to all your ideas, let's have a kind of, I'm not going to get too meta, but kind of an evaluator to the evaluator. So let's let the supervisor in now to say what is needed from here. \\n\\n58:04\\nBartek\\nMaybe we can also add like transcript. I'm thinking like kind of code review to the evaluator, but it's a transcript review. So transcript review agent. \\n\\n58:22\\nAlejo\\nSo this is kind of a tester. \\n\\n58:26\\nBartek\\nYeah, it brings back the whole transcript and slashes that with the evaluator output. \\n\\n58:36\\nAlejo\\nYeah. \\n\\n58:37\\nBartek\\nAnd kind of make a semantic check on the evaluator. \\n\\n58:46\\nAlejo\\nKind of semantic quality check on the evaluator. Cool. So as we are testing the system, this will definitely be necessary because what if the evaluator is the one that's wrong? \\n\\n59:01\\nBartek\\nRight? \\n\\n59:02\\nAlejo\\nWhat if the evaluator is the one that. So part of the input that this transcript reviewer is going to need is kind of its own examples. Here's the whole transcript, here's the query, here are the relevant chunks and we can kind of give its own few shot prompting. I'm not going to call it knowledge base right now because we have way too many knowledge bases to keep track. \\n\\n59:35\\nBartek\\nOf, but few shot prompt. Yeah, but that's good. I mean like every agent should have a knowledge base and every knowledge base should be different. \\n\\n59:43\\nAlejo\\nYes, I agree with you. Let's keep Fusot prompt for now and. \\n\\n59:49\\nBartek\\nWe can go from there. \\n\\n59:50\\nAlejo\\nFusion prompt of query plus transcript plus relevant chunks plus score from one to ten. So tester of QA agent transcript. There you go, QA agent, which we'll do like a check on the evaluator agent. Okay, I'm going to pause now because I want to be considerate to all the other human being in this conversation because I feel like we're robots right now. Kuba, what clarity, what questions. Maybe everything's clear, but I know sometimes. \\n\\n01:01:04\\nKuba\\nI go often, to be honest, I enjoyed the conversation. I like the way you guys think. This is like a new picture to the entire system. So I understand. I just need to go over the stigma body again to understand it. \\n\\n01:01:24\\nAlejo\\nWell, cool. Awesome. Well, if you have any questions, there's the chat, whatever comes to mind, ideas, feel free to pitch in. Okay. \\n\\n01:01:39\\nBartek\\nRefinement loops, definitely in the evaluator to. \\n\\n01:01:43\\nAlejo\\nThe extractor, my mind. So before you go into that, Kuba, you asked me the other day, what's the thought process for these icebreakers for the personalized outreach system? And I mentioned this reinforcement learning with human feedback, or at least trying to emulate that self refinement getting better over time. And this very much we want to go in that direction with this. So that's where the QA agents might come in too, right? How do we make sure that this system gets refined over time, that it doesn't hit a ceiling. \\n\\n01:02:27\\nBartek\\nOr at least. \\n\\n01:02:28\\nAlejo\\nDelay the ceiling as long as possible? So you're talking self refinement, which sounds like a branch from the QA agent, may or may not. \\n\\n01:02:45\\nBartek\\nThe evaluator agent, an evaluator agent into the extractor agent. And also I'm thinking like this is refinement on the process one time. But I'm thinking we could also have agents that if the refinement happens, so the initial output was somewhat wrong because maybe not always could be wrong, maybe sometimes it will just go fine. \\n\\n01:03:09\\nAlejo\\nRight? \\n\\n01:03:09\\nBartek\\nAnd the evaluator has nothing to say. QA agent has nothing to say. But if they have something to say, we should save that and have agent that keeps track of the refinements that happened and use that as later maybe knowledge base. Oh fuck yeah, dude, let's go. \\n\\n01:03:29\\nAlejo\\nOkay, that sounds like we're wondering like hey, where does the supervisor get into the conversation you just mentioned? Sometimes there might be like space for the self refinement agent, for the Q agent, and we might need to go back or reroute the conversation. So now we know a point where we want a supervisor to say hey, who's next? And it will have obviously knowledge of each agent, what they do, maybe a summary of their system QA. \\n\\n01:04:11\\nBartek\\nThe QA agent needs to also report the supervisor agent like the evaluator agent do. And then supervisor makes the refinement loop. \\n\\n01:04:23\\nAlejo\\nAnd now the supervisor. And now we start routing. Okay, we run out of figma board. We have the evaluator agent, then the QA agent. \\n\\n01:04:46\\nBartek\\nSo we can go either to the evaluation or to the extraction from supervisor. \\n\\n01:04:52\\nAlejo\\nNow. So we have PFA extractor which creates multiple queries optimized for rag. Then we have the knowledge which goes to parts of extraction from the knowledge base. We have the evaluation of that answer. What are the most relevant chunks then QA agent. We haven't defined yet what we do with these chunks. Trying to answer the prompt, right? So if we don't forget about what the user is asking, we're trying to answer the prompt. We now have the most relevant chunks to answer the prompt. At least we think we do. We pass it through the QA agent and we confirm yes, we have the most relevant chunks. Are we ready to answer the query? No. What is missing? \\n\\n01:05:57\\nBartek\\nSo we need like aggregator agent that, wait, aggregator agent or something else. We just need to now get these things that come out of the evaluator or QA agent. \\n\\n01:06:17\\nAlejo\\nAnd have a path. \\n\\n01:06:18\\nBartek\\nDownwards I guess to the, something should happen before the answer is now. And now we have evaluator that has scored the outputs and now those best scored we need like a merger agent. \\n\\n01:06:36\\nAlejo\\nI think that will take the go ahead. \\n\\n01:06:40\\nBartek\\nThe merger agent could take the best scoring from the evaluator, best scoring answers and then analyze them. Let's say there is the best chunk, but in the second best and the third best chunk there is also some stuff that is not in the first chunk. You get me? So the manager agent take the best pieces out of the say three most scored chunks and takes the best pieces into the answer. \\n\\n01:07:18\\nAlejo\\nYes. So take the best chunks from evaluator agent and create a full answer for each rag query, basically submerging the best. \\n\\n01:07:28\\nBartek\\nPieces now merging the best pieces. It's good now. No, it was good. You just add it at the, yeah, you take the best chunks and then for each rack query you merge the best pieces from those chunks. \\n\\n01:07:48\\nAlejo\\nBest pieces from each chunk. We will work on the wording later because we are following. Okay. The merger agent takes the best chunks from the evaluator agent and creates a full answer for each rag query by merging the best pieces from each chunk. Okay. And merge the best pieces from each chunk to create a full answer for each rack query. Yes. Awesome. We're going to put the self refinement agent somewhere around here and we're going to start creating the routing function, essentially, which is most likely literally a function call with the input being which agent is next, if that makes sense. Kind of like the tool is function calling for routing to most relevant next agent. To continue the conversation. Okay. \\n\\n01:09:16\\nBartek\\nI think that the supervisor is actually making those loops back to where it was the mistake, but the self refinement agent, it's more of like, I would say it's like a self refinement bookkeeper. So the one that keeps track of the refinements that happened and puts them in a knowledge base so we can have, this is where the self learning happens. Self learning knowledge base is happening right here. \\n\\n01:09:48\\nAlejo\\nOkay. So a supervisor could fulfill that role, technically could fulfill that role because he is keeping track of everything. He is tasked with being like the bright mind that can put all the pieces together and know who to call and kind of know what's missing. At the same time, the supervisor only knows what it knows. It's not necessarily there to judge what it was given. It's tasked with, take what it's given and run with it. It's like what's next, not what could have been better. So the supervisor says, hey, maybe there was room for improvement here. That's when the self refinement agent might create a kind of full evaluation of everything up till now and kind of find the blind spots which agent it was where the process went astray went wrong. \\n\\n01:11:15\\nBartek\\nYeah. Now this agent will have a kind of bookkeeper agent that's kind of working after the self refinement happens, it gets noted to the bookkeeper agent, which then keeps track of all the refinements that happen. \\n\\n01:11:32\\nAlejo\\nSo then we would function more than another agent. It's like it could call the function of bookkeeping. \\n\\n01:11:42\\nBartek\\nOh, yeah. If refinement happens, then call the function to save the refinement process that happened. \\n\\n01:11:50\\nAlejo\\nIf refinement happens, keep a log of full combo into what was wrong, evaluation of what was wrong, into improvements suggested, and at the very least, for now, let's not let the conversation just loop back. Let's just keep a log and that's going to be great. Training data to know what might need refinement as opposed to creating a crazy loop of agents that might end up no one knowing where to go next or like a feedback loop of bad data. So bookkeeping function, great. \\n\\n01:12:53\\nBartek\\nI think that supervisor role is to know what to do next from there. \\n\\n01:12:59\\nAlejo\\nActually, yeah, that's the function routing to most relevant next agent. Yeah, you mean from the self refinement agent? \\n\\n01:13:09\\nBartek\\nYeah. So the self refinement make decision what to refine and then supervisor makes a loop to that agent that needs to be refined. Okay. \\n\\n01:13:21\\nAlejo\\nThrough all this we have to figure out, you talked about low hanging fruits, we have to figure out what's like. \\n\\n01:13:27\\nBartek\\nPriority because that's the big picture now. \\n\\n01:13:32\\nAlejo\\nAnd this is great, you guys, this is truly going to be the future. Okay, so we know, let's assume that no refinement is needed. What we do know that we need is now a merger agent to take the best chunks from evaluator and merge the best species from each chunk to create a full answer for each rag query. Now that we have a full answer for those sub queries, we need to actually answer the prompt answer formatting agent. Okay, this is where if you talk. \\n\\n01:14:23\\nBartek\\nIn one prompt, this is the output format. \\n\\n01:14:27\\nAlejo\\nYes. \\n\\n01:14:28\\nBartek\\nAnd then from the merge chunks from the merger agent, it will have a structured output. \\n\\n01:14:39\\nAlejo\\nI see your mic going on Kuba, if you want to jump in, feel free. Okay, so we have answer formatting agent, but we're running out of figma space. Again, this is great. Okay, so what happens before the final evaluation of the answer? Well, there's answer formatting agent and in between evaluating the answer and deciding how the answer is going to be formatted, there's answer agent. So somebody that actually creates the final answer. \\n\\n01:15:32\\nBartek\\nI found blind spot in all of this because the final answer is bot messages you with to do we need a knowledge base with the competency metrics or something like that? Like at least information about who is in the team. \\n\\n01:15:49\\nAlejo\\nAt very least that's part of it. Knowing skills of each person and what they want to specialize in matrix. Good catch, man. \\n\\n01:16:01\\nBartek\\nBut yeah, I think that it should be at the end rather than in here. \\n\\n01:16:07\\nAlejo\\nSo for each different use case, this is something great, this is a great point you're bringing in. It's like, hey, what's the actual use case? But this is not the answer agent. This is the formatting agent. What's the actual use case. What other info might be needed? But then is this, what other info might be needed? The answer formatting or the supervisor. \\n\\n01:16:49\\nBartek\\nOr sort of like team manager agent that we are getting the answer, but now we need to actually choose who going to do what from this answer we got. \\n\\n01:17:06\\nAlejo\\nOkay. So we could subdivide this supervisor into other sub agents, like an HR agent. \\n\\n01:17:15\\nBartek\\nOr team lead agent. \\n\\n01:17:20\\nAlejo\\nYeah. It would feel slightly redundant to this supervisor because they can have that ability. Yeah. \\n\\n01:17:32\\nBartek\\nI'm just thinking if it wouldn't be too much for one agent, but let's talk MVP and maybe it will work. \\n\\n01:17:38\\nAlejo\\nOkay. Yeah, it's 02:20 a.m. For me already. But we're in a roll. We're in a roll. And then decide which agent comes next. Right off the bat is keeping track of the conversation, identify what info might be needed and then decide which agent comes next. Doesn't feel like too much. There's going to be other things that we add on top. \\n\\n01:18:08\\nBartek\\nAlso assign team members. \\n\\n01:18:10\\nAlejo\\nAssign team members. So what's the actual use case? For example, E. G, for the to do task use case, we would need to check relevant skills. Assign team members. We would need to. What else? \\n\\n01:18:43\\nBartek\\nDecompose tasks. \\n\\n01:18:46\\nAlejo\\nDecompose tasks? Yes, decompose projects into components. Into tasks. \\n\\n01:19:02\\nBartek\\nAssign deadlines. \\n\\n01:19:05\\nAlejo\\nAssign deadlines. Which ideally we're saying out loud during the call. \\n\\n01:19:16\\nBartek\\nIt'S like deadline for the whole project. Right. We talk on the call, but there is another deadline for the tasks and for the components, right? \\n\\n01:19:27\\nAlejo\\nYes. We then have to figure out over time how much autonomy do we want to give it, even if the output is perfect, the nuances of humans and hey, I'm actually quite swamped this week and I'm only now learning rag. So how big of a deadline, how long of a deadline or how big of a task can I really take on? Let's keep that human for now. And the scrum assistant can help with the evaluation, sort of the analysis, evaluation of all of that. \\n\\n01:20:18\\nBartek\\nYeah. We could also have at some point availability checker, something like that. So checks tasks already assigned to the person. \\n\\n01:20:33\\nAlejo\\nYeah. So like, checks tasks already assigned. So we need project manager management tool to keep track of this, which is likely going to be notion. So we're actually already migrating a lot of stuff to notion and we can then automate the project manager within notion. Check tasks already assigned, deliverables missed and delivered, missed. And it can help sort of adapt like, oh, well, maybe this person is overloaded right now and kind of like checks capacity and then assigns. \\n\\n01:21:29\\nBartek\\nThis is already fault three we're talking. But that could also be like contribution calculator or whatever. \\n\\n01:21:41\\nAlejo\\nYeah, contribution calculator. And I actually found a great template to do that. It's an airtable template where you can create a project and then keep progress logging. Yes, absolutely. And maybe even that can be filled automatically during the call live. That'd be cool. Kind of like project automated auto project logging, progress logging. \\n\\n01:22:32\\nBartek\\nOkay, and after that we have like a UI thing going on. After the answer we are stepping out of this agent. Now we have UI, so either yes or no. For V one, for example, you get the to do list from this and then you have option to say like. \\n\\n01:22:52\\nAlejo\\nYes or no, yes or no, like. \\n\\n01:22:57\\nBartek\\nIf you take the task or you don't take the task because you get assigned to something. AI already checked. You can do this, but now it's human decision if you want to do see? \\n\\n01:23:09\\nAlejo\\nI see, yep. \\n\\n01:23:17\\nBartek\\nNow we're getting to the human, to. \\n\\n01:23:19\\nAlejo\\nThe UI confirm task. \\n\\n01:23:23\\nBartek\\nI think that should be like separate card because we are stepping out of this is not AI anymore. We are going to the UI, to the human. So that should be like another card. \\n\\n01:23:37\\nAlejo\\nI think so. These are use cases. Each of these subcomponents may or may not contain AI. I want to just make sure that we're not now dividing the use cases into what we'll need, just so we can refer back to these and look at the whole use case as a whole. It's going to be very important to be very clear and almost like simplify use cases so we know what the success criteria is of each use case. Yes. Now knowledgenow completes this to do task successfully and we don't have such large variations of branches of the use case itself. So I'm putting here confirm task assignment. We'll figure out how that works and where that fits in. \\n\\n01:24:37\\nBartek\\nRight. So. \\n\\n01:24:42\\nAlejo\\nLet'S look at it backwards so we get the final answer. Hey, these are your to dos based on the project, based on the deliveries that you have, the capacity that you have. This is what has been assigned to you. Do you accept these? Which ones do you accept or do you want to review this? Yes, I accept. Contribution calculator comes later. You can message bot to catch up on meetings and get clarity on assignments. Which was the first low hanging fruit that we identified even as a subcomponent of this. We asked about this, right? What are the low hanging fruits? \\n\\n01:25:33\\nBartek\\nOkay, I think what we should do now because we have this high level thing and now we should maybe go backwards like you say, and mark the things that are required for the minimal version. \\n\\n01:25:45\\nAlejo\\nYeah. \\n\\n01:25:48\\nBartek\\nLet's have this green sticker. Where is things required? \\n\\n01:25:54\\nAlejo\\nOkay, cool. So we know that the actual output is required and we'll just tag like MVP. That's a little too small. MVP. Bam. Evaluation. We're going to be doing manual evaluation. \\n\\n01:26:17\\nBartek\\nYeah, I think all evaluations can go to the V two. \\n\\n01:26:21\\nAlejo\\nYeah. Answer. Obviously we need answer. It feels like depending on the use case. Well, we're going to start with one use case. So the format is already going to be set. Maybe we don't need an agent to come up with a format to give summaries of meetings that is already set. Then we have merger agent. \\n\\n01:26:50\\nBartek\\nWe are doing agent comes from evaluation. \\n\\n01:26:54\\nAlejo\\nSo no supervisor, I think supervisor. Yeah. We ended up not having any branches. This is all sequential. The only branch is the self refinement agents, which is probably not the MVP. \\n\\n01:27:19\\nBartek\\nSo. \\n\\n01:27:23\\nAlejo\\nI'm sure that a free for all conversation is going to be important, especially for coding tasks. So does this task require multiple agents having an open conversation. \\n\\n01:27:48\\nBartek\\nFor example. But we are talking like a board of the company. Like this is the board. And then later, if we have some tasks like coding and stuff, we would have another kind of system or swarm. That is the worker agents. Yeah, I don't think the programmers are in this diagram. This should be like another diagram of the worker agents because this is high level. Like a board. Like a seaboard. This thing we just built is like a seaboard. \\n\\n01:28:22\\nAlejo\\nSo kind of like, well, I'm just leaving at programming team. So programmer, tester, whatever, which for coding tasks we would need to route to here. You've definitely been watching the has framework. When you throw out the word. This is the board. The supreme oversight board. Yeah, no, it's a great concept. It's a very well developed concept. So yes, supervisor, moderator board. So these in itself could be a multi agent system because alignment, again, is probably the hardest problem in all of AI. So is this really a single agent question for not the MVP? Okay, we have the evaluator agent, which grabs the relevant chunks for each query. So we need an agent to grab those relevant chunks to grab chunks, period. So that's the extractor. \\n\\n01:29:33\\nAlejo\\nSo we need an extractor which will break down a prompt into break down prompt into multiple queries optimized for rag. I think we have something in our hands with you guys. And then, well, the knowledge base will need it, which is not trivial. And then finally we need context enrichment. So we need global context and this is human input. \\n\\n01:30:15\\nKuba\\nGuys, I have to bounce. \\n\\n01:30:17\\nAlejo\\nOkay, we're pretty much done, so thank you for sticking through it. Kuba, great to have you here. \\n\\n01:30:28\\nKuba\\nThe prompt engineering resources that I told you about. \\n\\n01:30:33\\nAlejo\\nYes, thank you for reminding me. Bartek. Kuba asked about some prompt engineering resources to sort of keep learning, keep getting better. I think it'll be good for all of us to sharpen our prompt engineering skills. Would you share some intermediate into advanced resources with Kuba? \\n\\n01:31:00\\nBartek\\nI already shared at some point the documentations. \\n\\n01:31:04\\nAlejo\\nDocumentation. Right, right. \\n\\n01:31:06\\nBartek\\nAnd the OpenAI guide. That's the thing for me. This is very beginner stuff. So if you talk intermediate, I would recommend reading markdown syntax and getting familiar with all the markdown things can. All the things markdown can do. Because that's actually how before going to latent space, because I'm referring to how I upgraded PFA because field version of PFA is already the documentation level stuff. But then the next version, like the PFA overseer was about, I was reading the markdown syntax and I was thinking, okay, I have this markdown syntax. I know Markdown is using the prompts. How do I use all those things markdown have? Because Markdown have quite a lot of things you can do with Markdown. So getting familiar with Markdown, I would recommend. Definitely. And then later I would recommend for more advanced stuff. \\n\\n01:32:02\\nBartek\\nGetting familiar with the latent space activation. \\n\\n01:32:05\\nAlejo\\nOkay, cool. Like sparse representation and all that stuff. \\n\\n01:32:14\\nBartek\\nYeah. Also there is actually the latent space activation function written by David Shapiro, so that you can also find it on his GitHub. Also on my GitHub, you can find it's still not finished, but I've been doing a Vicky for PFA. And in this Vicky, I have a little bit like two kind of little articles about latent space activation from my point of view and from point of view on property engineering. So how to use latent space in writing? Persona for the AI for the sale. You make an agent and you want a Persona, and you want this Persona to be with the latent space activation included. So you can read about this at my GitHub. \\n\\n01:33:02\\nAlejo\\nOkay, I will share the latent space activation video with. \\n\\n01:33:12\\nBartek\\nShapiro. Okay, cool. \\n\\n01:33:14\\nAlejo\\nSo, Kuba, I'm sending you two resources to start, and let's evaluate from there, if you need, where you feel like you want to go from there, if more into the very specific and advanced Personas, et cetera. \\n\\n01:33:33\\nKuba\\nAll right, thank you, guys. Thank you, Batik. \\n\\n01:33:37\\nAlejo\\nYeah, I'll see you soon, and we'll talk about the personalized outreach system. I went in a bit of a rabbit hole of evaluating which LLM is best at refactoring a whole big project into a proper repo that we can actually maintain. So all these different files and all that stuff. But I will add that to you by tomorrow. \\n\\n01:34:05\\nKuba\\nAll right, no problem going with your stuff. \\n\\n01:34:08\\nAlejo\\nI'll send you some more documents and we can with a bigger knowledge base. \\n\\n01:34:13\\nKuba\\nAll right, guys. \\n\\n01:34:15\\nBartek\\nGood job, brother. Yeah. \\n\\n01:34:21\\nAlejo\\nPrompt engineer. \\n\\n01:34:22\\nBartek\\nAll right, so we've got like 1234 agents for the MVP. \\n\\n01:34:34\\nAlejo\\nWe have to figure out the use case. There's the answer. Agent one, evaluator, extractor four. \\n\\n01:34:46\\nBartek\\nAll right, but the problem is that the first agent is a swarm itself. \\n\\n01:34:54\\nAlejo\\nSure. It need not be. Remember, you have built an amazing product just by itself, and we're going to make it even better. Dude. \\n\\n01:35:11\\nBartek\\nI'm striving to make it like, don't make a mistake, because now, because of the randomness, you cannot control in the GPT because you cannot even set the temperature. I'm not even talking about the other parameters, but you cannot even set the temperature. So that's why it's so random. And that's why sometimes the prompt is just like one line. I hate it. \\n\\n01:35:35\\nAlejo\\nSo this is what I'm going to need from you. I need you to pat yourself on the back for creating an amazing product that we are going to put in a whole different category of amazing once it's multiagent. And right now, we really need to focus on creating the bigger product because again, that's one amazing, but just one component of the whole system. And I am absolutely sure that through these testings, through these. Hey, now create, break down this enriched prompt into multiple queries optimized for rag. You're going to find new things to make better, not from this 8000 character prompt, but how to actually make it into these multiple agents. And then we'll step into that. \\n\\n01:36:38\\nAlejo\\nSo let's give it a little bit more freedom by taking it out of the chat OpenAI context window and limitations and putting it into a new environment where it can be a little more free and we'll see what it does. \\n\\n01:36:59\\nBartek\\nYeah, actually, I already drafted the prompts for, like, context agent. There is like, wait, there's context agent. There is the PM agent. Like a Pmidation agent. \\n\\n01:37:13\\nAlejo\\nI'm going to write this down. \\n\\n01:37:14\\nBartek\\nThis is the context. \\n\\n01:37:15\\nAlejo\\nContext agent. \\n\\n01:37:18\\nBartek\\nThen there is the pmidiation agent. Iteration, iteration, like ideation. \\n\\n01:37:28\\nAlejo\\nAnd then there is ideation agent. \\n\\n01:37:31\\nBartek\\nYeah. And this ideation agent is like technic choice, fusion structure and latent space activation. \\n\\n01:37:42\\nAlejo\\nFusion, latent space and what else? \\n\\n01:37:46\\nBartek\\nTechnic choice. Like a prompt. Technic choice. \\n\\n01:37:51\\nAlejo\\nOh yeah. Fuck yeah. I love that. So it'll know if it'll go like tree of thoughts or chain of reasoning. That's cool, man. \\n\\n01:38:01\\nBartek\\nThat's such a good idea. \\n\\n01:38:03\\nAlejo\\nI love that. I've had that in my brain for so long. I love that. Okay, awesome. \\n\\n01:38:11\\nBartek\\nAnd it's been on my whiteboard for quite a long time. \\n\\n01:38:15\\nAlejo\\nThat's cool. \\n\\n01:38:17\\nBartek\\nAnd then later is the generation agent. \\n\\n01:38:20\\nAlejo\\nThe what? Generation. \\n\\n01:38:22\\nBartek\\nGeneration agent. The actual generation of the prompt. \\n\\n01:38:25\\nAlejo\\nOkay. \\n\\n01:38:26\\nBartek\\nAnd that's where I'm at currently. But the ideation PM agent is still work in progress. So I finished the context and I finished the generation because that was basically had before. I just had to take that out to the one, to the separate prompt. So that's why in my vs code is the current state of the PFA swarm. Later on there will be obviously after generation there is evaluation and there the iterator. \\n\\n01:38:55\\nAlejo\\nOkay. And what we need to do progress. And what we need to do is knowledge. Now wait, Tor, remember this, we are checking which agents we've yet to build. And these are going to be the tests of this whole system. \\n\\n01:39:16\\nBartek\\nRight. \\n\\n01:39:16\\nAlejo\\nSo we're calling knowledge now. I love this. Okay. Evaluator agent. \\n\\n01:39:23\\nBartek\\nYes. And then iterator agent. \\n\\n01:39:25\\nAlejo\\nIterator agent. \\n\\n01:39:28\\nBartek\\nThen I have still cloudy talk. \\n\\n01:39:33\\nAlejo\\nExtractor agent, or we've yet to build. We need to break down a prompt into multiple queries optimized for rag. \\n\\n01:39:41\\nBartek\\nYeah. So that's also to do. \\n\\n01:39:44\\nAlejo\\nOkay. \\n\\n01:39:45\\nBartek\\nExtractorate, because that's not part of the PFA swarm itself, it's just part of the knowledge. \\n\\n01:39:50\\nAlejo\\nRight, right, exactly. Okay. \\n\\n01:39:57\\nBartek\\nAnd then also I got an idea. This is like a very raw idea. Like after the iterator, if you can see that after the iterator, there is prompt levels. Upgrade, swarm. I'm thinking like upgrading of the prompt will be another swarm upgrade. I still don't have that laid out completely because for V One there will be the iterator agent doing the upgrades. But what I'm thinking later, after iterator make a fish upgrade, we can have levels of upgrades like level one, upgrade Markdown, level two, upgrade complexity. Level three, upgrade latent space activation. \\n\\n01:40:44\\nAlejo\\nSo that is what I would love us to have as a testing framework of the PFA system. Like talking about that. We can integrate here, of course, but as a whole different system, these multi agents. And have the testers be kind of like what you showed in promptful, but on steroids, of course, evaluation and leveling up. So is that what we're doing for MVP? \\n\\n01:41:23\\nBartek\\nNo, that's for like, that's poultry or something. \\n\\n01:41:26\\nAlejo\\nOkay, so I'm then going to put this in green and it's MVP. Yeah. Okay. \\n\\n01:41:37\\nBartek\\nAnd then we will have like a testing upgrades form for later testing. \\n\\n01:41:46\\nAlejo\\nUpgradeswarm. And that's going to be V two. Okay. No, the other way around. V two is going to be testing an upgrade swarm with levels E. G. One, markdown two. What would level two be? \\n\\n01:42:15\\nBartek\\nComplexity or like details. \\n\\n01:42:18\\nAlejo\\nDetails. Three, accurate context capture. Okay. Anyway. Oh yeah. Actually run on the environment. Actually run the code and we'll figure this one out later. This is not V one, the programming team. \\n\\n01:42:49\\nBartek\\nSo. \\n\\n01:42:52\\nAlejo\\nInput we have. So what do we need to do? We need to do the for agents. This is what we need to do. And then for other stuff we need global context. We need knowledge base. \\n\\n01:43:20\\nBartek\\nNo, I got to beard back 1 minute. \\n\\n01:43:23\\nAlejo\\nYeah, we need answer agent. And I'm glad we budgeted $800 for fast rice. This is going to get fun. Make a message bot to catch up on meetings, declaring assignments. It discord. Discord. Right. Amak. \\n\\n01:44:48\\nBartek\\nLet'S sum up what prompts we need for those agents. So prepare those prompts for the MVP of the knowledge now. \\n\\n01:45:07\\nAlejo\\nOne sec. And then answer agent. And then for other stuff is the global context, the actual knowledge base which I'm working on. And then the discord bot web. Love it. This is looking so nice. Prompts. \\n\\n01:45:43\\nBartek\\nWe have four agents. The context enrichment is like 90 or 80% done because I had it done for PFA. So I would just tweak it a little bit for the knowledge now. So it's enriching in the transcript case rather than prompting case. \\n\\n01:46:03\\nAlejo\\nYeah. \\n\\n01:46:05\\nBartek\\nLater we have the query agent, direct query agent. \\n\\n01:46:18\\nAlejo\\nWhich is the rag extractor. \\n\\n01:46:22\\nBartek\\nYeah. \\n\\n01:46:25\\nAlejo\\nAha. \\n\\n01:46:30\\nBartek\\nThen we have evaluation in V one. \\n\\n01:46:36\\nAlejo\\nThe evaluator agent that will actually. So the rag query extractor agent. The rag query agent will create the queries from the prompt. And then the evaluator agent will say, these are the best chunks from that. Extract from that cosine, similar. \\n\\n01:47:02\\nBartek\\nBut the iterator agent is for. \\n\\n01:47:06\\nAlejo\\nOh, you mentioned for V one that would be V two. Yeah. \\n\\n01:47:12\\nBartek\\nBut now I'm talking about the knowledge now. So yeah, for the PFA there is an iteration agent. \\n\\n01:47:19\\nAlejo\\nRight. \\n\\n01:47:19\\nBartek\\nBut I'm talking about knowledge now because I'm thinking about the prompts needed for the knowledgenow system. \\n\\n01:47:25\\nAlejo\\nI'm talking about knowledge now too. But you had mentioned an iterator. \\n\\n01:47:30\\nBartek\\nOh, it's for. \\n\\n01:47:36\\nAlejo\\nPFA swarm. So that would be an iterator. \\n\\n01:47:44\\nBartek\\nJust I thought like, both of these green cards are for the PFA swarm, right? \\n\\n01:47:51\\nAlejo\\nWell, technically, yes, they are, but this is also for knowledge now. So I'm going to put different colors and we're going to call this V two for V two. This is what we're focusing on now. And the other stuff we're focusing on after we have the MVP, not that we can't keep thinking about it, but in terms of output. \\n\\n01:48:26\\nBartek\\nRight. So the progress part is actually for the PFS world. \\n\\n01:48:32\\nAlejo\\nGotcha. Gotcha. Great. So progress, bam, we put here. Great. Thank you for clarifying. And are any of these agents relevant to our MVP, which would be the context agent. Context enrichment agent, which is at 80%. Yeah. \\n\\n01:49:07\\nBartek\\nBecause for the PFA swarm, it's finished. It's just that I will have to make a little different vanishing for the knowledge now. So be more relevant to. \\n\\n01:49:24\\nAlejo\\nEvaluator, iterator agent was the other one. That was not that. Then evaluator agent, rag extractor agent, query builder agent, and then we have the answer agent. And then for other stuff that we need to have build is the global context, which is sort of a short system, prompt kind of style knowledge base. All of our transcripts. All of our transcripts or detailed summaries of our transcripts. It would probably be the full transcripts. \\n\\n01:50:09\\nBartek\\nOr the cleaned transcript. Clean from those weird words. \\n\\n01:50:13\\nAlejo\\nYes, cleaned transcript. And I think we are going, I have that code. \\n\\n01:50:24\\nBartek\\nI think we should be going like one transcript per one use of the knowledge now. Because if you throw all of the transcript in the one knowledge base, I'm not sure how that's going to go. I mean, you want to extract from one meeting, right? You don't want to extract from every meeting at once. \\n\\n01:50:43\\nAlejo\\nThe whole point is that there is continuity from meeting to meeting. \\n\\n01:50:50\\nBartek\\nYeah, but at one, say, run of the knowledge, now you're extracting from one particular meeting. \\n\\n01:50:57\\nAlejo\\nRight. \\n\\n01:50:58\\nBartek\\nThe all meetings is like a global context, like infrastructure, knowledge base, something like that. In my variant there is the run. It's on a one transcript, and then we have output of that and that should be saved into the all transcript knowledge base. Not the transcript itself, but the result of the knowledge. Now doing the work, analyzing transcript, and then have like summary or something like that. \\n\\n01:51:41\\nAlejo\\nOkay. I'm not 100% sure. What is the difference. We'll be testing this most likely with a few transcripts and see what it pulls. Because there is relevant information for the same question in different days, different meetings. Right. System or knowledge. Now we will limit it because it's a good point that you're bringing like are you really going to put like 100 hours of context of transcript just to grab from a knowledge base? That would be pretty messy and confusing for the rag. \\n\\n01:52:34\\nBartek\\nSo. \\n\\n01:52:38\\nAlejo\\nBut that is part of why we have the evaluator agent, because it's like, hey, based on the enriched prompt, the rag queries, this chunk that you withdrew, we're talking about AI agents. We're not talking about real estate agents. So this is irrelevant or the other way around. We're talking about a real estate solution. So AI agents doesn't make sense. So the evaluator would figure that out. Good question. Let's test it. Let's get the MVP. Let's test it. We'll figure out what we change and also obviously how we manage our knowledge base, which is going to be garbage in, garbage out. The quality of the data, the underlying data has to be high and we'll do our best to have a solid data quality standard for our MVP and we'll make it better over time. \\n\\n01:53:34\\nBartek\\nAnd you see that we are making, let's see, the call ends. The transcripts get rendered automatically or you have to do that yourself. \\n\\n01:53:47\\nAlejo\\nWe will be able to render them. \\n\\n01:53:51\\nBartek\\nAutomatically and then also we should automatically have them cleaned. \\n\\n01:53:56\\nAlejo\\nYes, correct. \\n\\n01:53:57\\nBartek\\nAnd the question is now if we also want them automatically to be pushed into the knowledge now. \\n\\n01:54:07\\nAlejo\\nThat is definitely a pending question because what? Oh, that's what the global context is. Oh my God. Global context is. This is what the dev team does, has worked on, is working on. This is the marketing team. This is who composes the marketing team. The upcoming strategy does say videos published, et cetera, et cetera. And that's the global context that, based on what the original query and the enriched query is, will have certain relevance. So we can create what makes sense to me as a gated access of information to guide. I don't know if that's what you meant by global or global meaning every single component, every single transcript is there. But we'll figure that out at the start. \\n\\n01:55:30\\nAlejo\\nIf we want to enrich a prompt, let's give it some context and then we can dig into all the details and the transcripts and all that stuff. \\n\\n01:55:40\\nBartek\\nYeah, I think it also depends on the use case. I feel like some use cases could be done automatically. Like we automatically render the transcript, automatically clean the transcript and let's say for the to do we also automatically run it through the knowledge now. But I guess some use cases will be like run manually and some use cases will be run automatically. \\n\\n01:56:01\\nAlejo\\nYeah. So I'm going to write dockup considerations, auto run or human check or fully manual, e. G. Modifying the dev team global context document. Because when a new project comes in and we have a new project we're working on a new project, the dev team global context document needs to be updated, but we want to do a human check. \\n\\n01:56:52\\nBartek\\nThat's like. \\n\\n01:56:53\\nAlejo\\nYes, that's how you should update it. Dev team deserves human check. Okay, cool. Okay. You threw out other considerations there. What was it. \\n\\n01:57:15\\nBartek\\nI was just saying before about the automation of rendering and cleaning? So I guess that happens automatically all the time. And then we only have differentiation for. \\n\\n01:57:28\\nAlejo\\nThe use case rendering and cleaning. Yeah, auto cleaning, but auto rendering. \\n\\n01:57:41\\nBartek\\nAnd also we can have, how to say, categorizing the transcript into like dev call or marketing call. \\n\\n01:57:52\\nAlejo\\nWe're lucky because Zoom already does that for us. This right now that we're on is a dev meeting. And if you look at the chat. \\n\\n01:58:01\\nBartek\\nOh yeah, I forget the name of. \\n\\n01:58:03\\nAlejo\\nThe meeting, and you scroll up, all of our chats of every dev meeting are there, including the summaries. So it's pretty cool. \\n\\n01:58:13\\nBartek\\nAll right. \\n\\n01:58:17\\nAlejo\\nAnd just to be funny, I'm going to ask the AI companion. Catch me? \\n\\n01:58:32\\nBartek\\nYes, I think that's the end of my idea for today. \\n\\n01:58:37\\nAlejo\\nWell, that was 2 hours of idea. So I'm asking the zoom AI companion to give me an in depth explanation of knowledge now. I'm sorry, but the meeting transcript does not provide enough information to give an in depth explanation of knowledge now. So the rag sucks. \\n\\n01:59:00\\nBartek\\nBut this is like the zoom out of the box transcript analysis, right? \\n\\n01:59:06\\nAlejo\\nYes. Okay, I'm going to walk through this real quick and we can close it. So I input a prompt, there's global context about who fasterize is, who the teams are, and who each person is. That context allows the PFA context enrichment agent to fix and enrich the prompt with the context and outputs an enriched prompt. A lot of the word enrich in there. We'll fix that. We'll ask PFA to fix that. That follows into a PFA rag extractor agent which has access, full access to the knowledge base. The output of, wait, that goes after. The output of this extractor agent is to break down a prompt into multiple queries optimized for rag. Those queries going to the knowledge base which will be living in pine cone. And that knowledge base has the most recent Zoom call transcript, plus every other transcript we have. \\n\\n02:00:27\\nAlejo\\nIt knows skills of each person and what they want to specialize in through the competency matrix and it has knowledge of projects, clients, industry, focus, et cetera. Then comes the evaluator agent because we extracted for each query several relevant based on semantic similarity, based on cosine similarity, several chunks of information. We now need to evaluate which chunks are relevant because if we're talking about real estate agents, AI agents shouldn't be part of the answer that we're integrating, or maybe yes, depending on the automations that we're building for them. So we have an evaluator agent to say, hey, these are the most relevant chunks for each query. This is the score from one to ten for each chunk, and here are the top five chunks. From there we will have a QA agent that will do a full transcript review. \\n\\n02:01:28\\nAlejo\\nSo what chunks were retrieved and then do an evaluation of how well did the evaluator agent do its job. We will integrate an oversight board agent that will be able to route to the most relevant next agents to continue the conversation. So we'll keep track of the conversation. Identify does this task require multiple agents to have an open conversation? What other information might be needed? And it will decide which agent comes next, which might be a self refinement agent to log potential refinements to the system. It might be the programming team or most commonly it will be the merger agent which will take the best chunks from the evaluator agent and merge the best pieces from each chunk to create a full answer for each rag query. \\n\\n02:02:23\\nAlejo\\nEach individual rag query and the final steps are we have answer formatting agent prompt format no wait, that goes to the beginning. We will have answer formatting agent for hey, what's the actual use case and how we make sure we are effective at answering. And there's a big one here who is asking how can we give them a relevant answer that they care about? The CEO doesn't care about the same thing as the engineering manager. So we'll give the output format to the answer agent. It'll grab all of the relevant information and create a final output. Finally, we will have an evaluation answer evaluation agent which will help us keep track of the accuracy of our system. How close is this to a full accurate relevant system? \\n\\n02:03:36\\nAlejo\\nThe first use case is going to be the first MVP use case is going to be you can message the bot to catch up on meetings and get clarity on assignments, which is going to be one component of our V one use case which is the bot messages you with your to Dos after the meeting checks the tasks that you already have assigned your deliverables checks the capacity and then assigns the tasks. It will confirm with you which tasks you actually want and can take on. It will actually help calculate your contributions and you can have a conversation with the bot to get clarity on those assignments and do your best work. That's knowledge now. \\n\\n02:04:24\\nBartek\\nYeah. And also it will attack everybody to make a post on social media. \\n\\n02:04:31\\nAlejo\\nIt will what? \\n\\n02:04:33\\nBartek\\nIt will attack everybody with a message to write something for the social media. Seriously, I need like, attacker to attack me every day. \\n\\n02:04:46\\nAlejo\\nI don't know that attack is the right word. It, but yes, we need, it's more. \\n\\n02:04:53\\nBartek\\nOf a peeing, but I don't know. I want this AI to be aggressively making me write a post because otherwise I won't. \\n\\n02:05:02\\nAlejo\\nDude, this is going to be a huge part of the knowledge base of knowledge. Now don't use the words aggressive and attack. That's funny. We'll cut that out. We'll cut that knowledge now. Cut that last part out. But I'm with you. I'm with you. Let's have something that we're proud to show PFA. You should be proud to show it. The real estate automations, as simple as they will be. We're proud to show it. It's our first client and we're actually delivering something great for them. So let's get on that social media game and let's grind these projects out for now. This is what this project and fastrase needs from you. Bartek working on the agents. Let's get some drafts for these three agents. \\n\\n02:05:58\\nBartek\\nCan you send it to me in a chat in a private message? \\n\\n02:06:03\\nAlejo\\nThat's exactly what I was about to do. Awesome. So we need draft prompts. \\n\\n02:06:15\\nBartek\\nFor. \\n\\n02:06:19\\nAlejo\\nGreat. \\n\\n02:06:22\\nBartek\\nAnd also context agent, right? \\n\\n02:06:27\\nAlejo\\nOh, did I not put that in there? Oh, yeah, you said the context agent was 90%, but yeah, I'll add that in there. It was in a different section. \\n\\n02:06:37\\nBartek\\nYeah, because it's finished for the PFA swarm, but for the transcript, it has to be a little tweaked, I think, because it's kind of a little different. Context enrichment in case of transcript analysis and in case of prompt engineering, it's a different thing. \\n\\n02:06:53\\nAlejo\\nYeah, makes sense. \\n\\n02:06:54\\nBartek\\nOkay, cool. And do you need any help with the real estate agent projects? Maybe Hubert can help you with that. \\n\\n02:07:05\\nAlejo\\nThank you. Not for now, because it would be more lift, it would be more time spent kind of guiding someone through all of the components of number one, the CRM, number two, the API, and then most importantly, what the client wants and how they want it. So I am going to show, not tell. I'm going to first work on these two free automations that we're making for them. And then I'm going to show hooby, for example, and walk him through the final build the output, and then go backwards from there. And we can all work on those. They'll be relatively simple and we all want to make money. So I want to integrate everybody into at least one part of those real estate automations. \\n\\n02:08:02\\nBartek\\nYes, awesome. \\n\\n02:08:06\\nAlejo\\nKnowledge. Now draft 1 March twelveth 2024. Let that date be remembered. \\n\\n02:08:19\\nBartek\\nYeah. And check out the messages I sent you before this call. I found some transcript. \\n\\n02:08:26\\nAlejo\\nOh yes. \\n\\n02:08:26\\nBartek\\nAnd also those videos. We can use them also for this. \\n\\n02:08:31\\nAlejo\\nCool, cool. Lovely. I'll check them out in between tomorrow. I'll check them out tomorrow. I'll find some bartech, thank you for your. This is, this has been very fun. I'm honored. \\n\\n02:08:46\\nBartek\\nYeah, sure, man. Yeah. Happy to work on this one. Seems that it's going to be revolutionizing. \\n\\n02:08:56\\nAlejo\\nYeah, absolutely. We can help a lot of people make better lifestyles, better work, better everything. \\n\\n02:09:04\\nBartek\\nYeah. \\n\\n02:09:04\\nAlejo\\nTake care, brother. I'll see you tomorrow. \\n\\n02:09:07\\nBartek\\nYeah, bye. \\n\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"AI meeting summary:\\n     **Kuba** showcases integrating Pine Cone Vector Database and OpenAI embeddings to generate responses from meeting transcriptions. The team discusses agents essential to their system, including context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. Automated tasks like cleaning and rendering transcripts are considered for system input. Use cases like messaging bots providing assignment updates post-meetings are highlighted. \\n  Future iterations aim at self-refinement agents to enhance AI performance over time. **Kuba** introduces data integration methods, emphasizing the importance of maintaining high-quality underlying data for accurate outcomes. The team prioritizes achieving Minimum Viable Product (MVP) status before delving into complexities like contribution calculators or project log automation. Tasks are assigned among team members to progress product development focusing on different 'agents' within their pipeline. \\nAction items:\\n     **Bartek**\\n     Share intermediate and advanced prompt engineering resources with Kuba (1:27:21)\\n    ï¿½ Draft prompts for context enrichment agent, RAG extractor agent, evaluator agent and answer formatting agent in relation to Knowledge Now MVP (2:06:19)\\n    ï¿½ **Kuba**\\n    ï¿½ Review Bartek's shared prompt engineering resources (1:28:33)\\n    ï¿½ Work on draft prompts provided by Bartek for Knowledge Now MVP once received (2:07)\\nNotes:\\n    ï¿½ ? **Developing Automation Services**\\n    ï¿½ The team is working on implementing automation services to streamline the project management process.\\n    ï¿½ A focus is placed on enhancing content creation and idea generation. \\n    ï¿½ **Hubi** is tasked with specific duties that need clarity.\\n    ï¿½ ? **Using 'Knowledgenow' for Task Management**\\n    ï¿½ 'Knowledgenow' is being used to generate a list of tasks for team members after each meeting.\\n    ï¿½ It is aimed to provide clarity on the tasks assigned to each individual.\\n    ï¿½ **Hubi** is given examples of how the system functions.\\n    ï¿½ ? **Success Criteria and Project Management**\\n    ï¿½ The team discussed the success criteria for the project, emphasizing clear task distribution and responsibility assignment.\\n    ï¿½ The introduction of a scrum master assistant was mentioned as a way to further improve task clarity.\\n    ï¿½ ? **Supervisor and Moderator Roles**\\n    ï¿½ The supervisor will guide the conversation, deciding what information is relevant.\\n    ï¿½ The moderator is responsible for overseeing the conversation and ensuring it stays on topic.\\n    ï¿½ ? **Focus on Markdown and Documentation**\\n    ï¿½ The team is advised to familiarize themselves with markdown syntax for better documentation.\\n    ï¿½ **Kuba** is given resources to get started on this.\\n    ï¿½ ? **Answer Formatting and Evaluation**\\n    ï¿½ An answer formatting agent is proposed to help evaluate and format the responses.\\n    ï¿½ The team also discussed the need for a separate agent to handle answer generation.\\n    ï¿½ ? **Assigning Team Members and Deadlines**\\n    ï¿½ The team members are assigned specific tasks and deadlines.\\n    ï¿½ A tool like Airtable is suggested as a potential way to track project progress.\\n    ï¿½ ? **Meeting Summaries and Global Context**\\n    ï¿½ The team discussed the importance of meeting summaries and the need for a global context in project management.\\n    ï¿½ The idea of categorizing transcripts based on the nature of the meeting (dev call, marketing call) was proposed.\\n    ï¿½ ? **MVP Use Case**\\n    ï¿½ The first MVP use case is decided to be a bot that sends you to-dos after meetings and allows you to clarify assignments.\\n    ï¿½ It checks assigned deliverables and tasks, as well as the capacity of each team member.\\nOutline:\\n    ï¿½ Chapter 1: Introduction to the Proposed System (10:21 - 13:12)\\n    ï¿½ 10:21: Discussion begins on the issues of short, non-detailed prompts and the possibility of using markdown for more structure.\\n    ï¿½ 13:12: **Kuba** is asked about his experience with starting the rack system from a single document transcript.\\n    ï¿½ Chapter 2: Processing and Transcript Considerations (18:43 - 28:00)\\n    ï¿½ 18:43: **Kuba** shares his process of importing the meeting transcript using planchain.\\n    ï¿½ 22:48: The team discusses potential improvements in the processing side, particularly the initial parts of the transcript.\\n    ï¿½ 27:53: The team acknowledges that the transcript quality and the limitations of context extraction are affecting query outputs.\\n    ï¿½ Chapter 3: Task Clarification and Success Criteria (32:10 - 34:22)\\n    ï¿½ 32:10: The objective of the meeting is clarified as understanding individual tasks within the system project.\\n    ï¿½ 33:44: The team identifies success criteria as the ability to message each person clarifications after the meeting.\\n    ï¿½ Chapter 4: Knowledge Extraction and Enrichment (43:24 - 54:48)\\n    ï¿½ 43:24: The team discusses enriching the extracted information to create an improved prompt.\\n    ï¿½ 50:42: An extractor agent is introduced, which uses the transcript as a knowledge base.\\n    ï¿½ 53:06: Importance of being explicit and clear in step-by-step extraction and understanding client requirements is emphasized.\\n    ï¿½ 54:48: The idea of having a supervisor to lead free conversations among agents is proposed.\\n    ï¿½ Chapter 5: Evaluation and Formatting of Answers (1:07:02 - 1:18:55)\\n    ï¿½ 1:07:02: A system is proposed where a manager agent selects the best parts from high-scored chunks to form an answer.\\n    ï¿½ 1:13:59: The team agrees on the need for an answer formatting agent to provide a structured output.\\n    ï¿½ 1:17:52: The role of a supervisor in tracking the conversation and identifying necessary information is highlighted.\\n    ï¿½ Chapter 6: Transcript Analysis and Knowledge Extraction (1:49:55 - 2:01:40)\\n    ï¿½ 1:49:55: The team discusses the potential of using all available transcripts or detailed summaries as resources.\\n    ï¿½ 1:51:18: The idea of saving the output from the analysis of a single transcript into a knowledge base is proposed.\\n    ï¿½ 1:56:32: The team talks about modifying the dev team global context document and categorizing transcripts.\\n    ï¿½ 2:01:15: A QA agent is proposed to review the full transcript and evaluate how well the evaluator agent did its job.\\n    ï¿½ Chapter 7: Final Steps and Use Cases (2:03:06 - 2:06:37)\\n    ï¿½ 2:03:06: The team discusses the final steps, such as giving the output format to the answer agent to create a final output.\\n    ï¿½ 2:03:36: The first use case is introduced as a bot that provides meeting summaries and clarifies assignments.\\n    ï¿½ 2:06:37: The team acknowledges the need to tweak the system for transcript analysis compared to prompt engineering.\\n\", metadata={'source': 'data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt'}), Document(page_content=\"wawid mozgafidu,\\n\\nmuturyn,\\n\\nheri deddf,\\n\\nmozgafan llawog,\\n\\napomat,\\n\\norlt\\n\\nWazzup?\\n\\nWazzup?\\n\\nOk\\n\\nOoooo\\n\\nBears in the house\\n\\nYo what up\\n\\nWazzup\\n\\nWazzup\\n\\nWazzup\\n\\nWe can't change the spot, ok cool\\n\\nWhat you guys been up to?\\n\\nWhat you guys been up to?\\n\\nWhat you guys been up to?\\n\\nWhat you guys been up to?\\n\\nFucking sell it\\n\\nFucking sell it\\n\\nOh yeah\\n\\nOh yeah\\n\\nWell you know the news\\n\\nWell you know the news\\n\\nYeah\\n\\nYou already bring the book with you\\n\\nIt's a printer ok\\n\\nI thought it's a book\\n\\nNo it's a stand\\n\\nOh\\n\\nOh\\n\\nHere's a couple updates\\n\\nHere's a couple updates\\n\\nOn books\\n\\nLet's see\\n\\nLet's find it\\n\\nSo\\n\\nWait for\\n\\nWait for\\n\\nWait for\\n\\nWait for\\n\\nWait for\\n\\nWait for\\n\\nUpdate number one\\n\\nWe are incorporated\\n\\nIn the US for now\\n\\nAnd at some point somewhere else\\n\\nWe're a Delaware LLC\\n\\nWe also\\n\\nOpened a bank account\\n\\nSo we can start actually\\n\\nCharging for our work\\n\\nThat's number two\\n\\nAnd number three\\n\\nAnd most importantly\\n\\nMan they gave me like\\n\\n100 pages of stuff\\n\\nThis is like\\n\\nFucking thick\\n\\nJust so much fucking paper\\n\\nLike hey can you send it to me digitally\\n\\nIt's like oh you can find it online\\n\\nIt's like then why are you giving me this paper\\n\\nAnyway\\n\\nThat's the minor\\n\\nThe major\\n\\nIs that yesterday\\n\\nWe got together with\\n\\nPaige\\n\\nAnd one of her\\n\\nCousins\\n\\nAnd they do real estate\\n\\nThey do mortgage lending\\n\\nSpecifically\\n\\nAt the beginning\\n\\nAnd at the end of the real estate process\\n\\nOf buying a home\\n\\nThat's where they come in\\n\\nHey this is how much money you will probably have\\n\\nTo buy a house\\n\\nA mortgage that will approve you for\\n\\nAnd then at the end is\\n\\nOkay now let's actually do the approval process\\n\\nIn between a lot of things happen\\n\\nAnd when you're\\n\\nBig\\n\\nAs a mortgage lender like they are\\n\\nWe'll talk more about real estate\\n\\nAnd I'm still getting educated\\n\\nBut I'll get you guys up to speed\\n\\nWith how the whole process works\\n\\nWhen you start getting big\\n\\nThe interactions\\n\\nYou start having more leverage\\n\\nWith the interactions\\n\\nLike you start having real estate agents\\n\\nThat you trust\\n\\nThat you send customers to\\n\\nAs opposed to the other way around\\n\\nWhen you're small in mortgage lending\\n\\nReal estate agents\\n\\nThey have more reliance to you\\n\\nSo they have the leverage\\n\\nSo they charge more\\n\\nAnd you charge less\\n\\nWell in this case\\n\\nIt's the mortgage lender\\n\\nIs big\\n\\nAnd has the leverage\\n\\nWhich is great\\n\\nBecause they get to decide\\n\\nWhat their process looks like\\n\\nAnd they are ready to automate stuff\\n\\nSo they get to decide\\n\\nWhat their process looks like\\n\\nAnd we had a great meeting\\n\\nGoing over everything they want to implement\\n\\nAs of right now\\n\\nMore ideas will come\\n\\nThe initial deal\\n\\nAnd we'll get this drafted up\\n\\nSo we can all\\n\\nSign it\\n\\nThat actual legal document\\n\\nWe're going to start with\\n\\nTwo minor automations\\n\\nMajor to them\\n\\nMinor to programmers\\n\\nThey're simple enough\\n\\nWe just have to find\\n\\nThe right services for it\\n\\nAnd try them out\\n\\nOn our own\\n\\nAnd by next\\n\\nWednesday\\n\\nHave\\n\\nSomething to share with them\\n\\nSo you get an idea\\n\\nOne of the automations\\n\\nIs something I was able to do in 15 minutes\\n\\nSo\\n\\nIt's nothing that we can't do\\n\\nAs long as we're\\n\\nSort of focused\\n\\nSo I'll show you guys\\n\\nWhat we talked about\\n\\nAnd I'll show you\\n\\nWhat this will look like\\n\\nAnd how the services connect\\n\\nWhat questions can I answer so far\\n\\nIf any\\n\\nIs it\\n\\nNo\\n\\nI just wanted to say\\n\\nMore details on what the actual thing is\\n\\nIs it a paid opportunity?\\n\\nThis is going to become\\n\\nA paid opportunity\\n\\nThese first couple automations\\n\\nThe amount of referrals\\n\\nThat are going to come through\\n\\nThis one person\\n\\nIs pretty absurd\\n\\nIt works pretty\\n\\nSymbiotically\\n\\nEverything wants her team\\n\\nTo be more productive\\n\\nThis is not a real estate agent\\n\\nVersus real estate agent\\n\\nIt's more of a\\n\\nIf everybody is more productive, everybody wins\\n\\nWhich is great, it's a great place to be in\\n\\nSo the first couple automations\\n\\nWe're doing for free, they're simple enough\\n\\nWe're expecting referrals\\n\\nAnd\\n\\nFrom third automation onward\\n\\nWe are charging for\\n\\nRetainer\\n\\nAnd per product\\n\\nWe'll dig into those details\\n\\nNext week at a general executive meeting\\n\\nOnce we have all the details\\n\\nOnce we actually bring the proposal\\n\\nAre you and Paige still in Maryland?\\n\\nUntil tomorrow\\n\\nWhere are you going after that?\\n\\nAustralia\\n\\nProject number one\\n\\nVery straightforward\\n\\nText message\\n\\nMake a calendar event\\n\\nLet's meet tomorrow at\\n\\n3pm at the cafe\\n\\nThis gets triggered\\n\\nGoogle Calendar event gets created\\n\\nThey're not using Slack or something?\\n\\nThey use text messages\\n\\nLike SMS?\\n\\nYep\\n\\nThat's basically a feature of Google Calendar\\n\\nIn Slack\\n\\nIs a chatbot okay for this?\\n\\nSorry?\\n\\nIs a chatbot on\\n\\nVoiceflow\\n\\nGood for that task?\\n\\nIn this case\\n\\nIt's even simpler than that\\n\\nIt's just\\n\\nBeing able to identify\\n\\nWhen the trigger\\n\\nNeeds to happen\\n\\nAnd the triggers\\n\\nTend to be pretty obvious\\n\\nThere's a 3pm\\n\\nIn the text\\n\\nWe'll have to figure out together\\n\\nWhat does it look like\\n\\nFor the trigger to be proper\\n\\nI'm sure there's vast research on this\\n\\n\\nbut yes, we are looking at their text messages, a service I found to simplify the process\\n\\nis Open Phone.\\n\\nI don't know if anybody has heard of it, but there has to be several services that allow\\n\\nyou to look at text and trigger something.\\n\\nThere might be some nuances here as to how this will work.\\n\\nThe iPhones might have some restrictions, we have to look into that.\\n\\nHowever, I think that this will be pretty straightforward.\\n\\nWhat is it, what is it?\\n\\nSo we can backtrack, I just want to move forward with what the client talked about.\\n\\nA text message would also, in some cases, in most cases that Google Calendar even needs\\n\\nto get created.\\n\\nAlso a task in their CRM would also need to happen.\\n\\nTheir CRM is called Follow Up Boss.\\n\\nWe're going to sort of try it out and try it out for ourselves.\\n\\nWe have a bunch of lead lists, so we're going to do that process ourselves, get familiarised\\n\\nwith the platform and start essentially doing the thing that they want to do for ourselves.\\n\\nAnd this is part of what we're doing from here to Wednesday.\\n\\nMaking sure that once they're like, okay, let's go, okay, great, give me a login and\\n\\npassword or API keys, and we can actually get to work as opposed to getting familiarised\\n\\nonce things are signed.\\n\\nSo task number two that we're doing this week is getting familiarised with the CRM.\\n\\nWait, so do we have logins to the Follow Up Boss?\\n\\nWe're going to create an account ourselves.\\n\\nWhat I find with a lot of these platforms is they're platforms and then they're similar\\n\\nand then your business customises it.\\n\\nSo I'd rather have logins to theirs to see how they've customised it already, if that\\n\\nmakes sense.\\n\\nSo for example, in Go High Level, I had a client who had a Go High Level set up and\\n\\nthere are some different automations and flows and you can see the stages of their\\n\\npipeline.\\n\\nThat was really, really useful to me.\\n\\nSo if we could have just a, maybe we have our own account as well, but if we also have\\n\\na just an account that can just look at stuff on theirs, that'd be interesting.\\n\\nYes.\\n\\nWell, I think there is like two things in here.\\n\\nLike first, yeah, we need access to their stuff to see their process.\\n\\nEven better, if we make like a business analysis, we will get access, just not today.\\n\\nIf you guys feel like that's something that we need to have by Monday to actually do the\\n\\nprocess right, I'm happy to ask and we can go from there.\\n\\nI think we need at least like a video, but I'm not sure how are they tech savvy to show\\n\\nit all.\\n\\nSo maybe it's better to have credentials, but on the finishing note, like we definitely\\n\\ndon't want to do it like first time in their account, we definitely want to have a test\\n\\nenvironment.\\n\\nYeah.\\n\\nSo we're definitely doing it in other accounts first, we just in their account, we're just\\n\\nlooking and it would be actually best, but I'm not sure if that's cost effective, because\\n\\nif this is a free client, then I don't think it's good to make business analysis for free\\n\\nunless they want to pay, but I'm not sure if they want to pay for it.\\n\\nThis is a free client with huge potential.\\n\\nSo whatever investment needs to get done, be it time or money, I'm pretty sure that\\n\\nyou can create an account and follow a boss for free, for example.\\n\\nWhen it comes to business analysis, they know what they want, which is this, this is one\\n\\nof the things that they want.\\n\\nSo when it comes to analysis, yes, let's make sure we can dive deep, but we barely understand\\n\\nthe real estate process at this point.\\n\\nSo in this case, we have the awesome circumstance that they know what they want and implementing\\n\\nit is relatively straightforward, as opposed to a client that has the business, not really\\n\\nsure how they see automations in that business, and then we need to give a full report of\\n\\nwhat they will need.\\n\\nSo that's-\\n\\nNo guys, I'm actually second guessing this whole concern because in the follow up boss,\\n\\nwe just have to create a task.\\n\\nI don't think we need to know the structure to create a task.\\n\\nCorrect, but to do a full business analysis, we would need to know the process.\\n\\nYeah, I'm just disregarding like at this early stage, I just disregarded the thought that we\\n\\nneed to analyze this because it's straightforward and it's just create a task.\\n\\nSo I don't think we need to know that their CRM structure even, but it will be safer to know.\\n\\nIf you could get the access, it will be definitely safer and possibly could save us some time\\n\\nspent that we would be trying to guess rather than just see.\\n\\nYes, so absolutely, absolutely.\\n\\nOK, so let's move on and we can backtrack.\\n\\nAlso, I looked into the follow up boss API and it looks great, man.\\n\\nIt looks very well documented.\\n\\nYou can do anything and everything.\\n\\nWe're getting very lucky with this.\\n\\nOK, they want to do the same things for emails, but not yet because their company, their big\\n\\nagency needs to approve the integration of sending emails somewhere else.\\n\\nSo this is on standby for emails.\\n\\nThis is a go for text messages.\\n\\nMoving on. Action plans.\\n\\nSo within follow up boss and I'm going to go create an account and put some leads and walk\\n\\nyou guys through through a lot of this, probably on Monday.\\n\\nWe have something called action plans.\\n\\nSo a task would be something like send follow up email, but an action plan would be OK.\\n\\nAnd what happens after?\\n\\nSo a bit of a sequence, if you will.\\n\\nAction plans will not only be emails in their business and how they are running their\\n\\nbusiness. Physical things are a big way that they show appreciation.\\n\\nSo some small gifts like a, let's call it a fruit basket or a small bottle of champagne for\\n\\nclosing a deal, for example.\\n\\nThis might go to to clients.\\n\\nThis might also go to realtors.\\n\\nSo think about it as there's a bunch of people that came to see this one house at an open\\n\\nhouse. Hey, and they all get the tour and whatever.\\n\\nAnd afterwards, they'll all put their emails in and they need to receive a follow up email.\\n\\nAn action plan would automate the who needs to receive the thank you email for coming and\\n\\nwhat happens after.\\n\\nAnd they would automatically be set into that flow.\\n\\nSo classic CRM stuff.\\n\\nAs we say, hey, these 30 people came, these 30 new leads came to the open house, we would\\n\\nalso tag them.\\n\\nAnd again, the API allows you to do all of this.\\n\\nWe would tag them with open house February so they can keep track of it and also we can\\n\\nkeep track of it programmatically.\\n\\nThis is one of the big things they want to do with follow up bosses, action plans.\\n\\nAnd then there's something that we are going to do that a lot of future referrals are going to\\n\\nwant and need because a lot of her realtors that she's connected to don't even use a CRM and she\\n\\nexplained two statistics.\\n\\nNumber one, realtors start, say, branching out and to hiring people and would be interested or\\n\\nactually can afford outside services once they hit about $5 million in sales.\\n\\nIt's a random figure right now.\\n\\nSo don't worry about the actual $5 million.\\n\\nHowever, it is also a causality that if you're not using a CRM, you're not going to get a\\n\\njob. That if you're not using a CRM, being successful as a real estate agent is very, very\\n\\nhard.\\n\\n\\nSo, this migration allows for real estate agents who are still managing their leads\\n\\nin spreadsheets to unlock one of the tools that will help them become successful in that\\n\\nbusiness.\\n\\nYeah.\\n\\nSo, this is partly for future uses, for future clients, for future referrals.\\n\\nHowever, this is a great first step for us to get very familiar with the API and with the actual CRM.\\n\\nYeah.\\n\\nI think what's interesting about the CRM as compared to spreadsheets is, one, to the client, it might not look much,\\n\\nbut the capabilities it would give us or them, for example, just triggering stuff off a CRM,\\n\\ninstead of having, you're not going to trigger stuff off a spreadsheet.\\n\\nRight.\\n\\nYeah.\\n\\nYeah.\\n\\nGood point.\\n\\nYeah.\\n\\nYeah.\\n\\nYou have a ceiling of what you can do.\\n\\nYeah.\\n\\nCool.\\n\\nThose are the three main things, three main flows, let's call it.\\n\\nHowever, we talked for like two hours in chunk.\\n\\nSo, this is all the notes we took, all the different things they wanted to do.\\n\\nI'm going to very quickly go over them and then we're going to move on.\\n\\nI want us to look at the API and just answer any questions that you guys have.\\n\\nSo, text and emails trigger a calendar event with a reminder.\\n\\nLet's look into reminder later.\\n\\nRobust action plans automations.\\n\\nTask, person with a certain task, meaning create task for person with certain tasks.\\n\\nThis may not only be one person.\\n\\nThis could be their social media manager.\\n\\nThis could be their email marketer.\\n\\nSo, create a task for this person with a certain task.\\n\\nThen there's follow-ups and touch bases.\\n\\nWe talked about gifts.\\n\\nSometimes they send something and they have a service for this.\\n\\nSo, us triggering an automation where it's like, hey, once a quarter, so start of the quarter,\\n\\nthe automation sends an email to the gift company with details of all people to send gifts to.\\n\\nJust going to move on.\\n\\nThis is not what is important right now.\\n\\nI just want you guys to see all that we talked about and all the ideas that this person gave us,\\n\\nthat they want to implement.\\n\\nHandwritten card, that's another service that they use.\\n\\nThey want it to be triggered automatically.\\n\\nSo, they don't actually have to go to the website and say, hey, it's this person,\\n\\nand this is the email, and that's the email, and this is the card, whatever.\\n\\nSo, automate this.\\n\\nAnd then things like for the realtors, meeting up once a quarter, for example.\\n\\nHey, let's have lunch next week.\\n\\nAnd that's a simple text.\\n\\nVery simple things that we can do.\\n\\nMigration to follow-up box, so move leads from spreadsheets to follow-up box.\\n\\nSocial media automations.\\n\\nThe main one is integrations, to be able to post once and post everywhere.\\n\\nObviously, if it's a video or if it's a text post, it might not go to TikTok, right?\\n\\nBut essentially, post once, post everywhere relative to the type of post.\\n\\nAnd then there's some future ones.\\n\\nThis is where the retainer comes in.\\n\\nShe has expressed a lot of desire to implement different AI tools that help with productivity.\\n\\nFor example, Opus Pro grabs a video and creates a bunch of shorts out of it.\\n\\nI see Henry smiling.\\n\\nWe've been trying it for some of our meetings.\\n\\nThe last few days, we actually bought the full subscription.\\n\\nAnd man, it's fucking sick.\\n\\nIt's so good.\\n\\nAnd we showed it to her.\\n\\nAnd she's like, yes, this is something that I want.\\n\\nCan you do this for me?\\n\\nIt's like, sure, we can do this for you.\\n\\nThis is not really what we do.\\n\\nBut their social media person doesn't know this tool.\\n\\nSo when we're talking retainer, this actually has a purpose, which is new tools are coming out.\\n\\nHow can we help you improve your productivity consistently over time?\\n\\nAnd that's what the retainer is for.\\n\\nSometimes it was fuzzy to me.\\n\\nLike, hey, why are you charging a retainer for a chatbot?\\n\\nSure, maintenance and stuff, but does that mean the chatbot is going to break at any point?\\n\\nIt might.\\n\\nOkay, so it feels like you're telling me you're selling me this great thing, but then that it's going to break.\\n\\nAnd the value of the retainer was fuzzy to me.\\n\\nThis feels like great value to help their business continue to grow.\\n\\nAnd social media is huge in real estate.\\n\\nAnd then, again, post retainer, create posts with my style, with Canva.\\n\\nThis is kind of what she said.\\n\\nYou know, regarding the retainer feasibility, you can also say, and it's the truth.\\n\\nI mean, is the chatbot going to break?\\n\\nYeah, it can.\\n\\nBecause every time OpenAI makes an update, prompts that you've written before might not work again.\\n\\nAnd prompts written six months ago will probably not work as good as on the day of writing it.\\n\\nSo yeah, you can communicate to the clients like this.\\n\\nEvery time OpenAI makes an update, everything changes, basically.\\n\\nYeah, my problem with that is the perceived value goes down if they're constantly thinking.\\n\\nSo I think that's just a gray area to avoid.\\n\\nBut to go down the route of they will continuously look out for new tools and be trying to implement.\\n\\nYeah, but you're not saying it will break.\\n\\nAnd you're actually washing hands because you're putting it all on OpenAI.\\n\\nAnd you teach them that this technology looks like this.\\n\\nThis is a big player that gives us all the capabilities in here.\\n\\nAnd every time they make an update, things might break.\\n\\nAnd it's just the way it is.\\n\\nAnd you need to just frame it as an educational value rather than you explaining yourself.\\n\\nYeah, I mean, I agree.\\n\\nBut I also think there's kind of an edge to them not knowing.\\n\\nAlso, getting them on educating that much would take a lot of time.\\n\\nI don't know.\\n\\nWell, they're definitely early adopters.\\n\\nAlso, they think they're first to finding about AI tools.\\n\\nAnd it's been a year and a half.\\n\\nWe are so well-positioned.\\n\\nIt's ridiculous how well-positioned we are that they think they're first.\\n\\nSo I love the intellectual debate of retainer and how to show the value.\\n\\nAnd kind of washing your hands.\\n\\nBecause, yes, it is not our fault, but we can fix it.\\n\\nSo that's going to come up inevitably.\\n\\nMaybe not with this client, but in the future.\\n\\nSo thank you for your input, Bartek.\\n\\nKnowing that there are things outside of us that are changing.\\n\\nAnd you need someone very qualified to be able to adapt to the change.\\n\\nSo your chatbot keeps improving, not deteriorating over time.\\n\\nCool.\\n\\nMoving on.\\n\\nEmail automations.\\n\\nThis is for the near-medium future, because they now depend on a corporation\\n\\nto approve having their emails being read by an outside service.\\n\\nAnd there's some sensitive information, like, where do I live?\\n\\nI'm looking to buy this house.\\n\\nThis is how much money I have.\\n\\nThis is how much I got approved for.\\n\\nVery sensitive information, so we need to treat it carefully.\\n\\nBut for the simpler stuff, that doesn't really require us taking information\\n\\nout of their email, but us putting information in is newsletters.\\n\\nRight now, she has newsletters that are done mostly manually,\\n\\nbut they don't even have the name personalization.\\n\\nIt's just a newsletter that goes out to everybody.\\n\\nSo at the very least, we can help with that.\\n\\nAnd we're going to be able to help with other stuff,\\n\\nbut we didn't really dig into what the perfect newsletter would be.\\n\\nBut would this relate to a CRM automation of knowing who to send\\n\\nthe newsletter to?\\n\\nHow can we help improve CTA for the reading the email to actually\\n\\nleave somewhere or ask for feedback from the newsletter?\\n\\nHey, what would you like to know about the state of real estate this year?\\n\\nI said state a lot of times.\\n\\nSo this is for later, but newsletter is one thing that they're interested in.\\n\\nAnd then comes the bigger conversation of privacy for the future.\\n\\nLet's say the corporation doesn't approve the use case\\n\\nof having the emails being read by an outside service.\\n\\n\\nthat's not going to look like, yeah, just send them to OpenAI and they can train with\\n\\nthose emails because there is private sensitive data in there.\\n\\nSo how do we ensure privacy?\\n\\nOne way is actually going through the fine-tuning process that OpenAI has available where anything\\n\\nthat gets trained or any, I believe I have to confirm this, but any inputs or outputs\\n\\nare not used, so are not trained on.\\n\\nI have to confirm that.\\n\\nHowever, today and always, local models will be the big privacy thing.\\n\\nRunning on our server, running on their server, whatever, but local models would be the winner\\n\\nhere.\\n\\nI'm talking about a much higher price tag here.\\n\\nSo it's also a conversation for later on.\\n\\nBecause I'm assuming it's like a big corporation, right?\\n\\nIt's a big corporation and they are a smaller company within that corporation.\\n\\nI'm not sure what the exact business legal relationship is, but yes, they work inside\\n\\nof this corporation.\\n\\nThey probably pay fees or whatever.\\n\\nAnd what this corporation allows them to do is sign the mortgages because it's not coming\\n\\nout of these people's bank accounts when they're like, yeah, you're approved for $500,000 a\\n\\nmonth.\\n\\nIt's not their bank account that it comes out of.\\n\\nIt's the bigger corporation that is sort of undersigning that approval for a loan.\\n\\nBecause I'm thinking corporation most of the time are standing on the Microsoft.\\n\\nSo we could try to make an Azure instance of GPT-4.\\n\\nThat's a wonderful idea.\\n\\nWe already have Azure set up.\\n\\nLet's look into that.\\n\\nI don't think that's the priority, but yes, let's definitely look into it because sooner\\n\\nor later we need to know what the f**k we're talking about.\\n\\nOkay, wonderful, wonderful.\\n\\nI mean, the mortgages probably don't do that, but because I have this automation for generating\\n\\nthe real estate listing, like description and stuff, they're doing something like this\\n\\nor not?\\n\\nAnd that's a great question and great observation too.\\n\\nThe mortgage lenders, no, but they have about 40 real estate agents on the team and those\\n\\nagents would want to do that.\\n\\nAnd most of the agents are not going to overlap in district.\\n\\nSo within, at least in the US, a city is not really a city.\\n\\nIt's a collection of districts.\\n\\nSo there is the center of the city and you might call the whole collection of districts\\n\\nthe same name as San Francisco, but there's a lot of districts around and real estate\\n\\nagents essentially belong to a district, to a certain district.\\n\\nSo most of these real estate agents don't overlap or not in competition with each other,\\n\\nwhich is wonderful.\\n\\nAnd when it comes to, hey, we came up with this service for creating great listings,\\n\\nlisting descriptions, here it is.\\n\\nThis is how much it costs.\\n\\nAnd they can all use it.\\n\\nThis is how much it costs per user, for example.\\n\\nYeah.\\n\\nAnd we can also automate the content generation in a similar way.\\n\\nAlso to the real estate, Realtor basically, because we've been doing one Realtor in the\\n\\nbeginning and we already have this priority map and we have a few ideas for things in\\n\\nthere.\\n\\nSo maybe we can touch on that or later we'll have a call with PaweÅ‚, he'll probably want\\n\\nto bring that up.\\n\\nAnd I actually have to bounce because we have the next meeting in about an hour.\\n\\nSo I'll have to bounce off and then we can continue this conversation on another call\\n\\nlater.\\n\\nOkay.\\n\\nDo you have to leave right now?\\n\\nLike five minutes.\\n\\nOkay.\\n\\nFive minutes is great.\\n\\nI just want to go over this real quickly and see if any of you have used any of these services\\n\\nbefore or programmed with any of these services before.\\n\\nRight.\\n\\nTulio.\\n\\nYeah.\\n\\nSome knowledge.\\n\\nGreat.\\n\\nBartek, you said yes or no?\\n\\nI've been playing around a little bit with Make.com, but nothing serious.\\n\\nIt's more of like a dummy project.\\n\\nI don't know, Hubert, do you remember doing something with Tulio?\\n\\nOr it was Kamil doing that?\\n\\nOnce again?\\n\\nYou remember the yearly projects with Make.com we've been doing, you and Kamil, and then\\n\\none of you, I didn't remember which one, was doing something with Tulio.\\n\\nI don't think that we have the...\\n\\nIt was Kamil.\\n\\nTulio, it was Kamil.\\n\\nI mean, Tulio is more SMS, but the main thing is the regulations with SMS that you will\\n\\nneed to read up on the US stuff.\\n\\nUS tends to be lax with those things.\\n\\nOkay.\\n\\nYeah, yeah, yeah.\\n\\nI know Tulio in other countries has issues.\\n\\nOkay.\\n\\nMoving on.\\n\\nOpen phone, if it sounds familiar to anybody.\\n\\nOkay.\\n\\nBad, I will get the name of this, and probably not, but we'll just need to connect to it\\n\\nor send an email.\\n\\nOpus Pro, anybody?\\n\\nYeah, I've done my research on it.\\n\\nYeah.\\n\\nI think it's pretty easy.\\n\\nYeah, I've heard about it, and well, I found it and stuff, so.\\n\\nYeah, yeah, cool.\\n\\nYes, this is more of an automation.\\n\\nThis is just going to...\\n\\nIt is more cataloging who's familiar.\\n\\nZapier, who has done at least two automations with Zapier?\\n\\nWe are make.com fanboys.\\n\\nOkay, cool, cool, cool, cool, cool.\\n\\nBartek, Hubie.\\n\\nI prefer make.com as well.\\n\\nIt tends to be cheaper.\\n\\nThere's only certain things you want to use Zapier and make.com for.\\n\\nIf Zapier might connect with and follow up better than make.com, that's the only reason\\n\\nI'd choose.\\n\\nGreat.\\n\\nThat is some really good information.\\n\\nOkay, cool.\\n\\nZapier, if necessary.\\n\\nCool.\\n\\nAnd then connecting to text messages will be, yeah.\\n\\nWe'll figure that out probably.\\n\\nIsn't that kind of Twilio?\\n\\nSo we have to look into...\\n\\nOkay, let me ask that question.\\n\\nWith Twilio, am I able to read messages or just send messages?\\n\\nI think you can.\\n\\nYeah, because you can read the messages.\\n\\nI'd have to check.\\n\\nI think you can use the API so that you can send the incoming message somewhere.\\n\\nSo that then tells me, oh, you can read the message, if that makes sense.\\n\\nOkay, wonderful.\\n\\nSo, Henry, if you can look into those details of Twilio.\\n\\nWhat's the use case, sorry, for reading text messages?\\n\\nOh, yeah, yeah.\\n\\nGreat question.\\n\\nSo the use case is going to be this.\\n\\nIs there a task to...\\n\\nIs there a task to complete?\\n\\nLet me simplify for now.\\n\\nIs there an appointment to set?\\n\\nYeah.\\n\\nOkay.\\n\\nAnd how does it know whether to book one or not?\\n\\nIs it reading the message?\\n\\nAnd in the message, it says, hey, we should catch up next week.\\n\\nAnd then it knows.\\n\\nOr the AI is deciding it would be most valuable to connect up next week.\\n\\nThe AI would not be deciding if it's valuable to connect.\\n\\nIt will just read the messages.\\n\\nLunch next week?\\n\\nYes.\\n\\nWednesday at 3 p.m. at wherever?\\n\\nGreat.\\n\\nWednesday at 3 p.m. at wherever would trigger now creating a calendar event.\\n\\nOh, yeah.\\n\\nSo we need a service that simply can read that message.\\n\\nAnd then we'll have...\\n\\nHonestly, in my mind comes an assistant that just reads the message.\\n\\nWhat might have to happen is...\\n\\nA few short prompting would probably be good enough.\\n\\nBut we'll see.\\n\\nYeah.\\n\\nI'm thinking we might have to redirect the messages to a new phone number.\\n\\nAnd then have them read from there.\\n\\nOkay.\\n\\nCool.\\n\\nCool, cool, cool, cool.\\n\\nYeah.\\n\\nGreat, great.\\n\\nThat sounds plausible.\\n\\nLet me write that down here.\\n\\nRedirect messages.\\n\\nBecause she has a lot of texts.\\n\\n\\nso let's look into what the cost of that is and how if we would then include that into\\n\\nthe price or the price of the retainer.\\n\\nSo just if you can look at those two details regarding Tulio and would we need to redirect\\n\\nmessages and what would the price range be for that?\\n\\nOK, you can add me to your walkthrough.\\n\\nOh, wonderful, wonderful.\\n\\nOK, but that's me.\\n\\nYeah. Yeah, that's right.\\n\\nAwesome. Thank you, Kuba.\\n\\nNow, I'm going to look into Follow-Up Boss and look into adding a bunch of people, a bunch of leads inside of\\n\\nFollow-Up Boss so we can start doing things with it.\\n\\nOne question, oh, and we also already kind of have two referrals.\\n\\nSo that's good. One that already that needs to set up Follow-Up Boss and do the migration of leads and one that\\n\\nalready uses Follow-Up Boss and wants the next level, the automation.\\n\\nSo, yay.\\n\\nThis is exciting, you guys.\\n\\nWhat questions can I answer before we part into, Kuba wanted to look into into icebreakers and such, but what\\n\\nquestions can I answer right now?\\n\\nI think I don't have a question for now.\\n\\nI think we need to see the team.\\n\\nSo I was thinking we can also just send all messages to Twilio, to make.com and then have the just open AI call\\n\\nand, you know, filter from there.\\n\\nYeah. Yeah, that would definitely be one effective approach.\\n\\nBut on the other side, if she's sending so much text messages that are not all of them is like, you know, relevant,\\n\\nthen we would have a lot of operations on make, which might be quite costly.\\n\\nI mean, not that much, you know, just need to probably have some higher grade of subscription.\\n\\nBut we'll see how that goes later.\\n\\nGreat.\\n\\nThat's why I wanted to go into this in detail.\\n\\nShe might get 10 messages an hour for about 10 hours a day.\\n\\nIt's about 100 messages a day.\\n\\nI would be surprised if it was less.\\n\\nOK, we'll look into it.\\n\\nGood awareness. So.\\n\\nI'm thinking also about like, you know, for example, there could be a situation where she sends a message or two messages\\n\\nand I basically have to read them to as a one thread to understand the context.\\n\\nFor example, you know, one message stays a day and the other message stays the hour.\\n\\nSo I'm thinking that could be a risk in that, that\\n\\njust API call in make will just read one message and be out of context, kind of.\\n\\nI'm thinking mitigating that could be and also mitigating the cost could be if she just,\\n\\nthat will require some future automation, because I was thinking if she can make screenshot and then we can set automation to send that to GPT Vision.\\n\\nThat makes you make screenshot when she have the, you know, the meeting in those texts.\\n\\nSo we are meeting all the not meeting texts.\\n\\nBut at that point, we're looking at her pictures.\\n\\nAnd I don't think that that actually let's let's keep the ideas going.\\n\\nLet's definitely keep the ideas going.\\n\\nIf there's a way to compile last four messages, for example, from a certain person.\\n\\nSo let's look into Tulio first.\\n\\nAnd then we'll go through through branches of risks and solutions.\\n\\nYeah. Yeah. Cool.\\n\\nSo Henry and Cuba.\\n\\nWe're going to Tulio.\\n\\nI'll look into follow up boss.\\n\\nAnd for now, Cuba, let's keep going on the on the outreach.\\n\\nI'll stick around and we can talk about it.\\n\\nAnd Bartek, well, what does your time look like today and the next few days?\\n\\nI know we're talking in an hour, but what does your time look like?\\n\\nToday, I'm already fully booked.\\n\\nSorry, I meant like Monday and Tuesday more.\\n\\nLet me see that in the calendar.\\n\\nI got some calls in Tuesday and Wednesday.\\n\\nBesides that, I'm quite, quite, quite free.\\n\\nCool. Cool.\\n\\nSo we'll get to work on Monday on some of the details and we can actually get a prototype probably just straight up Monday.\\n\\nSo we have follow up boss.\\n\\nYou guys, this is really cool.\\n\\nYeah. Yeah, I'm glad you find it cool.\\n\\nUm, uh, Paige and I are moving to the other side of the world, um, tomorrow.\\n\\nUh, so we'll, we'll be around for on Monday for, for all the meetings and whatever.\\n\\nSo fortunately we're traveling through the weekend.\\n\\nHowever, um, we were evaluating if what times would work best for you.\\n\\nUh, because we won't have anybody in the Americas.\\n\\nUh, in fact, um, I've got a last minute up there as well.\\n\\nUm, basically my, my dad's now like got a job, but he's not starting until like a next month.\\n\\nSo he wanted to go do something.\\n\\nSo I'm actually flying to Thailand on Monday.\\n\\nDude also means we're in the same time zone.\\n\\nThat's awesome.\\n\\nSingapore.\\n\\nYeah.\\n\\nWe're going to, I think it's four hours difference between Singapore to Sydney.\\n\\nSo that'll, that'll work for us a lot better.\\n\\nHow long are you staying in?\\n\\nHow long are you traveling for?\\n\\nMaybe two, two, two and a half weeks.\\n\\nOkay.\\n\\nYes, I know.\\n\\nYup.\\n\\nYup.\\n\\nSo, so I'll share, I'll share some questions that we can, we can figure out probably some, uh, better, uh, times that work for, for people.\\n\\nUm, but anyway, we'll figure that out, that part out.\\n\\nUm,\\n\\nit also does mean I'm probably going to be, I will, I will make it, I will bring my laptop and I will work, but it will probably be about a bit.\\n\\nAnd then, yeah, today's really my last day to like work on this before Wednesday, probably.\\n\\nCool.\\n\\nCool.\\n\\nCool.\\n\\nOkay.\\n\\nAwesome.\\n\\nUm, great.\\n\\nSo let's, um,\\n\\nokay.\\n\\nWe'll, we'll come back to that in a second.\\n\\nUm, Henry, um,\\n\\nCuba, how are you doing my brother?\\n\\nWhere's my audio jam, bro?\\n\\nYeah.\\n\\nAs you can see, I'm doing fantastic.\\n\\nUm, curious.\\n\\nUm, what's the update on the, uh, relevance integration into the script?\\n\\nYeah.\\n\\nUm, it's works, but, but, um, currently, um, the project is going in another direction.\\n\\nSo I figure out that Landgraf would be like the best right now.\\n\\nSo we need to like, like we create everything with Landgraf because, um, we need like your outlier because when, like, it could come\\n\\ncomes in, we need like an LLM as I like as a router for the question.\\n\\nSo it's kind of like direct the question to the right agent.\\n\\nDo you understand what I'm trying to say?\\n\\nYeah, yeah, yeah.\\n\\nIt can like walk in a loop.\\n\\nSo that's what I'm trying to like figure out at the moment.\\n\\nSo, well, I tried out, I tried out the relevancy API and it works well, but the only problem right now is the email prompt.\\n\\nWhich is like, it's like taking so much of like, um,\\n\\n\\nthe course is very rare, I mean I tried the prompt template, so I need to address that\\n\\nfirst.\\n\\nOkay, so you're talking about, let me share a screen and you can show me which portion\\n\\nyou're talking about.\\n\\nOkay.\\n\\nYou mean for like email draft?\\n\\nYep.\\n\\nYes.\\n\\nLike break the email?\\n\\nYeah.\\n\\nBreakers.\\n\\nAnd then.\\n\\nYeah.\\n\\nYeah.\\n\\nHere.\\n\\nYeah, those prompt templates.\\n\\nYeah.\\n\\nOkay.\\n\\nDo you use Langsmith?\\n\\nLike, have you tried?\\n\\nI have not.\\n\\nOkay.\\n\\nLangsmith is just like for debugging and like checking token cost.\\n\\nSo when I checked, this is costing like about almost a dollar, so we need to like refine\\n\\nthe prompt to like make it better and.\\n\\nWait, so only this is costing a dollar is what you're saying?\\n\\nYeah, almost a dollar.\\n\\nOh, okay.\\n\\nCool.\\n\\nIs that with the output as well?\\n\\nYeah.\\n\\nOkay.\\n\\nCool.\\n\\nThis is for last month.\\n\\nCan you just show me last month?\\n\\nPlease show me last month.\\n\\nHere we go.\\n\\nSo these were like four or five runs of that event, of that script.\\n\\nIs this what you're saying?\\n\\nYeah.\\n\\nOkay.\\n\\nCan you go to Langsmith?\\n\\nJust log into Langsmith.\\n\\nOkay, I'm using my API.\\n\\nI need to share my screen.\\n\\nGive me a minute.\\n\\nOkay.\\n\\nYeah.\\n\\nYeah, that's cool.\\n\\nYeah.\\n\\nOkay.\\n\\nYeah.\\n\\nYeah.\\n\\nOkay.\\n\\nOkay.\\n\\nOkay.\\n\\nOkay.\\n\\nOkay.\\n\\nOkay.\\n\\nOkay.\\n\\nOkay.\\n\\nOkay.\\n\\nMessage.\\n\\nNice.\\n\\nI'm getting a message from his computer.\\n\\nYeah, that's cool.\\n\\nThank you.\\n\\nThank you.\\n\\nYes.\\n\\nThere you go.\\n\\nNo, not yet.\\n\\nYeah, it's loading.\\n\\nYeah. Okay.\\n\\nYes, so this is what I'm talking about.\\n\\nSo I can see the agents that I can see all my workflow here.\\n\\nSo for that draft an email.\\n\\n32,000 tokens from what?\\n\\nSometimes, I guess, I guess it's just the agents will be just sometimes like spin off.\\n\\nCan you can you see what percent of the tokens are the output what percent of the tokens are the prompt.\\n\\nWell, we have the prompt, so.\\n\\nOh, but it has like the question input and then the agent scratch pad.\\n\\nSummarize.\\n\\nWe're going to optimize the knowledge base because that's not very effective.\\n\\nOh, nice.\\n\\nOkay.\\n\\nYep.\\n\\nSo this is the output of the.\\n\\nWhere's the email.\\n\\nOkay.\\n\\nI'm sorry. This was like the question that I asked. So this is the amount of tokens for each of it. So for the email output.\\n\\nI think it should be.\\n\\nOkay, so for that one for that one prompt, which is the numbers of the 1800.\\n\\nThat amount of tokens are consumed.\\n\\nYeah. Okay. Well, you know, you know, like when you're using an agent, like it's breaking the tax step by step, step by step.\\n\\nSo let's from the beginning.\\n\\nFor me, this is the input. My input was dropped on email using like a summarized version of our knowledge base.\\n\\nYes, this is the output.\\n\\nSo 1300 tokens is what the input was.\\n\\nAnd then the whole step by step of breaking down the action input observation.\\n\\nAnd running the step by step of the Lang chain.\\n\\nThen that in total was 32,000. Is that what we're saying here?\\n\\nYeah.\\n\\nDoes that include like icebreakers and all that stuff? Or is this purely just that one step of drafting the email?\\n\\nJust the step of using our summarized knowledge base.\\n\\nSo what we're using now is the prompt, the icebreaker, the output from the icebreakers and summarized version of our knowledge base.\\n\\nAnd then we're going to run the step by step of breaking down the action input observation.\\n\\nAnd then running the step by step of the Lang chain.\\n\\nAnd then the whole step by step of the icebreaker.\\n\\nAnd then we're going to run the step by step of the Lang chain.\\n\\n\\nOkay, and what you're proposing for minimising token usage is changing to\\n\\nline graph. No, no, no, no, no, line graph is just like, line graph is just like routing, like, questions, when you, like,\\n\\nwhen an input is sent to an element, to route it to the right agent, you don't need, like,\\n\\ncan perform loop with the tools, like, you just need to give it the input, it knows, like, the\\n\\ntool that it's going to use, because of its ability. Gotcha. Yeah. So, line graph is just,\\n\\nit's just a better way to route agents, like, making it more autonomous, something like,\\n\\nthereabouts. So, yeah, but we need to, like, fix this prompt to be more effective and, like,\\n\\nminimise the cost of the tokens. Yes, we definitely do. Okay.\\n\\nIt's cool. I'm thinking of something, I'll try that and give it back to you, just, like, giving\\n\\nyou all the tools. Sounds good. I do really want us to prioritise making sure that, well, let me,\\n\\nlet me just double check and backtrack a second. I'm looking at the icebreakers.\\n\\nWe have five icebreakers. Professionally relevant, interest-based,\\n\\nadaptive communication style. Cool. Timely and relevant icebreaker,\\n\\nsuggestive of collaboration icebreaker. So, the icebreaker seems to, like, be writing,\\n\\nnot a whole email, but it is going for the congratulations on the release of whatever.\\n\\nIt's an impressive and collaborative effort. Could you elaborate on how this dataset could\\n\\nbe learning and multimodal perception? We might want to start choosing a real estate agent to\\n\\nask more relevant questions to what we're actually going to do, but could we set up a time to discuss\\n\\nthis further? Okay. Now comes the portion that we talked about. I'm going to share a screen real\\n\\nquick. Hey, guys, I have to bounce now. Okay. Sounds good. We'll see you later, Huy. Now comes\\n\\nthis portion of introducing the human. We have some icebreakers. We'll run it a few times with\\n\\ndifferent people. We'll collect those icebreakers and then actually evaluate. So, I'll get together\\n\\nwith Zach, and we can look at it. We can set up some time and actually go through a bunch of\\n\\nicebreakers. It feels to me that if we're going to do this in an organized, systematic manner,\\n\\nwe're going to need Airtable. So, uploading these to the Airtable base that we created\\n\\nso we can actually look at them one by one and have notes of what we would change.\\n\\nI'm thinking aloud here. Human here, upload icebreakers to Airtable. We can have a table\\n\\nof icebreakers, and then we can fine-tune starting from the icebreakers. The concern\\n\\nthat you bring up for tokens is a super valid concern, and we have the options of changing the\\n\\nmodel. We also have the option of changing the prompt to make it smaller so that at every step\\n\\nthat it gets processed, it's not consuming a multiplicative amount of tokens. That might come\\n\\nthrough optimizing the knowledge base first, kind of like creating the summary of the knowledge base\\n\\nfirst, because the knowledge base tells a whole story, and we don't need the whole story.\\n\\nWe just need, objectively, this is how we're involved, this is our offer, this is what we\\n\\noffer, and this is the ideal customer profile that we're going for. So, knowledge base,\\n\\nsummary, should only contain ICP, our offer, and ethos of the organization. Amplify the human.\\n\\nAnd this could just be, this could be just a whole summary. We might give it a little more,\\n\\nbut let's start there. So, we'll create a summary of the knowledge base, and that will, number one,\\n\\nhelp with reducing token usage and not having the model have to go through so much information,\\n\\nwe'll just confuse it. What other thoughts come to mind?\\n\\nSo, I'm thinking of refining the prompt. Okay. Email prompt. I'm thinking of refining it.\\n\\nAnd is that shortening?\\n\\nI can't see shortening. I think, like, creating it from, like, the beginning, but I'm thinking\\n\\nto be implementing some things from PFE, from this one that we're using, but really, like,\\n\\nbuilding it from scratch. So, I'll just try, I'll try out a lot of, like, iterations and\\n\\nsee what works out well. Okay. Sounds good. I think I'm going to look at this icebreaker prompt\\n\\nand probably change a few things, not much. I think this is pretty straightforward and effective.\\n\\nWe just need to go test it with our actual ideal customer profile.\\n\\nWe just need to go test it with our actual ideal customer profile, real estate agents,\\n\\nand we're working on that with the sales team. There also came the other question of, like,\\n\\nhey, what framework of email do we use? So, we'll be integrating that as well.\\n\\nMaybe that's something that helps guide this a bit more. Like, hey, here is the framework.\\n\\nOkay. Kuba, can we make sure that this gets uploaded to the GitHub?\\n\\nYeah, sure. Sure.\\n\\nWe can create a repository. I'll create a repository and\\n\\nI'll come in.\\n\\nOkay.\\n\\nOh, that's cool. I didn't know they had this.\\n\\nAnyway, I'm getting distracted.\\n\\nSo, we have personalized outreach system. I'm adding you guys in here.\\n\\nI'm going to security.\\n\\nSettings, collaborators. Great.\\n\\nAnd we have\\n\\nrate for members.\\n\\nCan you guys see if you can get here?\\n\\n\\nYeah, I'm in the GitHub.\\n\\nCool.\\n\\nWhere exactly are you looking?\\n\\nOh, just the Personalised Outreach System, if you can see it.\\n\\nYeah, I'm in it.\\n\\nCool.\\n\\nAnd Kuba, you too?\\n\\nOh, yes, I'm coming.\\n\\nAwesome, awesome.\\n\\nSo, that's where we're going to update everything.\\n\\nSo, if you could start with this initial commit, and then we'll go forward.\\n\\nThere's definitely some to-do's.\\n\\nKuba, what's your GitHub username?\\n\\nKuba, K-U-B-A. Let me send my open to K-U-B-A.\\n\\nOh, really?\\n\\nCool, man.\\n\\nUpload icebreakers to Airtable.\\n\\nOptimise email draft token usage.\\n\\nOh, okay, wait.\\n\\nI'm going to remove Ahmed, because we only have four seats.\\n\\nOh, I see.\\n\\nYep, yep.\\n\\nYeah.\\n\\nGreat.\\n\\nIt deleted what I wrote.\\n\\nHave you heard from Ahmed?\\n\\nYeah, I did.\\n\\nOkay.\\n\\nI also do...\\n\\nNan messaged me last night.\\n\\nOh, cool.\\n\\nSaying he's fine and stuff.\\n\\nOh, yeah, he just made it back to France.\\n\\nHe messaged me too.\\n\\nOh, very awesome.\\n\\nOptimise token usage on email draft.\\n\\nOkay.\\n\\nSo...\\n\\nOh, wait.\\n\\nYes.\\n\\nKuba, can you drop your email address to the GitHub in the chat?\\n\\nTo your GitHub account.\\n\\nAll right.\\n\\nOkay.\\n\\nSo...\\n\\n$10 for a million tokens.\\n\\n$30 for a million tokens.\\n\\nSo that's 3 cents for 1,000 tokens.\\n\\nFor output, 1 cent for 1,000 tokens.\\n\\nOkay.\\n\\nSo, yes, we definitely want to be using this.\\n\\nHowever, if we're talking GPT-4...\\n\\nOh, what?\\n\\nGPT-4 Turbo?\\n\\nOh, bro, we got to be using GPT-4 Turbo.\\n\\nAre we not?\\n\\nIt's like half the cost.\\n\\nIt's a third of the cost, yeah.\\n\\nAnd then GPT-3.5 Turbo, if we...\\n\\nYeah, they're making them cheaper as well.\\n\\nIt's crazy.\\n\\nIt's absurd.\\n\\nYeah, I've sent it.\\n\\nIt's in the chat.\\n\\nYep.\\n\\nI found you.\\n\\nCool.\\n\\nSo I'm just going to go update the model real quick.\\n\\nI didn't realize you weren't using Turbo.\\n\\nI would have said something, sorry.\\n\\nOh, but we found out now.\\n\\nAnd that's what's important.\\n\\nAll right.\\n\\nI'll send you an invitation.\\n\\nIt might be in your email.\\n\\nAll right.\\n\\nI'll check it now.\\n\\nAnd this is the organization called FastRise GitHub, yeah?\\n\\nYep.\\n\\nCool.\\n\\nSo GPT-4, preview, preview.\\n\\nKuba, if I run this whole thing, then you would be able to look at that same analysis of token cost.\\n\\nYeah?\\n\\nYeah, yeah, yeah, sure.\\n\\nOkay, cool.\\n\\nI added you as a collaborator, so yes.\\n\\nAwesome.\\n\\nYes, because we, yes, because you, yep, yep, yep.\\n\\nI'm going to connect and then run all.\\n\\nOkay, let's see what happens.\\n\\nOkay.\\n\\nSo this will be slow.\\n\\nThat's something that we'll have to work with.\\n\\nAnd it's fine because this is not time limited, fortunately.\\n\\nAs we prepare leads to send emails for a campaign, we have time to prepare them.\\n\\nEven just running it overnight is good enough.\\n\\nSo don't be too concerned about that part.\\n\\nAnd we will optimize over time.\\n\\nAll right, cool.\\n\\nYep.\\n\\nAnd yeah, the other thing is LinkedIn profile URLs.\\n\\nMost of the time we'll have it, not always.\\n\\nSo it's great that you left that in there.\\n\\nWe'll keep using it.\\n\\nAnd.\\n\\nYeah, I was about to ask about that.\\n\\nI saw your comment about it before.\\n\\nOh, yeah.\\n\\nI didn't get like what you're trying to say.\\n\\nOh, okay.\\n\\nWhich one?\\n\\nThis one or this one?\\n\\nAbout the LinkedIn URL.\\n\\nOh, yeah.\\n\\nSo for some of our lead lists, the LinkedIn URL will already be available.\\n\\nSo this step where we're doing the SERP for finding the.\\n\\nNo, it's not SERP.\\n\\nWe're doing the search of the LinkedIn URL.\\n\\nThis step would need to be skipped because we already have the LinkedIn URL.\\n\\nSo how does this flow change when we don't actually need to do this step?\\n\\nSo.\\n\\nAnd.\\n\\nSorry.\\n\\nSo this is where long graph comes in.\\n\\nSo.\\n\\nOkay.\\n\\nWe use like an LLM as like a router.\\n\\nInstead of like.\\n\\nOkay.\\n\\nIn a case where we have only the LinkedIn URL.\\n\\nThe LLM router knows that.\\n\\nOkay.\\n\\nIt's not going to use.\\n\\nIt's not going to be directed to this agent.\\n\\nOkay.\\n\\nSo instead we're going straight to.\\n\\nThis.\\n\\nYeah.\\n\\n\\nYeah, so, so, you are not using, we are not going to use like this agent. Do you understand?\\n\\nLike the router agent, we are going to create an agent that does the routing for each question.\\n\\nYeah.\\n\\nIf you input a LinkedIn link, so you know you are asking, you are skipping this agent, you are going to, the right agent that you are looking for. Do you understand?\\n\\nYes, I do. I understand. I guess my question is, so right now and for the near future, the critic will be set in different places, right?\\n\\nHere, there is another critic here, there is another critic here. And there is probably one loop that happens.\\n\\nHowever, it is mostly sequential. In fact, this loop is just a sequence where we put the email writer here and then the email gets sent.\\n\\nSo, since it is sequential and the LinkedIn profile, whether we have a LinkedIn profile or not, is pretty binary. It comes from a variable.\\n\\nWould we really need a whole agent, a whole routing agent to decide what step comes next? Or can we just do an, hey, if this variable is filled in this lead list, in this spreadsheet, in the CSV, then do this step.\\n\\nIf not, then do that step. Is there another purpose to the routing agent?\\n\\nNo, no, no, no, no. That works too, at least. That works. It makes things much easier.\\n\\nOkay. My ideal, in my ideal view, what you said, yes, it applies. There is a critic that will, whatever, do an assessment of the icebreakers and then say, hey, you know what, let's go back to the icebreakers step because none of these are good.\\n\\nIdeally, that's something that happens. For now, for a V1, let's keep it sequential. Let's keep it code and, in a way, reducing, minimizing the amount of agents that we're using, even as we're using like 10 different agents.\\n\\nOkay. So I'm with you on the application. Let's keep it simple for now. Let's keep it programmatic. And as soon as I can, I will give you a CSV of what that actually looks like, of what those leads actually look like.\\n\\nAnd when that LinkedIn profile column, that data is there or it's not. Yes, this is the LinkedIn URL, or it's empty. If it's empty, then run this step. Yeah, run this step. So we'll get around to that. For now, what you're doing here is wonderful.\\n\\nAnd we will decide for the next step, check if the leads CSV contains a LinkedIn profile URL.\\n\\nIf it doesn't, skip next step.\\n\\nIf it does, make LinkedIn profile URL equal to whatever, data frame, which has the same name, LinkedIn profile URL. Okay. Cool.\\n\\nAnd as we're looping through the people in this data frame, in the CSV, we can actually play with the variables inside and all that stuff. And we'll integrate the Instantly API later.\\n\\nYeah. Anyway, I think we're on the same page about that. Anything else to note? Anything else I should look at here?\\n\\nI think that should be all for now.\\n\\nOkay.\\n\\nI'm going to try running this one more time.\\n\\nAnd we are also not right now. You're comfortable. If you're comfortable with Google Colab, that's great.\\n\\nWe'll just make sure we have a version of it in the GitHub. And we are going to transition to, unless you can have GitHub. Yeah, yeah. Save a copy to GitHub. Okay, great.\\n\\nAs long as we're clicking on that. So good. Just can't see the organization.\\n\\nWhy not? Because it's not public? Is that a problem?\\n\\nI can see it here.\\n\\nOkay.\\n\\nI just can't see the organization here, which is weird.\\n\\nI can't see FastRice.\\n\\nWhy not? Because it's not public? Is that why? Because it's not public?\\n\\nI can see it here.\\n\\nOkay. Anyway, that's a neat thing.\\n\\nWe can move it to Visual Studio Code or something.\\n\\nMy point is, whatever you're comfortable coding is fine, as long as we have an updated version of it in GitHub every time. And I can just be using Visual Studio that I feel comfortable with. And I can be running it there. So it works.\\n\\nI just actually built it out using Colabo. Yeah, I'll move it over to Visual Studio Code. Then I can just pull in from the GitHub repo.\\n\\nOkay, sounds good.\\n\\nYeah.\\n\\nAnd just going to change the name too, just so we're on the same page.\\n\\nAnd let me run the rest of this.\\n\\nJust want to have you here while I run this.\\n\\nOh, I have another meeting.\\n\\nOkay, cool. Beautiful. Very readable.\\n\\nOh, it's still running. Okay.\\n\\nTo assess the relevance and potential alignment with our company's strategic goals in the AI sector, expertise, experience, and interests against the backdrop of our company.\\n\\nAI sector, you will always carefully review information of the person.\\n\\nAssess how significant a person is in artificial intelligence.\\n\\nOkay, we will also, I'll work on tuning that prompt.\\n\\nJust so we're on smoother.\\n\\nBut it's good. It's good.\\n\\nAnd down here, we put a step, part of the to-do list.\\n\\nThen we talked about optimized qualifier prompt.\\n\\nI also looked at uploading to Airtable for human review.\\n\\nSync with GitHub.\\n\\nLatest version accessible to everyone.\\n\\n\\nLovely. Okay. Great. Thank you, you guys. Oh, yeah. Checking this, checking this. Ran,\\n\\nLinkedIn profile, LinkedIn data. No, no, no, no. That should be deleted. I'll delete it. This is,\\n\\nthis is what, this is for like when I was using this proxy call. Yes, that's right. That's right.\\n\\nSo I'm going to delete it. That's why I moved everything down. Yeah. Yeah. Yeah. Okay. So this,\\n\\nand then, then it finished. Okay. If you can just upload a version that includes this,\\n\\nmaybe with a comment. I want us to have different available options. And this could, this worked,\\n\\nit worked. So having that code somewhere in the code base, it's just going to be a good idea\\n\\noverall. Okay. Great. Okay. The email draft agent stopped due to iteration limit or time limit.\\n\\nDo you know what that's about?\\n\\nYeah, that was when I was like running the, the email. Did you just run this one now?\\n\\nYeah. Yeah. I just ran it just now. Oh, okay. Let me see it. I need to bring down the email\\n\\ninto a smaller section.\\n\\nDid you, the input of the email, did you run the like email block?\\n\\nYes. Yep. Okay. So\\n\\nlet me see.\\n\\nWeird.\\n\\nOkay. I have to go to a meeting. I'll, I'll leave you with that. And\\n\\nwhy is he writing John Doe?\\n\\nJohn Doe is just like Laura Hampson.\\n\\nYeah. Yeah. Yeah. I don't know why, why that changed though. When would it have changed John?\\n\\nIt's the only time it shows up. It just.\\n\\nUnless the LLM model automatically names it John Doe.\\n\\nYeah. Yeah. Maybe. If you can look into that on your side, Kuba.\\n\\nThen I'll check it out.\\n\\nYeah. Great. Wonderful. Any questions that come up, clarification, please hit me up and, and,\\n\\nand we can, we can make sure we have it done, but these are the to-dos. If there's any confusion at\\n\\nall, we can talk about it. Check iteration limit\\n\\nerror on critic and check John Doe instead of Yann LeCun. I believe it's on, on icebreakers.\\n\\nNo, on, on email. Cool. You guys let's have a great rest of your day.\\n\\nYeah. Did you want to talk about the Thailand thing? I know you said something.\\n\\nYes, I do. And I have a meeting with Bartik and Powell. Sorry for, sorry that I kept you here.\\n\\nLet's talk about it later. Essentially what I'm saying is like you're with your dad,\\n\\nobviously enjoy your time. And as things speed up, we'll also like make sure that we give you\\n\\nvery specific, clear tasks so you can organize yourself.\\n\\nThat's it. Then that's fine. Yeah, no, I totally get it.\\n\\nCool. Thank you. Thanks for everything. Appreciate it.\\n\\nYeah. Yeah. My pleasure. It's time to, time to accelerate. Let's do this.\\n\\nAll right. Peace out, man.\\n\\nBye guys.\\n\\nPaige, let's meet in a different link. I'll send it to you.\\n\\n\", metadata={'source': 'data\\\\meeting_transcript.txt'})]\n"
     ]
    }
   ],
   "source": [
    "#extract the data \n",
    "extracted_data = load_file([ \"2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt\", \"2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt\"])\n",
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split documents into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = SemanticChunker(OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\")\n",
    "    documents = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the chunk: 130\n"
     ]
    }
   ],
   "source": [
    "text_chunk = text_split(extracted_data)\n",
    "print(\"The length of the chunk:\", len(text_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunch. I messed that up every time. Lunch. 03:13\n",
      "Kuba\n",
      "Hi guys. 03:15\n",
      "Alejo\n",
      "Hey Kuba. 03:23\n",
      "Kuba\n",
      "Let'S see how you doing, bro? 03:35\n",
      "Alejo\n",
      "1 second, you guys, thank you guys for sharing your update on Friday. It makes me very happy to see progress on what you get to work on or what you want to work on. I hear a lot of rag, I hear a lot of lang chain. As you said, kuwa, rag is the future. And it's been very exciting to talk to developers this last week. A variety of experiences and expertise and they all say the same thing. It's like Rag is where it's at. Rag is the future, Rag is what I want to learn. So we're taking that strong indication and running with it. We're building knowledge now. Okay, first of all, before we step into that, because start rattling on, wanted to share an update. I'm working on the real estate automations. 04:57\n",
      "Alejo\n",
      "I'm working on the free side on the two free real estate automations. When those are ready, I'll share the demo. In the next few days. They'll be ready. In the next few days. I'll share the demo. We can make sure we get some testing in together and I will make sure that each of us can follow the exact same process for when we actually have the paid clients that will come through referrals that we can emulate this system for their side. For some of those that might include importing contacts to the follow up boss CRM and just setting them up from scratch. For some of them that might be like, hey, I would like these automations and each of us needs to already know the API and how does the CRM actually look and feel? 06:09\n",
      "Alejo\n",
      "So I kind of tried to do that last week, but I realized I don't understand it well enough to guide others. So I took a step back. It's like, let me work on these automations, finish them, let me fall into the pits of working with any new API and make sure that I set up you guys for success once the money actually comes in. So that's the update on that. On real estate automations, client is still very excited. We got introduced to two people that she's working with, the manual follow up boss guy that's kind of importing her contacts manually and her social media person. And we're going to be able to find ways to help in both of those areas. 07:09\n",
      "Alejo\n",
      "We got some questions around profit sharing and we will make sure that we have a genexac to clarify, to share, to have questions, and to make sure that everything is clear. It's very important to us, to all of us, to each of us, that we know what's going to happen with the money once the money hits the account. Right. So we'll make sure that everybody has clarity on that and that everybody agrees. Yes, this is fair. Okay, so that's on the real estate side and that's the short term. Yeah, barta, go ahead. 07:58\n",
      "Bartek\n",
      "Because we are kind of starting to work this week, probably internally on some content automation. So I think we can actually work simultaneously on the automation for the real estate. We have this idea to make notion integrated with relevance AI. Like make some agents, and for example you have idea for your content, you write it in the notion, you have this kanban in notion. And then for example, you have this raw idea and then some ideas you want to put to AI to draft. And then that will trigger the relevance AI agent, for example, first kind of EDH version of it. And then basically it would draft a post or whatever and then send it back to notion. So that's where I'm thinking, and we're probably going to start working on it this week if there is a time, if the winds are correct. 09:04\n",
      "Alejo\n",
      "Yeah, cool, that's good to know. 09:11\n",
      "Bartek\n",
      "And I also have updates now from the call just a second ago. 09:17\n",
      "Alejo\n",
      "Go in a circle and do updates. 09:18\n",
      "Bartek\n",
      "So go crazy. Yeah, so I was talking to this guy from the prompt hub, and we can have collaboration there, like constant collaboration or whatever. I was talking to him on this kind of note, but the thing that really clicked after this call, because I was showing him PFA and the output was kind of short. I mean the use case was for a recipe and for a cuisine, sending and generating receipts. So I see that the details couldn't be there more. But I got thinking like PFA sometimes does that PFA sometimes give a short prompt and you need to regenerate. And I was thinking like, we need the swarm, we fucking need the swarm. It's not a product until we have the swarm. This is just a proof of content. And if user have to know that the prompt. 10:10\n",
      "Bartek\n",
      "I know from my eyes that the prompt is not good, but users want. So we need to have this. The thing that I'm doing manually, like regenerating, like looking the prompt is not good. Or regenerating, or saying, like, use more markdown or make this prompt more detailed. We need a feedback loop for that in the PFS form, like some agents doing basically what I'm doing now. So the prompt is too short, the prompt lacks markdown, lack structure. We should really go there. 10:42\n",
      "Alejo\n",
      "Okay, perfect. 10:42\n",
      "Bartek\n",
      "And I'm thinking about maybe we could repurpose some of our agent systems. Like, I'm not sure how we can. Maybe we can use the outage system a little bit to change it in a way that we could have those. Or maybe it's better to make it from scratch. I'm still not sure, but we kind of have this structure already where we have those agents talking to each other. I mean, they are not really talking. That are in a chain, right? Yeah, it's kind of chain of action rather than conversation. I think we need to step into the conversation part where we have some kind of hierarchies. Like this is agent one that making the context enrichment. And then there is another one, let's say in a simplest form, generating. And then we would have some agents that above them and check their work. 11:44\n",
      "Bartek\n",
      "And they need to talk, basically, yeah. I think we need to make it from scratch. 11:50\n",
      "Alejo\n",
      "Okay.\n"
     ]
    }
   ],
   "source": [
    "print(text_chunk[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"text-embedding-3-large\"\n",
    "\n",
    "def data_embedding():\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = data_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "Your_env = \"gcp-starter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = \"knowledgenow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding embeddings into the vectorstore\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_documents(text_chunk, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing retrival\n",
    "retriver = vectorstore.as_retriever(search_kwargs={'k':25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiaze language models\n",
    "llm  = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key, \n",
    "    model=\"gpt-4-turbo-preview\", \n",
    "    temperature= 0.0,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain. retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=retriver, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What were the topics of conversation between Alejo and Bartek during their meeting?', '2. Can you detail the subjects Alejo and Bartek covered in their recent meeting?', '3. What did Alejo and Bartek talk about in their conference?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what did alejo and bartek discuss in the meeting\"\n",
    "\n",
    "docs = retriever.get_relevant_documents(query=query)\n",
    "\n",
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"\\n01:09\\nAlejo\\nOkay. Hi, see you all again. 01:17\\nBartek\\nWaiting for us or it's only three of us here? Hi guys, I'm hearing you right now. I just had a dinner, so excuse me, eating. Aleo, I think you have something with your audio. I can't hear you. Aleo, you're not here. 02:49\\nAlejo\\nOkay, I guess no headphones it is. Hey you guys. 02:53\\nBartek\\nYeah, sounds good. 02:54\\nAlejo\\nCool. 02:55\\nBartek\\nHi again. 02:57\\nAlejo\\nHey, did you say something? Is there something you wanted to share? 03:05\\nBartek\\nI just wanted to share that I have great. Dinner or lunch?\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Happy to work on this one. Seems that it's going to be revolutionizing. 02:08:56\\nAlejo\\nYeah, absolutely. We can help a lot of people make better lifestyles, better work, better everything. 02:09:04\\nBartek\\nYeah. 02:09:04\\nAlejo\\nTake care, brother. I'll see you tomorrow. 02:09:07\\nBartek\\nYeah, bye. \", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Make what from scratch? 11:55\\nBartek\\nThe communication PFA is warm, like the lang chain framework for PFA, basically. 12:02\\nAlejo\\nOkay. 12:03\\nBartek\\nMaybe we can step into some kind of crew AI thing. It's popping recently. Crew AI on my. 12:11\\nAlejo\\nSo let's. Let's get there. I want to make sure that Kuba and Hubi are with us on this dive into the possibilities I'm following. So let's get to the point where everybody's on the same page and we can actually make some decisions because there's a lot of things that we don't need to do from scratch.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"31:14\\nAlejo\\nI like that. Okay, that's a whole different component. Let's figure out where that fits, because that probably fits here somewhere. 31:24\\nBartek\\nYeah, knowledge. 31:25\\nAlejo\\nNow let's start from the end of it, which is the answer. And I want to dig into this a little bit because, Bartek, you and I connected earlier today and we threw out some great brainstorming. I want to make sure that everybody's with us because we said some really interesting things that we could do with knowledge. Now we talked about a little more space. We talked about a bot that measures messages. You with your to dos say the call ends. We're in a dev meeting. At the end of this dev meeting, the objective for each of us is to have clarity on which of these tasks of this whole system that we're going to look at. We are tackling, it's a subcomponent of a component and we're going to make sure that we are each set up for success. 32:31\\nAlejo\\nWhat that looks like with knowledgenow in the future, with knowledgenow, is that right after the meeting we can get a list of to do's. It's like, hey, this is what you're working on and these are the subtasks that you have to.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"01:58:13\\nBartek\\nAll right. 01:58:17\\nAlejo\\nAnd just to be funny, I'm going to ask the AI companion. Catch me? 01:58:32\\nBartek\\nYes, I think that's the end of my idea for today. 01:58:37\\nAlejo\\nWell, that was 2 hours of idea. So I'm asking the zoom AI companion to give me an in depth explanation of knowledge now. I'm sorry, but the meeting transcript does not provide enough information to give an in depth explanation of knowledge now. So the rag sucks. 01:59:00\\nBartek\\nBut this is like the zoom out of the box transcript analysis, right? 01:59:06\\nAlejo\\nYes. Okay, I'm going to walk through this real quick and we can close it. So I input a prompt, there's global context about who fasterize is, who the teams are, and who each person is. That context allows the PFA context enrichment agent to fix and enrich the prompt with the context and outputs an enriched prompt. A lot of the word enrich in there. We'll fix that. We'll ask PFA to fix that. That follows into a PFA rag extractor agent which has access, full access to the knowledge base. The output of, wait, that goes after. The output of this extractor agent is to break down a prompt into multiple queries optimized for rag. Those queries going to the knowledge base which will be living in pine cone. And that knowledge base has the most recent Zoom call transcript, plus every other transcript we have. 02:00:27\\nAlejo\\nIt knows skills of each person and what they want to specialize in through the competency matrix and it has knowledge of projects, clients, industry, focus, et cetera. Then comes the evaluator agent because we extracted for each query several relevant based on semantic similarity, based on cosine similarity, several chunks of information. We now need to evaluate which chunks are relevant because if we're talking about real estate agents, AI agents shouldn't be part of the answer that we're integrating, or maybe yes, depending on the automations that we're building for them. So we have an evaluator agent to say, hey, these are the most relevant chunks for each query. This is the score from one to ten for each chunk, and here are the top five chunks. From there we will have a QA agent that will do a full transcript review. 02:01:28\\nAlejo\\nSo what chunks were retrieved and then do an evaluation of how well did the evaluator agent do its job. We will integrate an oversight board agent that will be able to route to the most relevant next agents to continue the conversation. So we'll keep track of the conversation. Identify does this task require multiple agents to have an open conversation? What other information might be needed? And it will decide which agent comes next, which might be a self refinement agent to log potential refinements to the system. It might be the programming team or most commonly it will be the merger agent which will take the best chunks from the evaluator agent and merge the best pieces from each chunk to create a full answer for each rag query. 02:02:23\\nAlejo\\nEach individual rag query and the final steps are we have answer formatting agent prompt format no wait, that goes to the beginning. We will have answer formatting agent for hey, what's the actual use case and how we make sure we are effective at answering. And there's a big one here who is asking how can we give them a relevant answer that they care about? The CEO doesn't care about the same thing as the engineering manager. So we'll give the output format to the answer agent. It'll grab all of the relevant information and create a final output. Finally, we will have an evaluation answer evaluation agent which will help us keep track of the accuracy of our system. How close is this to a full accurate relevant system? 02:03:36\\nAlejo\\nThe first use case is going to be the first MVP use case is going to be you can message the bot to catch up on meetings and get clarity on assignments, which is going to be one component of our V one use case which is the bot messages you with your to Dos after the meeting checks the tasks that you already have assigned your deliverables checks the capacity and then assigns the tasks. It will confirm with you which tasks you actually want and can take on. It will actually help calculate your contributions and you can have a conversation with the bot to get clarity on those assignments and do your best work. That's knowledge now.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Lunch. I messed that up every time. Lunch. 03:13\\nKuba\\nHi guys. 03:15\\nAlejo\\nHey Kuba. 03:23\\nKuba\\nLet'S see how you doing, bro? 03:35\\nAlejo\\n1 second, you guys, thank you guys for sharing your update on Friday. It makes me very happy to see progress on what you get to work on or what you want to work on. I hear a lot of rag, I hear a lot of lang chain. As you said, kuwa, rag is the future. And it's been very exciting to talk to developers this last week. A variety of experiences and expertise and they all say the same thing. It's like Rag is where it's at. Rag is the future, Rag is what I want to learn. So we're taking that strong indication and running with it. We're building knowledge now. Okay, first of all, before we step into that, because start rattling on, wanted to share an update. I'm working on the real estate automations. 04:57\\nAlejo\\nI'm working on the free side on the two free real estate automations. When those are ready, I'll share the demo. In the next few days. They'll be ready. In the next few days. I'll share the demo. We can make sure we get some testing in together and I will make sure that each of us can follow the exact same process for when we actually have the paid clients that will come through referrals that we can emulate this system for their side. For some of those that might include importing contacts to the follow up boss CRM and just setting them up from scratch. For some of them that might be like, hey, I would like these automations and each of us needs to already know the API and how does the CRM actually look and feel? 06:09\\nAlejo\\nSo I kind of tried to do that last week, but I realized I don't understand it well enough to guide others. So I took a step back. It's like, let me work on these automations, finish them, let me fall into the pits of working with any new API and make sure that I set up you guys for success once the money actually comes in. So that's the update on that. On real estate automations, client is still very excited. We got introduced to two people that she's working with, the manual follow up boss guy that's kind of importing her contacts manually and her social media person. And we're going to be able to find ways to help in both of those areas. 07:09\\nAlejo\\nWe got some questions around profit sharing and we will make sure that we have a genexac to clarify, to share, to have questions, and to make sure that everything is clear. It's very important to us, to all of us, to each of us, that we know what's going to happen with the money once the money hits the account. Right. So we'll make sure that everybody has clarity on that and that everybody agrees. Yes, this is fair. Okay, so that's on the real estate side and that's the short term. Yeah, barta, go ahead. 07:58\\nBartek\\nBecause we are kind of starting to work this week, probably internally on some content automation. So I think we can actually work simultaneously on the automation for the real estate. We have this idea to make notion integrated with relevance AI. Like make some agents, and for example you have idea for your content, you write it in the notion, you have this kanban in notion. And then for example, you have this raw idea and then some ideas you want to put to AI to draft. And then that will trigger the relevance AI agent, for example, first kind of EDH version of it. And then basically it would draft a post or whatever and then send it back to notion. So that's where I'm thinking, and we're probably going to start working on it this week if there is a time, if the winds are correct. 09:04\\nAlejo\\nYeah, cool, that's good to know. 09:11\\nBartek\\nAnd I also have updates now from the call just a second ago. 09:17\\nAlejo\\nGo in a circle and do updates. 09:18\\nBartek\\nSo go crazy. Yeah, so I was talking to this guy from the prompt hub, and we can have collaboration there, like constant collaboration or whatever. I was talking to him on this kind of note, but the thing that really clicked after this call, because I was showing him PFA and the output was kind of short. I mean the use case was for a recipe and for a cuisine, sending and generating receipts. So I see that the details couldn't be there more. But I got thinking like PFA sometimes does that PFA sometimes give a short prompt and you need to regenerate. And I was thinking like, we need the swarm, we fucking need the swarm. It's not a product until we have the swarm. This is just a proof of content. And if user have to know that the prompt. 10:10\\nBartek\\nI know from my eyes that the prompt is not good, but users want. So we need to have this. The thing that I'm doing manually, like regenerating, like looking the prompt is not good. Or regenerating, or saying, like, use more markdown or make this prompt more detailed. We need a feedback loop for that in the PFS form, like some agents doing basically what I'm doing now. So the prompt is too short, the prompt lacks markdown, lack structure. We should really go there. 10:42\\nAlejo\\nOkay, perfect. 10:42\\nBartek\\nAnd I'm thinking about maybe we could repurpose some of our agent systems. Like, I'm not sure how we can. Maybe we can use the outage system a little bit to change it in a way that we could have those. Or maybe it's better to make it from scratch. I'm still not sure, but we kind of have this structure already where we have those agents talking to each other. I mean, they are not really talking. That are in a chain, right? Yeah, it's kind of chain of action rather than conversation. I think we need to step into the conversation part where we have some kind of hierarchies. Like this is agent one that making the context enrichment. And then there is another one, let's say in a simplest form, generating. And then we would have some agents that above them and check their work. 11:44\\nBartek\\nAnd they need to talk, basically, yeah. I think we need to make it from scratch. 11:50\\nAlejo\\nOkay.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"We'll talk about that too. 22:48\\nBartek\\nAnd one thing on the processing side, I'm thinking maybe we should use, I mean, it looks quite good over here, but the beginning of the transcript, weird. 23:00\\nAlejo\\nWords. 23:04\\nBartek\\nWe should have. Maybe. 23:09\\nKuba\\nThere are a lot of weird words in the document. 23:13\\nBartek\\nYeah, I'm thinking maybe we should have agent that corrects the words like extract the meaning. 23:25\\nAlejo\\nSo that is already built. I can show you. I want to go from big picture to small picture. And we can talk about the components and the subcomponents. And fixing the transcript is one of those subcomponents. All right, call out.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"01:52:34\\nBartek\\nSo. 01:52:38\\nAlejo\\nBut that is part of why we have the evaluator agent, because it's like, hey, based on the enriched prompt, the rag queries, this chunk that you withdrew, we're talking about AI agents. We're not talking about real estate agents.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Since we're there. 13:05\\nBartek\\nLet's just go there, Kuba, we'll get. 13:07\\nAlejo\\nAround to personalized our system, and I'll give you an update on that. I would like to ask you, Kuba, were you able to start with this rack system from the single document transcript? 13:24\\nKuba\\nYeah, I created it with pine cone. I tested pine cone and abute system. One with pine cone and one with. 13:41\\nAlejo\\nPine cone and the other one with. 13:48\\nKuba\\nOpen source vector database. 13:50\\nAlejo\\nOkay. 13:51\\nKuba\\nYeah, I'm just testing, like cosine similarities between the vectors. 14:01\\nAlejo\\nI'm just testing, yeah. 14:07\\nKuba\\nUpdates the two system. I will show you demo like that. 14:13\\nBartek\\nCool. 14:14\\nAlejo\\nYeah, you have it now. You said you have it now. 14:17\\nKuba\\nYeah, I do. 14:19\\nAlejo\\nAwesome. Let's do it. Let me allow sharing. It's great.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Amak. 01:44:48\\nBartek\\nLet'S sum up what prompts we need for those agents. So prepare those prompts for the MVP of the knowledge now. 01:45:07\\nAlejo\\nOne sec. And then answer agent. And then for other stuff is the global context, the actual knowledge base which I'm working on. And then the discord bot web. Love it.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Yeah. Cool. So Henry and Cuba. We're going to Tulio. I'll look into follow up boss. And for now, Cuba, let's keep going on the on the outreach. I'll stick around and we can talk about it. And Bartek, well, what does your time look like today and the next few days? I know we're talking in an hour, but what does your time look like? Today, I'm already fully booked. Sorry, I meant like Monday and Tuesday more. Let me see that in the calendar. I got some calls in Tuesday and Wednesday. Besides that, I'm quite, quite, quite free. Cool.\", metadata={'source': 'data\\\\meeting_transcript.txt'}), Document(page_content=\"Yes. And that exactly fits in with what Bartek was mentioning of. Hey, we need somebody to kind of moderate and manage the conversation. Could you text what that service thing that you were looking at is called? 37:43\\nKuba\\nThe service Aws. Is that what I mean? 37:50\\nAlejo\\nI'm not familiar. Could you write it? You were watching something that does this? Did I capture that? 37:59\\nKuba\\nYeah, yeah, I was watching like a video. That's what I was saying.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"What if you try it again? 24:04\\nBartek\\nWhat if you instead of agents say product? Because I think this was about the real estate how to say listing description generator. 24:19\\nAlejo\\nRight? 24:19\\nBartek\\nI saw it in the transcript. It was actually me talking about the first project of celebrities. So I think it's more of a product. Oh yeah. 24:37\\nAlejo\\nGo. There we go. 24:40\\nBartek\\nYou see, you need a prompt engineer. 24:44\\nAlejo\\nThat's where that comes in. 24:45\\nBartek\\nThe prompt registration. 24:51\\nAlejo\\nShould we. Wow, this is just. 24:59\\nKuba\\nLike imputing, like incrementing continuously. 25:05\\nAlejo\\nOkay, got you. Let's try. This call was about knowledge. Now could you ask what is the product called, how is it used about. 25:44\\nBartek\\nExtract and either eight project documentation. 25:49\\nKuba\\nExtract. Sorry, I didn't get that. 25:54\\nAlejo\\nExtract and ideate product documentation. 26:00\\nBartek\\nProject. 26:14\\nAlejo\\nI wonder how well it does with typos. Summary.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"All of our transcripts or detailed summaries of our transcripts. It would probably be the full transcripts. 01:50:09\\nBartek\\nOr the cleaned transcript. Clean from those weird words. 01:50:13\\nAlejo\\nYes, cleaned transcript. And I think we are going, I have that code. 01:50:24\\nBartek\\nI think we should be going like one transcript per one use of the knowledge now. Because if you throw all of the transcript in the one knowledge base, I'm not sure how that's going to go. I mean, you want to extract from one meeting, right? You don't want to extract from every meeting at once. 01:50:43\\nAlejo\\nThe whole point is that there is continuity from meeting to meeting. 01:50:50\\nBartek\\nYeah, but at one, say, run of the knowledge, now you're extracting from one particular meeting. 01:50:57\\nAlejo\\nRight. 01:50:58\\nBartek\\nThe all meetings is like a global context, like infrastructure, knowledge base, something like that. In my variant there is the run. It's on a one transcript, and then we have output of that and that should be saved into the all transcript knowledge base. Not the transcript itself, but the result of the knowledge. Now doing the work, analyzing transcript, and then have like summary or something like that. 01:51:41\\nAlejo\\nOkay. I'm not 100% sure.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"But I will add that to you by tomorrow. 01:34:05\\nKuba\\nAll right, no problem going with your stuff. 01:34:08\\nAlejo\\nI'll send you some more documents and we can with a bigger knowledge base. 01:34:13\\nKuba\\nAll right, guys. 01:34:15\\nBartek\\nGood job, brother. Yeah. 01:34:21\\nAlejo\\nPrompt engineer. 01:34:22\\nBartek\\nAll right, so we've got like 1234 agents for the MVP. 01:34:34\\nAlejo\\nWe have to figure out the use case. There's the answer. Agent one, evaluator, extractor four. 01:34:46\\nBartek\\nAll right, but the problem is that the first agent is a swarm itself. 01:34:54\\nAlejo\\nSure.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"This is wonderful. I wanted to be able to visualize these components, so let's pause so we can keep going forward. So we talked about a lot of things last meeting, it was brainstorming session, and we're taking all these ideas and all these use cases and we're running with it. So let's make it a little more visual. Number one, the thing that we know for sure, which is at the end of a. Sorry, I'm trying to remove the captions. They're in the way. Okay, well, it is what it is. At the end of. 30:11\\nBartek\\nThe end of. 30:12\\nAlejo\\nThe day, what we need is answer. Sounds obvious, but how do we get.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Okay. 01:41:37\\nBartek\\nAnd then we will have like a testing upgrades form for later testing. 01:41:46\\nAlejo\\nUpgradeswarm. And that's going to be V two.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"I'm with you. Let's have something that we're proud to show PFA. You should be proud to show it. The real estate automations, as simple as they will be. We're proud to show it. It's our first client and we're actually delivering something great for them. So let's get on that social media game and let's grind these projects out for now. This is what this project and fastrase needs from you. Bartek working on the agents. Let's get some drafts for these three agents. 02:05:58\\nBartek\\nCan you send it to me in a chat in a private message? 02:06:03\\nAlejo\\nThat's exactly what I was about to do. Awesome. So we need draft prompts. 02:06:15\\nBartek\\nFor. 02:06:19\\nAlejo\\nGreat. 02:06:22\\nBartek\\nAnd also context agent, right? 02:06:27\\nAlejo\\nOh, did I not put that in there? Oh, yeah, you said the context agent was 90%, but yeah, I'll add that in there. It was in a different section. 02:06:37\\nBartek\\nYeah, because it's finished for the PFA swarm, but for the transcript, it has to be a little tweaked, I think, because it's kind of a little different. Context enrichment in case of transcript analysis and in case of prompt engineering, it's a different thing. 02:06:53\\nAlejo\\nYeah, makes sense. 02:06:54\\nBartek\\nOkay, cool. And do you need any help with the real estate agent projects? Maybe Hubert can help you with that. 02:07:05\\nAlejo\\nThank you. Not for now, because it would be more lift, it would be more time spent kind of guiding someone through all of the components of number one, the CRM, number two, the API, and then most importantly, what the client wants and how they want it. So I am going to show, not tell. I'm going to first work on these two free automations that we're making for them. And then I'm going to show hooby, for example, and walk him through the final build the output, and then go backwards from there. And we can all work on those. They'll be relatively simple and we all want to make money. So I want to integrate everybody into at least one part of those real estate automations. 02:08:02\\nBartek\\nYes, awesome. 02:08:06\\nAlejo\\nKnowledge. Now draft 1 March twelveth 2024. Let that date be remembered. 02:08:19\\nBartek\\nYeah. And check out the messages I sent you before this call. I found some transcript. 02:08:26\\nAlejo\\nOh yes. 02:08:26\\nBartek\\nAnd also those videos. We can use them also for this. 02:08:31\\nAlejo\\nCool, cool. Lovely. I'll check them out in between tomorrow. I'll check them out tomorrow. I'll find some bartech, thank you for your. This is, this has been very fun. I'm honored. 02:08:46\\nBartek\\nYeah, sure, man. Yeah.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Okay. You threw out other considerations there. What was it. 01:57:15\\nBartek\\nI was just saying before about the automation of rendering and cleaning? So I guess that happens automatically all the time. And then we only have differentiation for. 01:57:28\\nAlejo\\nThe use case rendering and cleaning. Yeah, auto cleaning, but auto rendering. 01:57:41\\nBartek\\nAnd also we can have, how to say, categorizing the transcript into like dev call or marketing call. 01:57:52\\nAlejo\\nWe're lucky because Zoom already does that for us. This right now that we're on is a dev meeting. And if you look at the chat. 01:58:01\\nBartek\\nOh yeah, I forget the name of. 01:58:03\\nAlejo\\nThe meeting, and you scroll up, all of our chats of every dev meeting are there, including the summaries. So it's pretty cool.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"There's going to be other things that we add on top. 01:18:08\\nBartek\\nAlso assign team members. 01:18:10\\nAlejo\\nAssign team members. So what's the actual use case?\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Yeah. 46:41\\nBartek\\nBut if it knows where we're going and from where we're coming from, actually the fasterized knowledge base. Okay.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"What else? 01:18:43\\nBartek\\nDecompose tasks. 01:18:46\\nAlejo\\nDecompose tasks? Yes, decompose projects into components. Into tasks. 01:19:02\\nBartek\\nAssign deadlines. 01:19:05\\nAlejo\\nAssign deadlines. Which ideally we're saying out loud during the call. 01:19:16\\nBartek\\nIt'S like deadline for the whole project. Right. We talk on the call, but there is another deadline for the tasks and for the components, right? 01:19:27\\nAlejo\\nYes. We then have to figure out over time how much autonomy do we want to give it, even if the output is perfect, the nuances of humans and hey, I'm actually quite swamped this week and I'm only now learning rag. So how big of a deadline, how long of a deadline or how big of a task can I really take on? Let's keep that human for now. And the scrum assistant can help with the evaluation, sort of the analysis, evaluation of all of that. 01:20:18\\nBartek\\nYeah. We could also have at some point availability checker, something like that. So checks tasks already assigned to the person. 01:20:33\\nAlejo\\nYeah. So like, checks tasks already assigned. So we need project manager management tool to keep track of this, which is likely going to be notion. So we're actually already migrating a lot of stuff to notion and we can then automate the project manager within notion. Check tasks already assigned, deliverables missed and delivered, missed. And it can help sort of adapt like, oh, well, maybe this person is overloaded right now and kind of like checks capacity and then assigns. 01:21:29\\nBartek\\nThis is already fault three we're talking. But that could also be like contribution calculator or whatever. 01:21:41\\nAlejo\\nYeah, contribution calculator. And I actually found a great template to do that. It's an airtable template where you can create a project and then keep progress logging. Yes, absolutely. And maybe even that can be filled automatically during the call live. That'd be cool. Kind of like project automated auto project logging, progress logging. 01:22:32\\nBartek\\nOkay, and after that we have like a UI thing going on. After the answer we are stepping out of this agent. Now we have UI, so either yes or no. For V one, for example, you get the to do list from this and then you have option to say like. 01:22:52\\nAlejo\\nYes or no, yes or no, like. 01:22:57\\nBartek\\nIf you take the task or you don't take the task because you get assigned to something. AI already checked. You can do this, but now it's human decision if you want to do see? 01:23:09\\nAlejo\\nI see, yep. 01:23:17\\nBartek\\nNow we're getting to the human, to. 01:23:19\\nAlejo\\nThe UI confirm task. 01:23:23\\nBartek\\nI think that should be like separate card because we are stepping out of this is not AI anymore. We are going to the UI, to the human. So that should be like another card. 01:23:37\\nAlejo\\nI think so. These are use cases. Each of these subcomponents may or may not contain AI. I want to just make sure that we're not now dividing the use cases into what we'll need, just so we can refer back to these and look at the whole use case as a whole. It's going to be very important to be very clear and almost like simplify use cases so we know what the success criteria is of each use case. Yes. Now knowledgenow completes this to do task successfully and we don't have such large variations of branches of the use case itself. So I'm putting here confirm task assignment. We'll figure out how that works and where that fits in. 01:24:37\\nBartek\\nRight. So. 01:24:42\\nAlejo\\nLet'S look at it backwards so we get the final answer. Hey, these are your to dos based on the project, based on the deliveries that you have, the capacity that you have. This is what has been assigned to you. Do you accept these? Which ones do you accept or do you want to review this? Yes, I accept. Contribution calculator comes later. You can message bot to catch up on meetings and get clarity on assignments. Which was the first low hanging fruit that we identified even as a subcomponent of this. We asked about this, right? What are the low hanging fruits? 01:25:33\\nBartek\\nOkay, I think what we should do now because we have this high level thing and now we should maybe go backwards like you say, and mark the things that are required for the minimal version. 01:25:45\\nAlejo\\nYeah. 01:25:48\\nBartek\\nLet's have this green sticker. Where is things required? 01:25:54\\nAlejo\\nOkay, cool. So we know that the actual output is required and we'll just tag like MVP. That's a little too small. MVP. Bam. Evaluation. We're going to be doing manual evaluation. 01:26:17\\nBartek\\nYeah, I think all evaluations can go to the V two. 01:26:21\\nAlejo\\nYeah.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Oh, right, okay. Yeah, thank you, Hubi. We'll get you the recording and we'll make sure that you have a clear task to work on. So at the end of the meeting, Hubi that now has to leave will get a list of tasks that he has to get done and maybe he's not super clear on what those tasks really mean. So you can message the bot to catch up on the meeting, get clarity on the meeting. That's kind of one use case in itself. So number one, great. Another use case is at a deaf meeting. We have a new project. 33:34\\nAlejo\\nWe're talking about knowledge. Now we figure out the objectives of knowledge. Now we figure out the use case, right? So let's say it's this first use case. We figure out the success criteria, that it actually messages each person after the meeting. That it's clear on the tasks, that the tasks are actually what we talked about, that they're assigned to the right person. So we set up the success criteria and we figure out the step by step. This whole thing that we're doing now is going to be that step by step. So all that knowledge exists in the meeting. After the meeting, there's already a prototype being built. So that might look like a documentation writer. A documentation writer. It might look like a project manager, multi agent, anybody. It might look like actual programmers. 34:39\\nBartek\\nLet's make digital twins. Of all the dev team partners of. 34:45\\nAlejo\\nAll the dev team. Hey, I am good at this, but I want to learn rag. 34:52\\nKuba\\nGreat. 34:52\\nAlejo\\nNow you have a Bartech digital partner that is an expert at Rag and can help you build those projects while guiding you through it. Because code, in the very near future we won't even need to write. But systems design is something that we need to keep honing in on Cuba. The fact with a personalized outreach system, the fact that were able to throw you a picture of the system that we wanted, and you were able to write the code to put each agent and how it would work together, what tools each agent would need. That is freaking awesome, man.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"01:35:35\\nAlejo\\nSo this is what I'm going to need from you. I need you to pat yourself on the back for creating an amazing product that we are going to put in a whole different category of amazing once it's multiagent. And right now, we really need to focus on creating the bigger product because again, that's one amazing, but just one component of the whole system. And I am absolutely sure that through these testings, through these. Hey, now create, break down this enriched prompt into multiple queries optimized for rag. You're going to find new things to make better, not from this 8000 character prompt, but how to actually make it into these multiple agents. And then we'll step into that. 01:36:38\\nAlejo\\nSo let's give it a little bit more freedom by taking it out of the chat OpenAI context window and limitations and putting it into a new environment where it can be a little more free and we'll see what it does. 01:36:59\\nBartek\\nYeah, actually, I already drafted the prompts for, like, context agent. There is like, wait, there's context agent. There is the PM agent. Like a Pmidation agent. 01:37:13\\nAlejo\\nI'm going to write this down. 01:37:14\\nBartek\\nThis is the context. 01:37:15\\nAlejo\\nContext agent. 01:37:18\\nBartek\\nThen there is the pmidiation agent. Iteration, iteration, like ideation. 01:37:28\\nAlejo\\nAnd then there is ideation agent. 01:37:31\\nBartek\\nYeah. And this ideation agent is like technic choice, fusion structure and latent space activation. 01:37:42\\nAlejo\\nFusion, latent space and what else? 01:37:46\\nBartek\\nTechnic choice. Like a prompt. Technic choice. 01:37:51\\nAlejo\\nOh yeah. Fuck yeah.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"And then, well, the knowledge base will need it, which is not trivial. And then finally we need context enrichment. So we need global context and this is human input. 01:30:15\\nKuba\\nGuys, I have to bounce. 01:30:17\\nAlejo\\nOkay, we're pretty much done, so thank you for sticking through it. Kuba, great to have you here. 01:30:28\\nKuba\\nThe prompt engineering resources that I told you about. 01:30:33\\nAlejo\\nYes, thank you for reminding me. Bartek. Kuba asked about some prompt engineering resources to sort of keep learning, keep getting better. I think it'll be good for all of us to sharpen our prompt engineering skills. Would you share some intermediate into advanced resources with Kuba? 01:31:00\\nBartek\\nI already shared at some point the documentations. 01:31:04\\nAlejo\\nDocumentation. Right, right. 01:31:06\\nBartek\\nAnd the OpenAI guide. That's the thing for me.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"Like a video on YouTube. You know this guy Matthew Berman now? 38:08\\nAlejo\\nNo. 38:12\\nKuba\\nHe'S like an AI influencer. He did a video about it, about the framework. 38:20\\nAlejo\\nOkay, cool. Could you post it in the chat and we'll definitely take a look? Yeah, thank you, man.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content=\"I believe that in the future. 35:41\\nKuba\\nThat'S. 35:42\\nAlejo\\nGoing to be a minor value added, which is huge value today, that the great value is going to be able to be in coming up with the system in the first place. So say we have a call and we come up with this system, and by the end of the meeting, there's already a prototype being built, there's already documentation written. The steps, the project manager figure out the steps because of the objective and the success criteria that we set up and the programmers are already working on it. Kuba, you wanted to add something? 36:25\\nKuba\\nNo, what I'm thinking is we can actually build all this. All I was watching videos on cool AI, and it's very cool. It can enable us to do this. That was saying like the documentation writer, the projects manager, the programmer, then we have like a supervisor for all of them. Supervisor is the one that will be assigning the rules when a query comes in. So the supervisor understands that. Okay, this message belongs to the documentation writer. Okay, let's say agent. Then this rule belongs to the project manager. Agent. It's just like routing h query to the right. 37:19\\nAlejo\\nSomething like perfect. Okay.\", metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'}), Document(page_content='Okay. No, the other way around. V two is going to be testing an upgrade swarm with levels E. G. One, markdown two. What would level two be? 01:42:15\\nBartek\\nComplexity or like details. 01:42:18\\nAlejo\\nDetails. Three, accurate context capture. Okay.', metadata={'source': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt'})]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key= \"chat_history\",\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrival chain\n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def Knowledgebase(query:str) -> str:\n",
    "    \"\"\"Use this tool when answering questions about meetings, task, or general about a company called fastrise\"\"\"\n",
    "    result_str = retriver\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a custom tool\n",
    "@tool\n",
    "def Knowledgebase(query:str)-> str:\n",
    "    \"\"\"\n",
    "    Use this tool when answering question about meeting, task, activities in a organization called Fastrise\"\"\"\n",
    "    result_str = qa.invoke(query)\n",
    "    return result_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_context = \"\"\"Fasterise\n",
    "\n",
    "### Mission and Vision\n",
    "- *Mission and Vision*: Fasterise is centered around leveraging AI technology to amplify human potential, prioritizing ethical AI development that enriches human capabilities. The company envisions a future where AI solutions address societal needs and business challenges while augmenting the human potential and keeping it at the center of the system.\n",
    "### Team Structure and Roles\n",
    "- *Henry*: Brings AI and entrepreneurial insights, contributing significantly to the team's innovative capabilities in AI and LangChain.\n",
    "- *Zach*: Offers sales expertise and a keen sense for impactful business development, essential for guiding the company's market direction.\n",
    "- *Paige*: With a background in education and a focus on ethical AI, Paige drives the mission, marketing vision, and operational strategies of the company.\n",
    "- *Pawel*: Provides business analysis and client-facing skills, ensuring professional and confident representation of Fasterise's image.\n",
    "- *Bartek*: Leads in engineering with expertise in Prompt Engineering and AI Agents, and a focus on system design and test-driven development, enhancing the company's technical rigor.\n",
    "- *Alejo*: Plays a key role in Operations, Sales, and Development. In development, Alejo focuses on developer guidance through Scrums, making the vision of the company more tangible into projects with a particular emphasis on AI technologies like RAG, LLMs and Multi-Agent Systems.\n",
    "- *Hubi*: is diving into Python, LangChain and RAG. He has experience in front end development.\n",
    "- *Jorg*: Contributes to social media content and marketing campaigns, showcasing the company's solutions through various platforms.\n",
    "- *Kuba*: has played a key role in LangChain and RAG efforts, creating the first versions of the Pinecone Vector Database chat and the Personalized Outreach System.\n",
    "### Projects and Operations\n",
    "- *Completed Projects*: Highlight projects like the Ski Chalet Concierge, Scheduler Assistant, and Lead Qualifier, which exemplify Fasterise's commitment to enhancing operational efficiency and customer experience through AI.\n",
    "- *Current Projects*: Emphasize the development of innovative solutions like the Zoom Transcriber to Pinecone Integration, Knowledge Base Builder called KnowledgeNow, Personalized Outreach System, Administrative Automation Tools, and Real Estate-focused AI Solutions. These projects aim to integrate AI across various industries, improving efficiency and amplifying human capabilities.\n",
    "- *Future Direction*: Focus on continuous exploration of AI applications, with a commitment to adapting to technological advancements and exploring areas where AI can have a transformative societal impact, keeping empowerement and education at the forefront of the company's mission.\n",
    "### Company Culture and Values\n",
    "- *Profit-Sharing and Collaboration*: All team members are co-founders, with a profit-sharing structure and collective decision-making. The company culture promotes innovation, ethical business practices, and a shared vision for the impact of AI technology.\n",
    "- *Ethical and Human-Centered Approach*: A foundational commitment to developing AI solutions that align with ethical standards, enhance rather than replace human work, and focus on amplifying human capabilities.\n",
    "### Innovations and Products\n",
    "- *Technological Innovations*: AI-driven products, including AI solutions for real estate, personalized outreach, and KnowledgeNow. High technological sophistication and human-centered design of products like automated CRM and calendar systems, which facilitate better interactions with leads and clients.\n",
    "### Conclusion\n",
    "Fasterise stands out for its innovative approach to AI technology, with a strong emphasis on ethical development, collaborative innovation, and a culture of shared success. Through a diverse range of projects, the company showcases its capability to address complex challenges across various sectors, aiming for a significant societal impact and leading by example in the ethical use and development of AI.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a prompt template\n",
    "\n",
    "template = \"\"\"\n",
    " Your role is to use the global context to answer any question from users. \n",
    "\n",
    "\n",
    " {chat_history}\n",
    "\n",
    " global_context: {global_context}\n",
    "\n",
    "Begin!\n",
    "\n",
    " Question: {input}\n",
    "\n",
    " Thoughts: {agent_scratchpad}\n",
    " \n",
    " \"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template, MessagePlaceholder=[\"(agent_scratchpad)\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [Knowledgebase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(llm=llm, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Knowledgebase` with `{'query': 'what project was bartek and Alejo discuss in the meeting'}`\n",
      "\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What was the topic of the project discussed by Bartek and Alejo during the meeting?', '2. Which project were Bartek and Alejo talking about in their recent meeting?', '3. What subject matter were Bartek and Alejo focusing on in their project discussion at the meeting?']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m{'question': 'what project was bartek and Alejo discuss in the meeting', 'answer': 'Bartek and Alejo discussed the project \"Knowledgenow\" during the meeting. This project involves creating a system that generates a list of tasks for team members after each meeting to provide clarity on the tasks assigned to each individual. The system includes various agents such as context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. The project aims to automate tasks like cleaning and rendering transcripts for system input and includes use cases like messaging bots providing assignment updates post-meetings. The team is working towards achieving Minimum Viable Product (MVP) status and plans to include features like contribution calculators or project log automation in future iterations.\\n\\n', 'sources': 'data\\\\2024-03-12-Dev-Meeting-Knowledge-Now-Transcrpt-2.txt, data\\\\2024-03-12_Dev_Meeting_-_Knowledge_Now_summary_1.txt'}\u001b[0m\u001b[32;1m\u001b[1;3mBartek and Alejo discussed the project \"Knowledgenow\" during the meeting. This project involves creating a system that generates a list of tasks for team members after each meeting to provide clarity on the tasks assigned to each individual. The system includes various agents such as context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. The project aims to automate tasks like cleaning and rendering transcripts for system input and includes use cases like messaging bots providing assignment updates post-meetings. The team is working towards achieving Minimum Viable Product (MVP) status and plans to include features like contribution calculators or project log automation in future iterations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Bartek and Alejo discussed the project \"Knowledgenow\" during the meeting. This project involves creating a system that generates a list of tasks for team members after each meeting to provide clarity on the tasks assigned to each individual. The system includes various agents such as context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. The project aims to automate tasks like cleaning and rendering transcripts for system input and includes use cases like messaging bots providing assignment updates post-meetings. The team is working towards achieving Minimum Viable Product (MVP) status and plans to include features like contribution calculators or project log automation in future iterations.\n"
     ]
    }
   ],
   "source": [
    "query =\"what project was bartek and Alejo discuss in the meeting\"\n",
    "\n",
    "out = agent_executor.invoke({\"input\": query,\n",
    "                       \"chat_history\": [],\n",
    "                       \"global_context\":global_context })\n",
    "\n",
    "print(out[\"output\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#conversational memory \n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    k=5,\n",
    "    return_messages=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_memory.chat_memory.add_user_message(query)\n",
    "conversational_memory.chat_memory.add_ai_message(out[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what project was bartek and Alejo discuss in the meeting'),\n",
       " AIMessage(content='Bartek and Alejo discussed the project \"Knowledgenow\" during the meeting. This project involves creating a system that generates a list of tasks for team members after each meeting to provide clarity on the tasks assigned to each individual. The system includes various agents such as context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. The project aims to automate tasks like cleaning and rendering transcripts for system input and includes use cases like messaging bots providing assignment updates post-meetings. The team is working towards achieving Minimum Viable Product (MVP) status and plans to include features like contribution calculators or project log automation in future iterations.')]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "def memory2str(memory:ConversationBufferWindowMemory):\n",
    "    messages = memory.chat_memory.messages\n",
    "    memory_list = [\n",
    "        f\"Human: {mem.content}\" for mem in messages \n",
    "    ]\n",
    "    memory_str = \"/n\".join(memory_list)\n",
    "    return memory_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: what project was bartek and Alejo discuss in the meeting/nHuman: Bartek and Alejo discussed the project \"Knowledgenow\" during the meeting. This project involves creating a system that generates a list of tasks for team members after each meeting to provide clarity on the tasks assigned to each individual. The system includes various agents such as context enrichment, rag extractor, evaluator, QA, supervisor, merger, and answer formatting agents. The project aims to automate tasks like cleaning and rendering transcripts for system input and includes use cases like messaging bots providing assignment updates post-meetings. The team is working towards achieving Minimum Viable Product (MVP) status and plans to include features like contribution calculators or project log automation in future iterations.\n"
     ]
    }
   ],
   "source": [
    "print(memory2str(conversational_memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(text:str):\n",
    "    out = agent_executor.invoke({\n",
    "        \"input\":text, \n",
    "        \"chat_history\": [memory2str(conversational_memory)], \n",
    "        \"global_context\": global_context})\n",
    "    conversational_memory.chat_memory.add_user_message(text)\n",
    "    conversational_memory.chat_memory.add_ai_message(out[\"output\"])\n",
    "    return out[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIn the meeting, Bartek and Alejo discussed the project \"Knowledgenow,\" which involves creating a system that generates a list of tasks for team members after each meeting. The tasks they likely talked about include:\n",
      "\n",
      "1. **Context Enrichment**: Developing a system to enhance the context of the meeting discussions, making it easier for the system to understand and categorize the content of the meetings.\n",
      "\n",
      "2. **RAG Extractor**: Working on a Retrieval-Augmented Generation (RAG) extractor to pull relevant information from various sources to support the generation of tasks.\n",
      "\n",
      "3. **Evaluator**: Creating an evaluator agent to assess the relevance and accuracy of the generated tasks, ensuring they align with the meeting's outcomes.\n",
      "\n",
      "4. **QA (Quality Assurance)**: Implementing a QA system to check the quality of the tasks generated, ensuring they meet the project's standards.\n",
      "\n",
      "5. **Supervisor**: Designing a supervisor agent to oversee the entire process of task generation, ensuring smooth operation and coordination among different agents.\n",
      "\n",
      "6. **Merger**: Developing a merger agent to combine tasks from different sources into a coherent list that can be easily understood and actioned by team members.\n",
      "\n",
      "7. **Answer Formatting**: Working on formatting the generated tasks in a clear and actionable manner, making it easy for team members to understand their assignments.\n",
      "\n",
      "8. **Automating Transcript Cleaning and Rendering**: Automating the process of cleaning and rendering meeting transcripts to serve as input for the system, making the process more efficient.\n",
      "\n",
      "9. **Messaging Bots for Assignment Updates**: Implementing messaging bots to provide updates on assignments post-meetings, ensuring team members are aware of their tasks.\n",
      "\n",
      "The project aims to automate these tasks to provide clarity on the tasks assigned to each individual post-meeting, working towards achieving Minimum Viable Product (MVP) status and planning to include features like contribution calculators or project log automation in future iterations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "In the meeting, Bartek and Alejo discussed the project \"Knowledgenow,\" which involves creating a system that generates a list of tasks for team members after each meeting. The tasks they likely talked about include:\n",
      "\n",
      "1. **Context Enrichment**: Developing a system to enhance the context of the meeting discussions, making it easier for the system to understand and categorize the content of the meetings.\n",
      "\n",
      "2. **RAG Extractor**: Working on a Retrieval-Augmented Generation (RAG) extractor to pull relevant information from various sources to support the generation of tasks.\n",
      "\n",
      "3. **Evaluator**: Creating an evaluator agent to assess the relevance and accuracy of the generated tasks, ensuring they align with the meeting's outcomes.\n",
      "\n",
      "4. **QA (Quality Assurance)**: Implementing a QA system to check the quality of the tasks generated, ensuring they meet the project's standards.\n",
      "\n",
      "5. **Supervisor**: Designing a supervisor agent to oversee the entire process of task generation, ensuring smooth operation and coordination among different agents.\n",
      "\n",
      "6. **Merger**: Developing a merger agent to combine tasks from different sources into a coherent list that can be easily understood and actioned by team members.\n",
      "\n",
      "7. **Answer Formatting**: Working on formatting the generated tasks in a clear and actionable manner, making it easy for team members to understand their assignments.\n",
      "\n",
      "8. **Automating Transcript Cleaning and Rendering**: Automating the process of cleaning and rendering meeting transcripts to serve as input for the system, making the process more efficient.\n",
      "\n",
      "9. **Messaging Bots for Assignment Updates**: Implementing messaging bots to provide updates on assignments post-meetings, ensuring team members are aware of their tasks.\n",
      "\n",
      "The project aims to automate these tasks to provide clarity on the tasks assigned to each individual post-meeting, working towards achieving Minimum Viable Product (MVP) status and planning to include features like contribution calculators or project log automation in future iterations.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"list out the tasks alejo and bartek were talking about in the meeting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mIn the meeting, Alejo and Bartek discussed working on a project that they believe will be revolutionary, aiming to help a lot of people improve their lifestyles, work, and overall well-being. While the specific tasks were not detailed, given their roles and expertise within Fasterise, it's likely that their discussion involved:\n",
      "\n",
      "- **Development and Implementation of AI Technologies**: Considering Bartek's expertise in engineering, particularly in Prompt Engineering and AI Agents, and Alejo's role in Operations, Sales, and Development with a focus on developer guidance through Scrums, their tasks might involve strategizing and implementing AI technologies like RAG, LLMs, and Multi-Agent Systems to make the company's vision more tangible in projects.\n",
      "\n",
      "- **Project Management and Scrum Guidance**: Alejo's focus on providing developer guidance through Scrums suggests that part of their discussion could have involved planning sprints, setting project milestones, and ensuring that the development team is aligned with the project's goals.\n",
      "\n",
      "- **System Design and Test-Driven Development**: Given Bartek's focus on system design and test-driven development, tasks could also include designing the architecture of the project, ensuring that it is scalable, efficient, and meets the ethical standards of Fasterise. They might also be planning how to test the project's components to ensure reliability and effectiveness.\n",
      "\n",
      "- **Collaboration and Innovation**: Both Alejo and Bartek would likely discuss how to foster collaboration among team members and encourage innovative thinking to address the challenges of the project. This could involve brainstorming sessions, workshops, or collaborative platforms to gather ideas and feedback.\n",
      "\n",
      "Their discussion, therefore, would encompass a range of tasks from the technical development of AI solutions to project management and team collaboration, all aimed at creating a project that aligns with Fasterise's mission of leveraging AI technology to amplify human potential while adhering to ethical standards.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "In the meeting, Alejo and Bartek discussed working on a project that they believe will be revolutionary, aiming to help a lot of people improve their lifestyles, work, and overall well-being. While the specific tasks were not detailed, given their roles and expertise within Fasterise, it's likely that their discussion involved:\n",
      "\n",
      "- **Development and Implementation of AI Technologies**: Considering Bartek's expertise in engineering, particularly in Prompt Engineering and AI Agents, and Alejo's role in Operations, Sales, and Development with a focus on developer guidance through Scrums, their tasks might involve strategizing and implementing AI technologies like RAG, LLMs, and Multi-Agent Systems to make the company's vision more tangible in projects.\n",
      "\n",
      "- **Project Management and Scrum Guidance**: Alejo's focus on providing developer guidance through Scrums suggests that part of their discussion could have involved planning sprints, setting project milestones, and ensuring that the development team is aligned with the project's goals.\n",
      "\n",
      "- **System Design and Test-Driven Development**: Given Bartek's focus on system design and test-driven development, tasks could also include designing the architecture of the project, ensuring that it is scalable, efficient, and meets the ethical standards of Fasterise. They might also be planning how to test the project's components to ensure reliability and effectiveness.\n",
      "\n",
      "- **Collaboration and Innovation**: Both Alejo and Bartek would likely discuss how to foster collaboration among team members and encourage innovative thinking to address the challenges of the project. This could involve brainstorming sessions, workshops, or collaborative platforms to gather ideas and feedback.\n",
      "\n",
      "Their discussion, therefore, would encompass a range of tasks from the technical development of AI solutions to project management and team collaboration, all aimed at creating a project that aligns with Fasterise's mission of leveraging AI technology to amplify human potential while adhering to ethical standards.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"can you list out the tasks alejo and bartek were talking about in the meeting\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Windows\\System32\\Knowledgenow\\env\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: It seems like you haven't asked a question yet. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input=input(f\"Input_Prompt:\")\n",
    "    result= qa({\"query\": user_input})\n",
    "    print(\"Response:\", result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
